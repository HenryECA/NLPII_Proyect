{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5648235934883908,
  "eval_steps": 200,
  "global_step": 14000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0004034454239202792,
      "grad_norm": 1.04974365234375,
      "learning_rate": 7.3343224253025624e-06,
      "loss": 1.6669,
      "step": 10
    },
    {
      "epoch": 0.0008068908478405584,
      "grad_norm": 0.6408606767654419,
      "learning_rate": 1.4668644850605125e-05,
      "loss": 1.743,
      "step": 20
    },
    {
      "epoch": 0.0012103362717608376,
      "grad_norm": 1.0023528337478638,
      "learning_rate": 2.2002967275907686e-05,
      "loss": 1.441,
      "step": 30
    },
    {
      "epoch": 0.0016137816956811168,
      "grad_norm": 1.40764582157135,
      "learning_rate": 2.933728970121025e-05,
      "loss": 1.55,
      "step": 40
    },
    {
      "epoch": 0.002017227119601396,
      "grad_norm": 1.5176419019699097,
      "learning_rate": 3.667161212651281e-05,
      "loss": 1.6644,
      "step": 50
    },
    {
      "epoch": 0.002420672543521675,
      "grad_norm": 1.6875901222229004,
      "learning_rate": 4.400593455181537e-05,
      "loss": 1.4973,
      "step": 60
    },
    {
      "epoch": 0.0028241179674419544,
      "grad_norm": 1.4775832891464233,
      "learning_rate": 5.1340256977117936e-05,
      "loss": 1.3496,
      "step": 70
    },
    {
      "epoch": 0.0032275633913622336,
      "grad_norm": 1.7245464324951172,
      "learning_rate": 5.86745794024205e-05,
      "loss": 1.5375,
      "step": 80
    },
    {
      "epoch": 0.0036310088152825127,
      "grad_norm": 1.403518795967102,
      "learning_rate": 6.600890182772305e-05,
      "loss": 1.5596,
      "step": 90
    },
    {
      "epoch": 0.004034454239202792,
      "grad_norm": 1.0108387470245361,
      "learning_rate": 7.334322425302562e-05,
      "loss": 1.5014,
      "step": 100
    },
    {
      "epoch": 0.004437899663123071,
      "grad_norm": 1.1914395093917847,
      "learning_rate": 8.067754667832818e-05,
      "loss": 1.3409,
      "step": 110
    },
    {
      "epoch": 0.00484134508704335,
      "grad_norm": 0.9425318837165833,
      "learning_rate": 8.801186910363075e-05,
      "loss": 1.3486,
      "step": 120
    },
    {
      "epoch": 0.005244790510963629,
      "grad_norm": 1.0117218494415283,
      "learning_rate": 9.53461915289333e-05,
      "loss": 1.4255,
      "step": 130
    },
    {
      "epoch": 0.005648235934883909,
      "grad_norm": 1.2888743877410889,
      "learning_rate": 0.00010268051395423587,
      "loss": 1.2941,
      "step": 140
    },
    {
      "epoch": 0.0060516813588041875,
      "grad_norm": 1.019389271736145,
      "learning_rate": 0.00011001483637953843,
      "loss": 1.3145,
      "step": 150
    },
    {
      "epoch": 0.006455126782724467,
      "grad_norm": 0.8355432748794556,
      "learning_rate": 0.000117349158804841,
      "loss": 1.4527,
      "step": 160
    },
    {
      "epoch": 0.006858572206644746,
      "grad_norm": 1.8176640272140503,
      "learning_rate": 0.00012468348123014357,
      "loss": 1.307,
      "step": 170
    },
    {
      "epoch": 0.0072620176305650255,
      "grad_norm": 0.772991418838501,
      "learning_rate": 0.0001320178036554461,
      "loss": 1.4217,
      "step": 180
    },
    {
      "epoch": 0.007665463054485304,
      "grad_norm": 1.0222395658493042,
      "learning_rate": 0.00013935212608074868,
      "loss": 1.3951,
      "step": 190
    },
    {
      "epoch": 0.008068908478405584,
      "grad_norm": 0.6731542944908142,
      "learning_rate": 0.00014668644850605124,
      "loss": 1.4007,
      "step": 200
    },
    {
      "epoch": 0.008068908478405584,
      "eval_loss": 1.33827805519104,
      "eval_runtime": 14.8299,
      "eval_samples_per_second": 3.372,
      "eval_steps_per_second": 1.686,
      "step": 200
    },
    {
      "epoch": 0.008472353902325864,
      "grad_norm": 1.2499288320541382,
      "learning_rate": 0.0001540207709313538,
      "loss": 1.3217,
      "step": 210
    },
    {
      "epoch": 0.008875799326246141,
      "grad_norm": 0.6071576476097107,
      "learning_rate": 0.00016135509335665635,
      "loss": 1.234,
      "step": 220
    },
    {
      "epoch": 0.009279244750166421,
      "grad_norm": 1.0289640426635742,
      "learning_rate": 0.00016868941578195894,
      "loss": 1.5754,
      "step": 230
    },
    {
      "epoch": 0.0096826901740867,
      "grad_norm": 1.0633856058120728,
      "learning_rate": 0.0001760237382072615,
      "loss": 1.2524,
      "step": 240
    },
    {
      "epoch": 0.01008613559800698,
      "grad_norm": 0.7681804895401001,
      "learning_rate": 0.00018335806063256405,
      "loss": 1.3579,
      "step": 250
    },
    {
      "epoch": 0.010489581021927258,
      "grad_norm": 0.8510327339172363,
      "learning_rate": 0.0001833212047409796,
      "loss": 1.3942,
      "step": 260
    },
    {
      "epoch": 0.010893026445847538,
      "grad_norm": 1.1970306634902954,
      "learning_rate": 0.00018328434884939517,
      "loss": 1.3216,
      "step": 270
    },
    {
      "epoch": 0.011296471869767817,
      "grad_norm": 0.7888671159744263,
      "learning_rate": 0.00018324749295781074,
      "loss": 1.3013,
      "step": 280
    },
    {
      "epoch": 0.011699917293688097,
      "grad_norm": 1.0640573501586914,
      "learning_rate": 0.0001832106370662263,
      "loss": 1.2471,
      "step": 290
    },
    {
      "epoch": 0.012103362717608375,
      "grad_norm": 1.8072682619094849,
      "learning_rate": 0.00018317378117464186,
      "loss": 1.216,
      "step": 300
    },
    {
      "epoch": 0.012506808141528655,
      "grad_norm": 0.8492854237556458,
      "learning_rate": 0.00018313692528305742,
      "loss": 1.3042,
      "step": 310
    },
    {
      "epoch": 0.012910253565448934,
      "grad_norm": 0.9907780885696411,
      "learning_rate": 0.00018310006939147301,
      "loss": 1.3302,
      "step": 320
    },
    {
      "epoch": 0.013313698989369214,
      "grad_norm": 0.8126429915428162,
      "learning_rate": 0.00018306321349988858,
      "loss": 1.2908,
      "step": 330
    },
    {
      "epoch": 0.013717144413289492,
      "grad_norm": 0.7614100575447083,
      "learning_rate": 0.00018302635760830414,
      "loss": 1.2995,
      "step": 340
    },
    {
      "epoch": 0.014120589837209771,
      "grad_norm": 0.7745555639266968,
      "learning_rate": 0.00018298950171671968,
      "loss": 1.3483,
      "step": 350
    },
    {
      "epoch": 0.014524035261130051,
      "grad_norm": 1.0099531412124634,
      "learning_rate": 0.00018295264582513527,
      "loss": 1.2999,
      "step": 360
    },
    {
      "epoch": 0.01492748068505033,
      "grad_norm": 1.009347915649414,
      "learning_rate": 0.00018291578993355083,
      "loss": 1.3729,
      "step": 370
    },
    {
      "epoch": 0.015330926108970609,
      "grad_norm": 0.8130093216896057,
      "learning_rate": 0.0001828789340419664,
      "loss": 1.3711,
      "step": 380
    },
    {
      "epoch": 0.015734371532890888,
      "grad_norm": 0.7105342745780945,
      "learning_rate": 0.00018284207815038195,
      "loss": 1.2745,
      "step": 390
    },
    {
      "epoch": 0.016137816956811168,
      "grad_norm": 0.8914085030555725,
      "learning_rate": 0.00018280522225879752,
      "loss": 1.3899,
      "step": 400
    },
    {
      "epoch": 0.016137816956811168,
      "eval_loss": 1.3241010904312134,
      "eval_runtime": 14.8146,
      "eval_samples_per_second": 3.375,
      "eval_steps_per_second": 1.688,
      "step": 400
    },
    {
      "epoch": 0.016541262380731447,
      "grad_norm": 0.5556920766830444,
      "learning_rate": 0.00018276836636721308,
      "loss": 1.2963,
      "step": 410
    },
    {
      "epoch": 0.016944707804651727,
      "grad_norm": 0.8387794494628906,
      "learning_rate": 0.00018273151047562864,
      "loss": 1.2418,
      "step": 420
    },
    {
      "epoch": 0.017348153228572007,
      "grad_norm": 1.386899471282959,
      "learning_rate": 0.0001826946545840442,
      "loss": 1.3844,
      "step": 430
    },
    {
      "epoch": 0.017751598652492283,
      "grad_norm": 0.9507974982261658,
      "learning_rate": 0.0001826577986924598,
      "loss": 1.2395,
      "step": 440
    },
    {
      "epoch": 0.018155044076412562,
      "grad_norm": 1.5620603561401367,
      "learning_rate": 0.00018262094280087536,
      "loss": 1.3829,
      "step": 450
    },
    {
      "epoch": 0.018558489500332842,
      "grad_norm": 0.7854077816009521,
      "learning_rate": 0.00018258408690929092,
      "loss": 1.2978,
      "step": 460
    },
    {
      "epoch": 0.01896193492425312,
      "grad_norm": 0.7939662337303162,
      "learning_rate": 0.00018254723101770648,
      "loss": 1.5628,
      "step": 470
    },
    {
      "epoch": 0.0193653803481734,
      "grad_norm": 0.746910572052002,
      "learning_rate": 0.00018251037512612205,
      "loss": 1.2365,
      "step": 480
    },
    {
      "epoch": 0.01976882577209368,
      "grad_norm": 1.6454898118972778,
      "learning_rate": 0.0001824735192345376,
      "loss": 1.343,
      "step": 490
    },
    {
      "epoch": 0.02017227119601396,
      "grad_norm": 0.6832097768783569,
      "learning_rate": 0.00018243666334295317,
      "loss": 1.3593,
      "step": 500
    },
    {
      "epoch": 0.020575716619934237,
      "grad_norm": 0.7347155809402466,
      "learning_rate": 0.00018239980745136873,
      "loss": 1.2171,
      "step": 510
    },
    {
      "epoch": 0.020979162043854516,
      "grad_norm": 1.202126145362854,
      "learning_rate": 0.00018236295155978432,
      "loss": 1.3135,
      "step": 520
    },
    {
      "epoch": 0.021382607467774796,
      "grad_norm": 0.7580407857894897,
      "learning_rate": 0.00018232609566819986,
      "loss": 1.2153,
      "step": 530
    },
    {
      "epoch": 0.021786052891695076,
      "grad_norm": 0.7426155209541321,
      "learning_rate": 0.00018228923977661542,
      "loss": 1.2447,
      "step": 540
    },
    {
      "epoch": 0.022189498315615355,
      "grad_norm": 1.3983371257781982,
      "learning_rate": 0.00018225238388503098,
      "loss": 1.3394,
      "step": 550
    },
    {
      "epoch": 0.022592943739535635,
      "grad_norm": 0.6933587193489075,
      "learning_rate": 0.00018221552799344657,
      "loss": 1.3388,
      "step": 560
    },
    {
      "epoch": 0.022996389163455914,
      "grad_norm": 0.904536783695221,
      "learning_rate": 0.00018217867210186214,
      "loss": 1.3663,
      "step": 570
    },
    {
      "epoch": 0.023399834587376194,
      "grad_norm": 0.774606466293335,
      "learning_rate": 0.0001821418162102777,
      "loss": 1.2385,
      "step": 580
    },
    {
      "epoch": 0.02380328001129647,
      "grad_norm": 0.7420041561126709,
      "learning_rate": 0.00018210496031869326,
      "loss": 1.3078,
      "step": 590
    },
    {
      "epoch": 0.02420672543521675,
      "grad_norm": 0.666803240776062,
      "learning_rate": 0.00018206810442710883,
      "loss": 1.1722,
      "step": 600
    },
    {
      "epoch": 0.02420672543521675,
      "eval_loss": 1.3139358758926392,
      "eval_runtime": 15.0543,
      "eval_samples_per_second": 3.321,
      "eval_steps_per_second": 1.661,
      "step": 600
    },
    {
      "epoch": 0.02461017085913703,
      "grad_norm": 0.9496687650680542,
      "learning_rate": 0.0001820312485355244,
      "loss": 1.1679,
      "step": 610
    },
    {
      "epoch": 0.02501361628305731,
      "grad_norm": 0.6417443752288818,
      "learning_rate": 0.00018199439264393995,
      "loss": 1.5673,
      "step": 620
    },
    {
      "epoch": 0.02541706170697759,
      "grad_norm": 1.0747878551483154,
      "learning_rate": 0.0001819575367523555,
      "loss": 1.2375,
      "step": 630
    },
    {
      "epoch": 0.02582050713089787,
      "grad_norm": 1.5876781940460205,
      "learning_rate": 0.0001819206808607711,
      "loss": 1.274,
      "step": 640
    },
    {
      "epoch": 0.026223952554818148,
      "grad_norm": 1.0579814910888672,
      "learning_rate": 0.00018188382496918664,
      "loss": 1.2818,
      "step": 650
    },
    {
      "epoch": 0.026627397978738428,
      "grad_norm": 0.7236341238021851,
      "learning_rate": 0.0001818469690776022,
      "loss": 1.3356,
      "step": 660
    },
    {
      "epoch": 0.027030843402658704,
      "grad_norm": 1.2109988927841187,
      "learning_rate": 0.00018181011318601776,
      "loss": 1.2812,
      "step": 670
    },
    {
      "epoch": 0.027434288826578983,
      "grad_norm": 0.7187151312828064,
      "learning_rate": 0.00018177325729443335,
      "loss": 1.4227,
      "step": 680
    },
    {
      "epoch": 0.027837734250499263,
      "grad_norm": 1.113329291343689,
      "learning_rate": 0.00018173640140284892,
      "loss": 1.2415,
      "step": 690
    },
    {
      "epoch": 0.028241179674419543,
      "grad_norm": 0.7928338050842285,
      "learning_rate": 0.00018169954551126448,
      "loss": 1.2062,
      "step": 700
    },
    {
      "epoch": 0.028644625098339822,
      "grad_norm": 0.8597027659416199,
      "learning_rate": 0.00018166268961968004,
      "loss": 1.3638,
      "step": 710
    },
    {
      "epoch": 0.029048070522260102,
      "grad_norm": 0.9496225118637085,
      "learning_rate": 0.0001816258337280956,
      "loss": 1.3685,
      "step": 720
    },
    {
      "epoch": 0.02945151594618038,
      "grad_norm": 0.8309710621833801,
      "learning_rate": 0.00018158897783651117,
      "loss": 1.3062,
      "step": 730
    },
    {
      "epoch": 0.02985496137010066,
      "grad_norm": 0.9045329093933105,
      "learning_rate": 0.00018155212194492673,
      "loss": 1.4,
      "step": 740
    },
    {
      "epoch": 0.030258406794020937,
      "grad_norm": 0.7023568153381348,
      "learning_rate": 0.0001815152660533423,
      "loss": 1.2344,
      "step": 750
    },
    {
      "epoch": 0.030661852217941217,
      "grad_norm": 0.8838591575622559,
      "learning_rate": 0.00018147841016175788,
      "loss": 1.3706,
      "step": 760
    },
    {
      "epoch": 0.031065297641861497,
      "grad_norm": 0.99320387840271,
      "learning_rate": 0.00018144155427017342,
      "loss": 1.3111,
      "step": 770
    },
    {
      "epoch": 0.031468743065781776,
      "grad_norm": 1.2095069885253906,
      "learning_rate": 0.00018140469837858898,
      "loss": 1.3485,
      "step": 780
    },
    {
      "epoch": 0.03187218848970205,
      "grad_norm": 2.61368727684021,
      "learning_rate": 0.00018136784248700454,
      "loss": 1.3331,
      "step": 790
    },
    {
      "epoch": 0.032275633913622336,
      "grad_norm": 0.8004366159439087,
      "learning_rate": 0.00018133098659542013,
      "loss": 1.2291,
      "step": 800
    },
    {
      "epoch": 0.032275633913622336,
      "eval_loss": 1.3197935819625854,
      "eval_runtime": 14.5751,
      "eval_samples_per_second": 3.431,
      "eval_steps_per_second": 1.715,
      "step": 800
    },
    {
      "epoch": 0.03267907933754261,
      "grad_norm": 0.8334012031555176,
      "learning_rate": 0.0001812941307038357,
      "loss": 1.2464,
      "step": 810
    },
    {
      "epoch": 0.033082524761462895,
      "grad_norm": 0.9045017957687378,
      "learning_rate": 0.00018125727481225126,
      "loss": 1.3062,
      "step": 820
    },
    {
      "epoch": 0.03348597018538317,
      "grad_norm": 0.7613312005996704,
      "learning_rate": 0.00018122041892066682,
      "loss": 1.3693,
      "step": 830
    },
    {
      "epoch": 0.033889415609303454,
      "grad_norm": 1.3614826202392578,
      "learning_rate": 0.00018118356302908238,
      "loss": 1.2894,
      "step": 840
    },
    {
      "epoch": 0.03429286103322373,
      "grad_norm": 0.7722920179367065,
      "learning_rate": 0.00018114670713749795,
      "loss": 1.2383,
      "step": 850
    },
    {
      "epoch": 0.03469630645714401,
      "grad_norm": 1.6424413919448853,
      "learning_rate": 0.0001811098512459135,
      "loss": 1.3946,
      "step": 860
    },
    {
      "epoch": 0.03509975188106429,
      "grad_norm": 1.0108064413070679,
      "learning_rate": 0.00018107299535432907,
      "loss": 1.5274,
      "step": 870
    },
    {
      "epoch": 0.035503197304984566,
      "grad_norm": 0.9285642504692078,
      "learning_rate": 0.00018103613946274466,
      "loss": 1.2311,
      "step": 880
    },
    {
      "epoch": 0.03590664272890485,
      "grad_norm": 1.150478482246399,
      "learning_rate": 0.00018099928357116023,
      "loss": 1.4253,
      "step": 890
    },
    {
      "epoch": 0.036310088152825125,
      "grad_norm": 1.0146628618240356,
      "learning_rate": 0.00018096242767957576,
      "loss": 1.4017,
      "step": 900
    },
    {
      "epoch": 0.03671353357674541,
      "grad_norm": 1.0198076963424683,
      "learning_rate": 0.00018092557178799132,
      "loss": 1.4448,
      "step": 910
    },
    {
      "epoch": 0.037116979000665684,
      "grad_norm": 1.1009198427200317,
      "learning_rate": 0.00018088871589640691,
      "loss": 1.3387,
      "step": 920
    },
    {
      "epoch": 0.03752042442458597,
      "grad_norm": 0.9215904474258423,
      "learning_rate": 0.00018085186000482248,
      "loss": 1.3336,
      "step": 930
    },
    {
      "epoch": 0.03792386984850624,
      "grad_norm": 1.0638986825942993,
      "learning_rate": 0.00018081500411323804,
      "loss": 1.3695,
      "step": 940
    },
    {
      "epoch": 0.03832731527242652,
      "grad_norm": 0.5850130319595337,
      "learning_rate": 0.0001807781482216536,
      "loss": 1.4689,
      "step": 950
    },
    {
      "epoch": 0.0387307606963468,
      "grad_norm": 0.7805556058883667,
      "learning_rate": 0.00018074129233006916,
      "loss": 1.1453,
      "step": 960
    },
    {
      "epoch": 0.03913420612026708,
      "grad_norm": 0.8147582411766052,
      "learning_rate": 0.00018070443643848473,
      "loss": 1.4212,
      "step": 970
    },
    {
      "epoch": 0.03953765154418736,
      "grad_norm": 1.2068815231323242,
      "learning_rate": 0.0001806675805469003,
      "loss": 1.3634,
      "step": 980
    },
    {
      "epoch": 0.03994109696810764,
      "grad_norm": 1.0024573802947998,
      "learning_rate": 0.00018063072465531585,
      "loss": 1.2837,
      "step": 990
    },
    {
      "epoch": 0.04034454239202792,
      "grad_norm": 1.3653719425201416,
      "learning_rate": 0.00018059386876373144,
      "loss": 1.5382,
      "step": 1000
    },
    {
      "epoch": 0.04034454239202792,
      "eval_loss": 1.3112505674362183,
      "eval_runtime": 14.5615,
      "eval_samples_per_second": 3.434,
      "eval_steps_per_second": 1.717,
      "step": 1000
    },
    {
      "epoch": 0.0407479878159482,
      "grad_norm": 1.0971983671188354,
      "learning_rate": 0.000180557012872147,
      "loss": 1.2643,
      "step": 1010
    },
    {
      "epoch": 0.04115143323986847,
      "grad_norm": 0.9748796820640564,
      "learning_rate": 0.00018052015698056254,
      "loss": 1.4163,
      "step": 1020
    },
    {
      "epoch": 0.04155487866378876,
      "grad_norm": 1.7529711723327637,
      "learning_rate": 0.0001804833010889781,
      "loss": 1.4053,
      "step": 1030
    },
    {
      "epoch": 0.04195832408770903,
      "grad_norm": 0.9443985819816589,
      "learning_rate": 0.0001804464451973937,
      "loss": 1.2639,
      "step": 1040
    },
    {
      "epoch": 0.042361769511629316,
      "grad_norm": 0.8160395622253418,
      "learning_rate": 0.00018040958930580926,
      "loss": 1.1989,
      "step": 1050
    },
    {
      "epoch": 0.04276521493554959,
      "grad_norm": 0.9439788460731506,
      "learning_rate": 0.00018037273341422482,
      "loss": 1.2428,
      "step": 1060
    },
    {
      "epoch": 0.043168660359469875,
      "grad_norm": 0.8359459638595581,
      "learning_rate": 0.00018033587752264038,
      "loss": 1.2857,
      "step": 1070
    },
    {
      "epoch": 0.04357210578339015,
      "grad_norm": 1.212087869644165,
      "learning_rate": 0.00018029902163105594,
      "loss": 1.4182,
      "step": 1080
    },
    {
      "epoch": 0.043975551207310434,
      "grad_norm": 0.8237515687942505,
      "learning_rate": 0.0001802621657394715,
      "loss": 1.4498,
      "step": 1090
    },
    {
      "epoch": 0.04437899663123071,
      "grad_norm": 0.9933043718338013,
      "learning_rate": 0.00018022530984788707,
      "loss": 1.1582,
      "step": 1100
    },
    {
      "epoch": 0.04478244205515099,
      "grad_norm": 1.1493189334869385,
      "learning_rate": 0.00018018845395630263,
      "loss": 1.2825,
      "step": 1110
    },
    {
      "epoch": 0.04518588747907127,
      "grad_norm": 0.6801223754882812,
      "learning_rate": 0.00018015159806471822,
      "loss": 1.2478,
      "step": 1120
    },
    {
      "epoch": 0.045589332902991546,
      "grad_norm": 0.9648957848548889,
      "learning_rate": 0.00018011474217313379,
      "loss": 1.3305,
      "step": 1130
    },
    {
      "epoch": 0.04599277832691183,
      "grad_norm": 1.1065772771835327,
      "learning_rate": 0.00018007788628154932,
      "loss": 1.46,
      "step": 1140
    },
    {
      "epoch": 0.046396223750832105,
      "grad_norm": 1.0895071029663086,
      "learning_rate": 0.00018004103038996488,
      "loss": 1.3495,
      "step": 1150
    },
    {
      "epoch": 0.04679966917475239,
      "grad_norm": 1.2329260110855103,
      "learning_rate": 0.00018000417449838047,
      "loss": 1.2498,
      "step": 1160
    },
    {
      "epoch": 0.047203114598672664,
      "grad_norm": 1.2770240306854248,
      "learning_rate": 0.00017996731860679604,
      "loss": 1.3335,
      "step": 1170
    },
    {
      "epoch": 0.04760656002259294,
      "grad_norm": 0.9850426912307739,
      "learning_rate": 0.0001799304627152116,
      "loss": 1.2137,
      "step": 1180
    },
    {
      "epoch": 0.048010005446513224,
      "grad_norm": 1.0081725120544434,
      "learning_rate": 0.00017989360682362716,
      "loss": 1.1996,
      "step": 1190
    },
    {
      "epoch": 0.0484134508704335,
      "grad_norm": 1.1626116037368774,
      "learning_rate": 0.00017985675093204272,
      "loss": 1.3829,
      "step": 1200
    },
    {
      "epoch": 0.0484134508704335,
      "eval_loss": 1.3093132972717285,
      "eval_runtime": 14.5543,
      "eval_samples_per_second": 3.435,
      "eval_steps_per_second": 1.718,
      "step": 1200
    },
    {
      "epoch": 0.04881689629435378,
      "grad_norm": 1.7225704193115234,
      "learning_rate": 0.0001798198950404583,
      "loss": 1.139,
      "step": 1210
    },
    {
      "epoch": 0.04922034171827406,
      "grad_norm": 0.8031116127967834,
      "learning_rate": 0.00017978303914887385,
      "loss": 1.5545,
      "step": 1220
    },
    {
      "epoch": 0.04962378714219434,
      "grad_norm": 0.6177252531051636,
      "learning_rate": 0.0001797461832572894,
      "loss": 1.3216,
      "step": 1230
    },
    {
      "epoch": 0.05002723256611462,
      "grad_norm": 0.8406946659088135,
      "learning_rate": 0.000179709327365705,
      "loss": 1.4364,
      "step": 1240
    },
    {
      "epoch": 0.0504306779900349,
      "grad_norm": 0.6874325275421143,
      "learning_rate": 0.00017967247147412057,
      "loss": 1.3556,
      "step": 1250
    },
    {
      "epoch": 0.05083412341395518,
      "grad_norm": 0.8656779527664185,
      "learning_rate": 0.00017963561558253613,
      "loss": 1.2517,
      "step": 1260
    },
    {
      "epoch": 0.051237568837875454,
      "grad_norm": 0.881244421005249,
      "learning_rate": 0.00017959875969095166,
      "loss": 1.3631,
      "step": 1270
    },
    {
      "epoch": 0.05164101426179574,
      "grad_norm": 0.9717349410057068,
      "learning_rate": 0.00017956190379936725,
      "loss": 1.2592,
      "step": 1280
    },
    {
      "epoch": 0.05204445968571601,
      "grad_norm": 1.0242596864700317,
      "learning_rate": 0.00017952504790778282,
      "loss": 1.435,
      "step": 1290
    },
    {
      "epoch": 0.052447905109636296,
      "grad_norm": 1.0916606187820435,
      "learning_rate": 0.00017948819201619838,
      "loss": 1.3459,
      "step": 1300
    },
    {
      "epoch": 0.05285135053355657,
      "grad_norm": 1.099143385887146,
      "learning_rate": 0.00017945133612461394,
      "loss": 1.3926,
      "step": 1310
    },
    {
      "epoch": 0.053254795957476855,
      "grad_norm": 1.1550445556640625,
      "learning_rate": 0.0001794144802330295,
      "loss": 1.3595,
      "step": 1320
    },
    {
      "epoch": 0.05365824138139713,
      "grad_norm": 0.8911797404289246,
      "learning_rate": 0.00017937762434144507,
      "loss": 1.5216,
      "step": 1330
    },
    {
      "epoch": 0.05406168680531741,
      "grad_norm": 0.861750602722168,
      "learning_rate": 0.00017934076844986063,
      "loss": 1.2643,
      "step": 1340
    },
    {
      "epoch": 0.05446513222923769,
      "grad_norm": 0.7398843169212341,
      "learning_rate": 0.0001793039125582762,
      "loss": 1.2117,
      "step": 1350
    },
    {
      "epoch": 0.05486857765315797,
      "grad_norm": 1.8131457567214966,
      "learning_rate": 0.00017926705666669178,
      "loss": 1.4029,
      "step": 1360
    },
    {
      "epoch": 0.05527202307707825,
      "grad_norm": 1.1343908309936523,
      "learning_rate": 0.00017923020077510734,
      "loss": 1.3097,
      "step": 1370
    },
    {
      "epoch": 0.055675468500998526,
      "grad_norm": 1.1422053575515747,
      "learning_rate": 0.0001791933448835229,
      "loss": 1.3588,
      "step": 1380
    },
    {
      "epoch": 0.05607891392491881,
      "grad_norm": 0.9264635443687439,
      "learning_rate": 0.00017915648899193844,
      "loss": 1.2679,
      "step": 1390
    },
    {
      "epoch": 0.056482359348839085,
      "grad_norm": 0.8585936427116394,
      "learning_rate": 0.00017911963310035403,
      "loss": 1.4141,
      "step": 1400
    },
    {
      "epoch": 0.056482359348839085,
      "eval_loss": 1.312109112739563,
      "eval_runtime": 14.5755,
      "eval_samples_per_second": 3.43,
      "eval_steps_per_second": 1.715,
      "step": 1400
    },
    {
      "epoch": 0.05688580477275936,
      "grad_norm": 0.9989091753959656,
      "learning_rate": 0.0001790827772087696,
      "loss": 1.5103,
      "step": 1410
    },
    {
      "epoch": 0.057289250196679645,
      "grad_norm": 1.348872423171997,
      "learning_rate": 0.00017904592131718516,
      "loss": 1.2282,
      "step": 1420
    },
    {
      "epoch": 0.05769269562059992,
      "grad_norm": 1.5664682388305664,
      "learning_rate": 0.00017900906542560072,
      "loss": 1.4404,
      "step": 1430
    },
    {
      "epoch": 0.058096141044520204,
      "grad_norm": 0.8329107165336609,
      "learning_rate": 0.00017897220953401628,
      "loss": 1.313,
      "step": 1440
    },
    {
      "epoch": 0.05849958646844048,
      "grad_norm": 0.7576317191123962,
      "learning_rate": 0.00017893535364243185,
      "loss": 1.387,
      "step": 1450
    },
    {
      "epoch": 0.05890303189236076,
      "grad_norm": 1.4714454412460327,
      "learning_rate": 0.0001788984977508474,
      "loss": 1.5221,
      "step": 1460
    },
    {
      "epoch": 0.05930647731628104,
      "grad_norm": 0.9099302291870117,
      "learning_rate": 0.00017886164185926297,
      "loss": 1.3485,
      "step": 1470
    },
    {
      "epoch": 0.05970992274020132,
      "grad_norm": 1.0038611888885498,
      "learning_rate": 0.00017882478596767853,
      "loss": 1.3559,
      "step": 1480
    },
    {
      "epoch": 0.0601133681641216,
      "grad_norm": 0.8774077892303467,
      "learning_rate": 0.00017878793007609412,
      "loss": 1.3549,
      "step": 1490
    },
    {
      "epoch": 0.060516813588041875,
      "grad_norm": 0.8884508609771729,
      "learning_rate": 0.0001787510741845097,
      "loss": 1.3505,
      "step": 1500
    },
    {
      "epoch": 0.06092025901196216,
      "grad_norm": 1.0332216024398804,
      "learning_rate": 0.00017871421829292522,
      "loss": 1.2276,
      "step": 1510
    },
    {
      "epoch": 0.061323704435882434,
      "grad_norm": 1.4754263162612915,
      "learning_rate": 0.00017867736240134079,
      "loss": 1.2768,
      "step": 1520
    },
    {
      "epoch": 0.06172714985980272,
      "grad_norm": 1.0664163827896118,
      "learning_rate": 0.00017864050650975638,
      "loss": 1.3292,
      "step": 1530
    },
    {
      "epoch": 0.06213059528372299,
      "grad_norm": 1.4977401494979858,
      "learning_rate": 0.00017860365061817194,
      "loss": 1.3203,
      "step": 1540
    },
    {
      "epoch": 0.06253404070764328,
      "grad_norm": 1.0489826202392578,
      "learning_rate": 0.0001785667947265875,
      "loss": 1.2541,
      "step": 1550
    },
    {
      "epoch": 0.06293748613156355,
      "grad_norm": 2.403841733932495,
      "learning_rate": 0.00017852993883500306,
      "loss": 1.5242,
      "step": 1560
    },
    {
      "epoch": 0.06334093155548383,
      "grad_norm": 1.0329290628433228,
      "learning_rate": 0.00017849308294341863,
      "loss": 1.3418,
      "step": 1570
    },
    {
      "epoch": 0.0637443769794041,
      "grad_norm": 1.0601085424423218,
      "learning_rate": 0.0001784562270518342,
      "loss": 1.4767,
      "step": 1580
    },
    {
      "epoch": 0.0641478224033244,
      "grad_norm": 0.8752143979072571,
      "learning_rate": 0.00017841937116024975,
      "loss": 1.3498,
      "step": 1590
    },
    {
      "epoch": 0.06455126782724467,
      "grad_norm": 0.8710609078407288,
      "learning_rate": 0.00017838251526866531,
      "loss": 1.288,
      "step": 1600
    },
    {
      "epoch": 0.06455126782724467,
      "eval_loss": 1.3102253675460815,
      "eval_runtime": 14.5573,
      "eval_samples_per_second": 3.435,
      "eval_steps_per_second": 1.717,
      "step": 1600
    },
    {
      "epoch": 0.06495471325116495,
      "grad_norm": 0.8719134330749512,
      "learning_rate": 0.0001783456593770809,
      "loss": 1.409,
      "step": 1610
    },
    {
      "epoch": 0.06535815867508522,
      "grad_norm": 0.8582799434661865,
      "learning_rate": 0.00017830880348549647,
      "loss": 1.2893,
      "step": 1620
    },
    {
      "epoch": 0.06576160409900551,
      "grad_norm": 1.3580862283706665,
      "learning_rate": 0.000178271947593912,
      "loss": 1.2454,
      "step": 1630
    },
    {
      "epoch": 0.06616504952292579,
      "grad_norm": 0.7439702153205872,
      "learning_rate": 0.00017823509170232757,
      "loss": 1.5262,
      "step": 1640
    },
    {
      "epoch": 0.06656849494684607,
      "grad_norm": 0.9795427322387695,
      "learning_rate": 0.00017819823581074316,
      "loss": 1.3439,
      "step": 1650
    },
    {
      "epoch": 0.06697194037076634,
      "grad_norm": 1.0355664491653442,
      "learning_rate": 0.00017816137991915872,
      "loss": 1.2479,
      "step": 1660
    },
    {
      "epoch": 0.06737538579468662,
      "grad_norm": 1.4072513580322266,
      "learning_rate": 0.00017812452402757428,
      "loss": 1.2561,
      "step": 1670
    },
    {
      "epoch": 0.06777883121860691,
      "grad_norm": 0.9081989526748657,
      "learning_rate": 0.00017808766813598984,
      "loss": 1.2829,
      "step": 1680
    },
    {
      "epoch": 0.06818227664252718,
      "grad_norm": 1.0149180889129639,
      "learning_rate": 0.0001780508122444054,
      "loss": 1.3698,
      "step": 1690
    },
    {
      "epoch": 0.06858572206644746,
      "grad_norm": 1.0749878883361816,
      "learning_rate": 0.00017801395635282097,
      "loss": 1.2119,
      "step": 1700
    },
    {
      "epoch": 0.06898916749036774,
      "grad_norm": 0.7773149013519287,
      "learning_rate": 0.00017797710046123653,
      "loss": 1.3267,
      "step": 1710
    },
    {
      "epoch": 0.06939261291428803,
      "grad_norm": 1.0880305767059326,
      "learning_rate": 0.0001779402445696521,
      "loss": 1.3112,
      "step": 1720
    },
    {
      "epoch": 0.0697960583382083,
      "grad_norm": 0.9777073860168457,
      "learning_rate": 0.00017790338867806768,
      "loss": 1.2306,
      "step": 1730
    },
    {
      "epoch": 0.07019950376212858,
      "grad_norm": 0.8514275550842285,
      "learning_rate": 0.00017786653278648325,
      "loss": 1.382,
      "step": 1740
    },
    {
      "epoch": 0.07060294918604886,
      "grad_norm": 0.7119027972221375,
      "learning_rate": 0.0001778296768948988,
      "loss": 1.4093,
      "step": 1750
    },
    {
      "epoch": 0.07100639460996913,
      "grad_norm": 1.1171194314956665,
      "learning_rate": 0.00017779282100331435,
      "loss": 1.3035,
      "step": 1760
    },
    {
      "epoch": 0.07140984003388942,
      "grad_norm": 1.4123194217681885,
      "learning_rate": 0.00017775596511172994,
      "loss": 1.4676,
      "step": 1770
    },
    {
      "epoch": 0.0718132854578097,
      "grad_norm": 0.8812827467918396,
      "learning_rate": 0.0001777191092201455,
      "loss": 1.3652,
      "step": 1780
    },
    {
      "epoch": 0.07221673088172997,
      "grad_norm": 0.8904091715812683,
      "learning_rate": 0.00017768225332856106,
      "loss": 1.4323,
      "step": 1790
    },
    {
      "epoch": 0.07262017630565025,
      "grad_norm": 0.7566947340965271,
      "learning_rate": 0.00017764539743697662,
      "loss": 1.1938,
      "step": 1800
    },
    {
      "epoch": 0.07262017630565025,
      "eval_loss": 1.3112660646438599,
      "eval_runtime": 14.564,
      "eval_samples_per_second": 3.433,
      "eval_steps_per_second": 1.717,
      "step": 1800
    },
    {
      "epoch": 0.07302362172957053,
      "grad_norm": 1.4394339323043823,
      "learning_rate": 0.00017760854154539219,
      "loss": 1.2465,
      "step": 1810
    },
    {
      "epoch": 0.07342706715349082,
      "grad_norm": 1.3682196140289307,
      "learning_rate": 0.00017757168565380775,
      "loss": 1.2403,
      "step": 1820
    },
    {
      "epoch": 0.07383051257741109,
      "grad_norm": 0.9286985397338867,
      "learning_rate": 0.0001775348297622233,
      "loss": 1.3689,
      "step": 1830
    },
    {
      "epoch": 0.07423395800133137,
      "grad_norm": 1.3031522035598755,
      "learning_rate": 0.00017749797387063887,
      "loss": 1.3547,
      "step": 1840
    },
    {
      "epoch": 0.07463740342525164,
      "grad_norm": 0.817374050617218,
      "learning_rate": 0.00017746111797905446,
      "loss": 1.1728,
      "step": 1850
    },
    {
      "epoch": 0.07504084884917193,
      "grad_norm": 0.8632168769836426,
      "learning_rate": 0.00017742426208747003,
      "loss": 1.2045,
      "step": 1860
    },
    {
      "epoch": 0.07544429427309221,
      "grad_norm": 1.0438134670257568,
      "learning_rate": 0.0001773874061958856,
      "loss": 1.2352,
      "step": 1870
    },
    {
      "epoch": 0.07584773969701249,
      "grad_norm": 1.3374994993209839,
      "learning_rate": 0.00017735055030430113,
      "loss": 1.4754,
      "step": 1880
    },
    {
      "epoch": 0.07625118512093276,
      "grad_norm": 1.4636204242706299,
      "learning_rate": 0.00017731369441271672,
      "loss": 1.3573,
      "step": 1890
    },
    {
      "epoch": 0.07665463054485304,
      "grad_norm": 0.7475707530975342,
      "learning_rate": 0.00017727683852113228,
      "loss": 1.3371,
      "step": 1900
    },
    {
      "epoch": 0.07705807596877333,
      "grad_norm": 1.1266412734985352,
      "learning_rate": 0.00017723998262954784,
      "loss": 1.4164,
      "step": 1910
    },
    {
      "epoch": 0.0774615213926936,
      "grad_norm": 0.6547154784202576,
      "learning_rate": 0.0001772031267379634,
      "loss": 1.1529,
      "step": 1920
    },
    {
      "epoch": 0.07786496681661388,
      "grad_norm": 1.1409133672714233,
      "learning_rate": 0.00017716627084637897,
      "loss": 1.4181,
      "step": 1930
    },
    {
      "epoch": 0.07826841224053416,
      "grad_norm": 1.565811038017273,
      "learning_rate": 0.00017712941495479453,
      "loss": 1.4061,
      "step": 1940
    },
    {
      "epoch": 0.07867185766445445,
      "grad_norm": 0.9453374743461609,
      "learning_rate": 0.0001770925590632101,
      "loss": 1.2838,
      "step": 1950
    },
    {
      "epoch": 0.07907530308837472,
      "grad_norm": 1.2905728816986084,
      "learning_rate": 0.00017705570317162565,
      "loss": 1.5289,
      "step": 1960
    },
    {
      "epoch": 0.079478748512295,
      "grad_norm": 0.9038769602775574,
      "learning_rate": 0.00017701884728004124,
      "loss": 1.467,
      "step": 1970
    },
    {
      "epoch": 0.07988219393621528,
      "grad_norm": 1.1189488172531128,
      "learning_rate": 0.0001769819913884568,
      "loss": 1.184,
      "step": 1980
    },
    {
      "epoch": 0.08028563936013555,
      "grad_norm": 1.6057833433151245,
      "learning_rate": 0.00017694513549687237,
      "loss": 1.3729,
      "step": 1990
    },
    {
      "epoch": 0.08068908478405584,
      "grad_norm": 1.1765217781066895,
      "learning_rate": 0.0001769082796052879,
      "loss": 1.3761,
      "step": 2000
    },
    {
      "epoch": 0.08068908478405584,
      "eval_loss": 1.3069943189620972,
      "eval_runtime": 14.5722,
      "eval_samples_per_second": 3.431,
      "eval_steps_per_second": 1.716,
      "step": 2000
    },
    {
      "epoch": 0.08109253020797612,
      "grad_norm": 0.9716706275939941,
      "learning_rate": 0.0001768714237137035,
      "loss": 1.4019,
      "step": 2010
    },
    {
      "epoch": 0.0814959756318964,
      "grad_norm": 0.9578578472137451,
      "learning_rate": 0.00017683456782211906,
      "loss": 1.3034,
      "step": 2020
    },
    {
      "epoch": 0.08189942105581667,
      "grad_norm": 1.0761141777038574,
      "learning_rate": 0.00017679771193053462,
      "loss": 1.5586,
      "step": 2030
    },
    {
      "epoch": 0.08230286647973695,
      "grad_norm": 1.5008403062820435,
      "learning_rate": 0.00017676085603895018,
      "loss": 1.3951,
      "step": 2040
    },
    {
      "epoch": 0.08270631190365724,
      "grad_norm": 0.7480542659759521,
      "learning_rate": 0.00017672400014736575,
      "loss": 1.3712,
      "step": 2050
    },
    {
      "epoch": 0.08310975732757751,
      "grad_norm": 1.4420270919799805,
      "learning_rate": 0.0001766871442557813,
      "loss": 1.5116,
      "step": 2060
    },
    {
      "epoch": 0.08351320275149779,
      "grad_norm": 1.126407265663147,
      "learning_rate": 0.00017665028836419687,
      "loss": 1.3007,
      "step": 2070
    },
    {
      "epoch": 0.08391664817541807,
      "grad_norm": 1.0838221311569214,
      "learning_rate": 0.00017661343247261243,
      "loss": 1.5621,
      "step": 2080
    },
    {
      "epoch": 0.08432009359933836,
      "grad_norm": 0.8087521195411682,
      "learning_rate": 0.00017657657658102802,
      "loss": 1.3477,
      "step": 2090
    },
    {
      "epoch": 0.08472353902325863,
      "grad_norm": 1.4220836162567139,
      "learning_rate": 0.0001765397206894436,
      "loss": 1.143,
      "step": 2100
    },
    {
      "epoch": 0.08512698444717891,
      "grad_norm": 0.9762405157089233,
      "learning_rate": 0.00017650286479785915,
      "loss": 1.1787,
      "step": 2110
    },
    {
      "epoch": 0.08553042987109918,
      "grad_norm": 1.1167256832122803,
      "learning_rate": 0.0001764660089062747,
      "loss": 1.3976,
      "step": 2120
    },
    {
      "epoch": 0.08593387529501946,
      "grad_norm": 0.8187076449394226,
      "learning_rate": 0.00017642915301469027,
      "loss": 1.2034,
      "step": 2130
    },
    {
      "epoch": 0.08633732071893975,
      "grad_norm": 0.8897579908370972,
      "learning_rate": 0.00017639229712310584,
      "loss": 1.3392,
      "step": 2140
    },
    {
      "epoch": 0.08674076614286003,
      "grad_norm": 0.9554995894432068,
      "learning_rate": 0.0001763554412315214,
      "loss": 1.2171,
      "step": 2150
    },
    {
      "epoch": 0.0871442115667803,
      "grad_norm": 1.0696988105773926,
      "learning_rate": 0.00017631858533993696,
      "loss": 1.392,
      "step": 2160
    },
    {
      "epoch": 0.08754765699070058,
      "grad_norm": 1.8448208570480347,
      "learning_rate": 0.00017628172944835255,
      "loss": 1.4354,
      "step": 2170
    },
    {
      "epoch": 0.08795110241462087,
      "grad_norm": 0.9281290173530579,
      "learning_rate": 0.0001762448735567681,
      "loss": 1.3279,
      "step": 2180
    },
    {
      "epoch": 0.08835454783854114,
      "grad_norm": 0.7638074159622192,
      "learning_rate": 0.00017620801766518365,
      "loss": 1.4745,
      "step": 2190
    },
    {
      "epoch": 0.08875799326246142,
      "grad_norm": 1.039916753768921,
      "learning_rate": 0.00017617116177359921,
      "loss": 1.3656,
      "step": 2200
    },
    {
      "epoch": 0.08875799326246142,
      "eval_loss": 1.3093922138214111,
      "eval_runtime": 14.5863,
      "eval_samples_per_second": 3.428,
      "eval_steps_per_second": 1.714,
      "step": 2200
    },
    {
      "epoch": 0.0891614386863817,
      "grad_norm": 1.049759030342102,
      "learning_rate": 0.0001761343058820148,
      "loss": 1.1307,
      "step": 2210
    },
    {
      "epoch": 0.08956488411030197,
      "grad_norm": 0.9090353846549988,
      "learning_rate": 0.00017609744999043037,
      "loss": 1.274,
      "step": 2220
    },
    {
      "epoch": 0.08996832953422226,
      "grad_norm": 0.9087158441543579,
      "learning_rate": 0.00017606059409884593,
      "loss": 1.3333,
      "step": 2230
    },
    {
      "epoch": 0.09037177495814254,
      "grad_norm": 1.2655062675476074,
      "learning_rate": 0.0001760237382072615,
      "loss": 1.262,
      "step": 2240
    },
    {
      "epoch": 0.09077522038206282,
      "grad_norm": 1.5695186853408813,
      "learning_rate": 0.00017598688231567705,
      "loss": 1.4623,
      "step": 2250
    },
    {
      "epoch": 0.09117866580598309,
      "grad_norm": 0.9376614093780518,
      "learning_rate": 0.00017595002642409262,
      "loss": 1.3314,
      "step": 2260
    },
    {
      "epoch": 0.09158211122990337,
      "grad_norm": 1.257711410522461,
      "learning_rate": 0.00017591317053250818,
      "loss": 1.2169,
      "step": 2270
    },
    {
      "epoch": 0.09198555665382366,
      "grad_norm": 0.7908757328987122,
      "learning_rate": 0.00017587631464092374,
      "loss": 1.1201,
      "step": 2280
    },
    {
      "epoch": 0.09238900207774393,
      "grad_norm": 0.7993413805961609,
      "learning_rate": 0.00017583945874933933,
      "loss": 1.181,
      "step": 2290
    },
    {
      "epoch": 0.09279244750166421,
      "grad_norm": 1.041905403137207,
      "learning_rate": 0.00017580260285775487,
      "loss": 1.2417,
      "step": 2300
    },
    {
      "epoch": 0.09319589292558449,
      "grad_norm": 0.9548014998435974,
      "learning_rate": 0.00017576574696617043,
      "loss": 1.2076,
      "step": 2310
    },
    {
      "epoch": 0.09359933834950478,
      "grad_norm": 1.4998974800109863,
      "learning_rate": 0.000175728891074586,
      "loss": 1.3807,
      "step": 2320
    },
    {
      "epoch": 0.09400278377342505,
      "grad_norm": 1.4191608428955078,
      "learning_rate": 0.00017569203518300158,
      "loss": 1.3414,
      "step": 2330
    },
    {
      "epoch": 0.09440622919734533,
      "grad_norm": 1.0042232275009155,
      "learning_rate": 0.00017565517929141715,
      "loss": 1.217,
      "step": 2340
    },
    {
      "epoch": 0.0948096746212656,
      "grad_norm": 1.2971619367599487,
      "learning_rate": 0.0001756183233998327,
      "loss": 1.3087,
      "step": 2350
    },
    {
      "epoch": 0.09521312004518588,
      "grad_norm": 0.6462915539741516,
      "learning_rate": 0.00017558146750824827,
      "loss": 1.3407,
      "step": 2360
    },
    {
      "epoch": 0.09561656546910617,
      "grad_norm": 1.1617203950881958,
      "learning_rate": 0.00017554461161666383,
      "loss": 1.3647,
      "step": 2370
    },
    {
      "epoch": 0.09602001089302645,
      "grad_norm": 0.8952522277832031,
      "learning_rate": 0.0001755077557250794,
      "loss": 1.3284,
      "step": 2380
    },
    {
      "epoch": 0.09642345631694672,
      "grad_norm": 1.1600202322006226,
      "learning_rate": 0.00017547089983349496,
      "loss": 1.3368,
      "step": 2390
    },
    {
      "epoch": 0.096826901740867,
      "grad_norm": 0.8903072476387024,
      "learning_rate": 0.00017543404394191052,
      "loss": 1.4296,
      "step": 2400
    },
    {
      "epoch": 0.096826901740867,
      "eval_loss": 1.3109619617462158,
      "eval_runtime": 14.5841,
      "eval_samples_per_second": 3.428,
      "eval_steps_per_second": 1.714,
      "step": 2400
    },
    {
      "epoch": 0.09723034716478729,
      "grad_norm": 1.1514277458190918,
      "learning_rate": 0.0001753971880503261,
      "loss": 1.5496,
      "step": 2410
    },
    {
      "epoch": 0.09763379258870757,
      "grad_norm": 1.0383639335632324,
      "learning_rate": 0.00017536033215874165,
      "loss": 1.4113,
      "step": 2420
    },
    {
      "epoch": 0.09803723801262784,
      "grad_norm": 0.8851528167724609,
      "learning_rate": 0.0001753234762671572,
      "loss": 1.393,
      "step": 2430
    },
    {
      "epoch": 0.09844068343654812,
      "grad_norm": 1.252003788948059,
      "learning_rate": 0.00017528662037557277,
      "loss": 1.3653,
      "step": 2440
    },
    {
      "epoch": 0.0988441288604684,
      "grad_norm": 0.8052831292152405,
      "learning_rate": 0.00017524976448398836,
      "loss": 1.4535,
      "step": 2450
    },
    {
      "epoch": 0.09924757428438868,
      "grad_norm": 2.067479133605957,
      "learning_rate": 0.00017521290859240393,
      "loss": 1.3159,
      "step": 2460
    },
    {
      "epoch": 0.09965101970830896,
      "grad_norm": 1.378170132637024,
      "learning_rate": 0.0001751760527008195,
      "loss": 1.3955,
      "step": 2470
    },
    {
      "epoch": 0.10005446513222924,
      "grad_norm": 1.270764946937561,
      "learning_rate": 0.00017513919680923505,
      "loss": 1.3542,
      "step": 2480
    },
    {
      "epoch": 0.10045791055614951,
      "grad_norm": 1.3947402238845825,
      "learning_rate": 0.00017510234091765061,
      "loss": 1.4185,
      "step": 2490
    },
    {
      "epoch": 0.1008613559800698,
      "grad_norm": 0.9264646172523499,
      "learning_rate": 0.00017506548502606618,
      "loss": 1.3315,
      "step": 2500
    },
    {
      "epoch": 0.10126480140399008,
      "grad_norm": 0.8945112228393555,
      "learning_rate": 0.00017502862913448174,
      "loss": 1.2499,
      "step": 2510
    },
    {
      "epoch": 0.10166824682791036,
      "grad_norm": 1.2858988046646118,
      "learning_rate": 0.0001749917732428973,
      "loss": 1.381,
      "step": 2520
    },
    {
      "epoch": 0.10207169225183063,
      "grad_norm": 1.461234211921692,
      "learning_rate": 0.0001749549173513129,
      "loss": 1.301,
      "step": 2530
    },
    {
      "epoch": 0.10247513767575091,
      "grad_norm": 0.9196884632110596,
      "learning_rate": 0.00017491806145972846,
      "loss": 1.4012,
      "step": 2540
    },
    {
      "epoch": 0.1028785830996712,
      "grad_norm": 0.9534275531768799,
      "learning_rate": 0.000174881205568144,
      "loss": 1.2979,
      "step": 2550
    },
    {
      "epoch": 0.10328202852359147,
      "grad_norm": 0.8598957061767578,
      "learning_rate": 0.00017484434967655955,
      "loss": 1.3072,
      "step": 2560
    },
    {
      "epoch": 0.10368547394751175,
      "grad_norm": 1.4821125268936157,
      "learning_rate": 0.00017480749378497512,
      "loss": 1.2594,
      "step": 2570
    },
    {
      "epoch": 0.10408891937143203,
      "grad_norm": 1.0811930894851685,
      "learning_rate": 0.0001747706378933907,
      "loss": 1.2334,
      "step": 2580
    },
    {
      "epoch": 0.1044923647953523,
      "grad_norm": 1.0813777446746826,
      "learning_rate": 0.00017473378200180627,
      "loss": 1.2551,
      "step": 2590
    },
    {
      "epoch": 0.10489581021927259,
      "grad_norm": 1.5601297616958618,
      "learning_rate": 0.00017469692611022183,
      "loss": 1.2967,
      "step": 2600
    },
    {
      "epoch": 0.10489581021927259,
      "eval_loss": 1.306868553161621,
      "eval_runtime": 14.5676,
      "eval_samples_per_second": 3.432,
      "eval_steps_per_second": 1.716,
      "step": 2600
    },
    {
      "epoch": 0.10529925564319287,
      "grad_norm": 1.0700459480285645,
      "learning_rate": 0.0001746600702186374,
      "loss": 1.2746,
      "step": 2610
    },
    {
      "epoch": 0.10570270106711314,
      "grad_norm": 1.0675718784332275,
      "learning_rate": 0.00017462321432705296,
      "loss": 1.2073,
      "step": 2620
    },
    {
      "epoch": 0.10610614649103342,
      "grad_norm": 0.9565584063529968,
      "learning_rate": 0.00017458635843546852,
      "loss": 1.6759,
      "step": 2630
    },
    {
      "epoch": 0.10650959191495371,
      "grad_norm": 1.106764554977417,
      "learning_rate": 0.00017454950254388408,
      "loss": 1.2217,
      "step": 2640
    },
    {
      "epoch": 0.10691303733887399,
      "grad_norm": 0.9549259543418884,
      "learning_rate": 0.00017451264665229965,
      "loss": 1.3614,
      "step": 2650
    },
    {
      "epoch": 0.10731648276279426,
      "grad_norm": 0.8518237471580505,
      "learning_rate": 0.00017447579076071523,
      "loss": 1.298,
      "step": 2660
    },
    {
      "epoch": 0.10771992818671454,
      "grad_norm": 1.4174751043319702,
      "learning_rate": 0.00017443893486913077,
      "loss": 1.4229,
      "step": 2670
    },
    {
      "epoch": 0.10812337361063482,
      "grad_norm": 0.7786015272140503,
      "learning_rate": 0.00017440207897754633,
      "loss": 1.2338,
      "step": 2680
    },
    {
      "epoch": 0.1085268190345551,
      "grad_norm": 2.017829418182373,
      "learning_rate": 0.0001743652230859619,
      "loss": 1.422,
      "step": 2690
    },
    {
      "epoch": 0.10893026445847538,
      "grad_norm": 1.4875199794769287,
      "learning_rate": 0.00017432836719437749,
      "loss": 1.197,
      "step": 2700
    },
    {
      "epoch": 0.10933370988239566,
      "grad_norm": 1.4029189348220825,
      "learning_rate": 0.00017429151130279305,
      "loss": 1.3962,
      "step": 2710
    },
    {
      "epoch": 0.10973715530631593,
      "grad_norm": 1.6307462453842163,
      "learning_rate": 0.0001742546554112086,
      "loss": 1.33,
      "step": 2720
    },
    {
      "epoch": 0.11014060073023622,
      "grad_norm": 1.644643783569336,
      "learning_rate": 0.00017421779951962417,
      "loss": 1.2463,
      "step": 2730
    },
    {
      "epoch": 0.1105440461541565,
      "grad_norm": 1.067626953125,
      "learning_rate": 0.00017418094362803974,
      "loss": 1.2828,
      "step": 2740
    },
    {
      "epoch": 0.11094749157807678,
      "grad_norm": 0.8628644943237305,
      "learning_rate": 0.0001741440877364553,
      "loss": 1.3633,
      "step": 2750
    },
    {
      "epoch": 0.11135093700199705,
      "grad_norm": 0.8177421689033508,
      "learning_rate": 0.00017410723184487086,
      "loss": 1.1981,
      "step": 2760
    },
    {
      "epoch": 0.11175438242591733,
      "grad_norm": 1.2667547464370728,
      "learning_rate": 0.00017407037595328642,
      "loss": 1.2702,
      "step": 2770
    },
    {
      "epoch": 0.11215782784983762,
      "grad_norm": 0.92191481590271,
      "learning_rate": 0.00017403352006170201,
      "loss": 1.2322,
      "step": 2780
    },
    {
      "epoch": 0.1125612732737579,
      "grad_norm": 1.1652328968048096,
      "learning_rate": 0.00017399666417011755,
      "loss": 1.5278,
      "step": 2790
    },
    {
      "epoch": 0.11296471869767817,
      "grad_norm": 1.6356217861175537,
      "learning_rate": 0.0001739598082785331,
      "loss": 1.3417,
      "step": 2800
    },
    {
      "epoch": 0.11296471869767817,
      "eval_loss": 1.3149611949920654,
      "eval_runtime": 14.5768,
      "eval_samples_per_second": 3.43,
      "eval_steps_per_second": 1.715,
      "step": 2800
    },
    {
      "epoch": 0.11336816412159845,
      "grad_norm": 1.3110218048095703,
      "learning_rate": 0.00017392295238694868,
      "loss": 1.4809,
      "step": 2810
    },
    {
      "epoch": 0.11377160954551872,
      "grad_norm": 0.9952992796897888,
      "learning_rate": 0.00017388609649536427,
      "loss": 1.2754,
      "step": 2820
    },
    {
      "epoch": 0.11417505496943901,
      "grad_norm": 1.1902095079421997,
      "learning_rate": 0.00017384924060377983,
      "loss": 1.3287,
      "step": 2830
    },
    {
      "epoch": 0.11457850039335929,
      "grad_norm": 1.0786422491073608,
      "learning_rate": 0.0001738123847121954,
      "loss": 1.3812,
      "step": 2840
    },
    {
      "epoch": 0.11498194581727957,
      "grad_norm": 1.072594404220581,
      "learning_rate": 0.00017377552882061095,
      "loss": 1.331,
      "step": 2850
    },
    {
      "epoch": 0.11538539124119984,
      "grad_norm": 1.0667221546173096,
      "learning_rate": 0.00017373867292902652,
      "loss": 1.3165,
      "step": 2860
    },
    {
      "epoch": 0.11578883666512013,
      "grad_norm": 1.1736279726028442,
      "learning_rate": 0.00017370181703744208,
      "loss": 1.3067,
      "step": 2870
    },
    {
      "epoch": 0.11619228208904041,
      "grad_norm": 0.8009106516838074,
      "learning_rate": 0.00017366496114585764,
      "loss": 1.4849,
      "step": 2880
    },
    {
      "epoch": 0.11659572751296068,
      "grad_norm": 0.9988465309143066,
      "learning_rate": 0.0001736281052542732,
      "loss": 1.3195,
      "step": 2890
    },
    {
      "epoch": 0.11699917293688096,
      "grad_norm": 1.100365161895752,
      "learning_rate": 0.0001735912493626888,
      "loss": 1.3673,
      "step": 2900
    },
    {
      "epoch": 0.11740261836080124,
      "grad_norm": 0.8734198212623596,
      "learning_rate": 0.00017355439347110436,
      "loss": 1.3389,
      "step": 2910
    },
    {
      "epoch": 0.11780606378472153,
      "grad_norm": 0.8583125472068787,
      "learning_rate": 0.0001735175375795199,
      "loss": 1.2207,
      "step": 2920
    },
    {
      "epoch": 0.1182095092086418,
      "grad_norm": 1.3765695095062256,
      "learning_rate": 0.00017348068168793546,
      "loss": 1.2352,
      "step": 2930
    },
    {
      "epoch": 0.11861295463256208,
      "grad_norm": 1.3412123918533325,
      "learning_rate": 0.00017344382579635105,
      "loss": 1.4331,
      "step": 2940
    },
    {
      "epoch": 0.11901640005648235,
      "grad_norm": 1.0824732780456543,
      "learning_rate": 0.0001734069699047666,
      "loss": 1.4522,
      "step": 2950
    },
    {
      "epoch": 0.11941984548040264,
      "grad_norm": 2.774794101715088,
      "learning_rate": 0.00017337011401318217,
      "loss": 1.3978,
      "step": 2960
    },
    {
      "epoch": 0.11982329090432292,
      "grad_norm": 1.0206584930419922,
      "learning_rate": 0.00017333325812159773,
      "loss": 1.2579,
      "step": 2970
    },
    {
      "epoch": 0.1202267363282432,
      "grad_norm": 1.1135812997817993,
      "learning_rate": 0.0001732964022300133,
      "loss": 1.342,
      "step": 2980
    },
    {
      "epoch": 0.12063018175216347,
      "grad_norm": 1.252661943435669,
      "learning_rate": 0.00017325954633842886,
      "loss": 1.483,
      "step": 2990
    },
    {
      "epoch": 0.12103362717608375,
      "grad_norm": 0.851007342338562,
      "learning_rate": 0.00017322269044684442,
      "loss": 1.061,
      "step": 3000
    },
    {
      "epoch": 0.12103362717608375,
      "eval_loss": 1.312267780303955,
      "eval_runtime": 14.5688,
      "eval_samples_per_second": 3.432,
      "eval_steps_per_second": 1.716,
      "step": 3000
    },
    {
      "epoch": 0.12143707260000404,
      "grad_norm": 0.9588618874549866,
      "learning_rate": 0.00017318583455525998,
      "loss": 1.6047,
      "step": 3010
    },
    {
      "epoch": 0.12184051802392432,
      "grad_norm": 1.7698626518249512,
      "learning_rate": 0.00017314897866367557,
      "loss": 1.36,
      "step": 3020
    },
    {
      "epoch": 0.12224396344784459,
      "grad_norm": 1.1273585557937622,
      "learning_rate": 0.00017311212277209114,
      "loss": 1.273,
      "step": 3030
    },
    {
      "epoch": 0.12264740887176487,
      "grad_norm": 0.8752007484436035,
      "learning_rate": 0.00017307526688050667,
      "loss": 1.4271,
      "step": 3040
    },
    {
      "epoch": 0.12305085429568516,
      "grad_norm": 0.898584246635437,
      "learning_rate": 0.00017303841098892224,
      "loss": 1.3564,
      "step": 3050
    },
    {
      "epoch": 0.12345429971960543,
      "grad_norm": 1.0552831888198853,
      "learning_rate": 0.00017300155509733783,
      "loss": 1.3779,
      "step": 3060
    },
    {
      "epoch": 0.12385774514352571,
      "grad_norm": 1.2064106464385986,
      "learning_rate": 0.0001729646992057534,
      "loss": 1.4972,
      "step": 3070
    },
    {
      "epoch": 0.12426119056744599,
      "grad_norm": 1.0197341442108154,
      "learning_rate": 0.00017292784331416895,
      "loss": 1.2001,
      "step": 3080
    },
    {
      "epoch": 0.12466463599136626,
      "grad_norm": 1.1223243474960327,
      "learning_rate": 0.0001728909874225845,
      "loss": 1.2818,
      "step": 3090
    },
    {
      "epoch": 0.12506808141528655,
      "grad_norm": 1.0987987518310547,
      "learning_rate": 0.00017285413153100008,
      "loss": 1.3271,
      "step": 3100
    },
    {
      "epoch": 0.12547152683920682,
      "grad_norm": 1.1303441524505615,
      "learning_rate": 0.00017281727563941564,
      "loss": 1.2102,
      "step": 3110
    },
    {
      "epoch": 0.1258749722631271,
      "grad_norm": 0.9711422920227051,
      "learning_rate": 0.0001727804197478312,
      "loss": 1.2321,
      "step": 3120
    },
    {
      "epoch": 0.1262784176870474,
      "grad_norm": 3.5264477729797363,
      "learning_rate": 0.00017274356385624676,
      "loss": 1.3474,
      "step": 3130
    },
    {
      "epoch": 0.12668186311096766,
      "grad_norm": 1.105570912361145,
      "learning_rate": 0.00017270670796466235,
      "loss": 1.4005,
      "step": 3140
    },
    {
      "epoch": 0.12708530853488795,
      "grad_norm": 0.9090680480003357,
      "learning_rate": 0.00017266985207307792,
      "loss": 1.3709,
      "step": 3150
    },
    {
      "epoch": 0.1274887539588082,
      "grad_norm": 0.8852123618125916,
      "learning_rate": 0.00017263299618149345,
      "loss": 1.0915,
      "step": 3160
    },
    {
      "epoch": 0.1278921993827285,
      "grad_norm": 1.1605708599090576,
      "learning_rate": 0.00017259614028990902,
      "loss": 1.3248,
      "step": 3170
    },
    {
      "epoch": 0.1282956448066488,
      "grad_norm": 0.9615469574928284,
      "learning_rate": 0.0001725592843983246,
      "loss": 1.2311,
      "step": 3180
    },
    {
      "epoch": 0.12869909023056905,
      "grad_norm": 0.9555561542510986,
      "learning_rate": 0.00017252242850674017,
      "loss": 1.4377,
      "step": 3190
    },
    {
      "epoch": 0.12910253565448934,
      "grad_norm": 1.2773146629333496,
      "learning_rate": 0.00017248557261515573,
      "loss": 1.3211,
      "step": 3200
    },
    {
      "epoch": 0.12910253565448934,
      "eval_loss": 1.305066704750061,
      "eval_runtime": 14.5995,
      "eval_samples_per_second": 3.425,
      "eval_steps_per_second": 1.712,
      "step": 3200
    },
    {
      "epoch": 0.1295059810784096,
      "grad_norm": 0.9613035917282104,
      "learning_rate": 0.0001724487167235713,
      "loss": 1.5829,
      "step": 3210
    },
    {
      "epoch": 0.1299094265023299,
      "grad_norm": 1.3397358655929565,
      "learning_rate": 0.00017241186083198686,
      "loss": 1.3398,
      "step": 3220
    },
    {
      "epoch": 0.13031287192625018,
      "grad_norm": 1.1131796836853027,
      "learning_rate": 0.00017237500494040242,
      "loss": 1.3556,
      "step": 3230
    },
    {
      "epoch": 0.13071631735017045,
      "grad_norm": 0.9549842476844788,
      "learning_rate": 0.00017233814904881798,
      "loss": 1.2089,
      "step": 3240
    },
    {
      "epoch": 0.13111976277409074,
      "grad_norm": 2.129293918609619,
      "learning_rate": 0.00017230129315723354,
      "loss": 1.2812,
      "step": 3250
    },
    {
      "epoch": 0.13152320819801103,
      "grad_norm": 2.0714728832244873,
      "learning_rate": 0.00017226443726564913,
      "loss": 1.3614,
      "step": 3260
    },
    {
      "epoch": 0.1319266536219313,
      "grad_norm": 1.2303529977798462,
      "learning_rate": 0.0001722275813740647,
      "loss": 1.4199,
      "step": 3270
    },
    {
      "epoch": 0.13233009904585158,
      "grad_norm": 1.1587035655975342,
      "learning_rate": 0.00017219072548248026,
      "loss": 1.2123,
      "step": 3280
    },
    {
      "epoch": 0.13273354446977184,
      "grad_norm": 1.187381625175476,
      "learning_rate": 0.0001721538695908958,
      "loss": 1.3348,
      "step": 3290
    },
    {
      "epoch": 0.13313698989369213,
      "grad_norm": 2.040581226348877,
      "learning_rate": 0.00017211701369931138,
      "loss": 1.4478,
      "step": 3300
    },
    {
      "epoch": 0.13354043531761242,
      "grad_norm": 0.9957476854324341,
      "learning_rate": 0.00017208015780772695,
      "loss": 1.314,
      "step": 3310
    },
    {
      "epoch": 0.13394388074153268,
      "grad_norm": 2.13155198097229,
      "learning_rate": 0.0001720433019161425,
      "loss": 1.4107,
      "step": 3320
    },
    {
      "epoch": 0.13434732616545297,
      "grad_norm": 1.2106900215148926,
      "learning_rate": 0.00017200644602455807,
      "loss": 1.388,
      "step": 3330
    },
    {
      "epoch": 0.13475077158937324,
      "grad_norm": 0.9581992030143738,
      "learning_rate": 0.00017196959013297364,
      "loss": 1.2581,
      "step": 3340
    },
    {
      "epoch": 0.13515421701329353,
      "grad_norm": 0.8951935768127441,
      "learning_rate": 0.0001719327342413892,
      "loss": 1.2755,
      "step": 3350
    },
    {
      "epoch": 0.13555766243721382,
      "grad_norm": 1.0096882581710815,
      "learning_rate": 0.00017189587834980476,
      "loss": 1.3481,
      "step": 3360
    },
    {
      "epoch": 0.13596110786113408,
      "grad_norm": 1.2395411729812622,
      "learning_rate": 0.00017185902245822032,
      "loss": 1.3432,
      "step": 3370
    },
    {
      "epoch": 0.13636455328505437,
      "grad_norm": 0.9973400831222534,
      "learning_rate": 0.00017182216656663591,
      "loss": 1.2592,
      "step": 3380
    },
    {
      "epoch": 0.13676799870897463,
      "grad_norm": 0.7808886766433716,
      "learning_rate": 0.00017178531067505148,
      "loss": 1.2149,
      "step": 3390
    },
    {
      "epoch": 0.13717144413289492,
      "grad_norm": 1.1635491847991943,
      "learning_rate": 0.00017174845478346704,
      "loss": 1.2423,
      "step": 3400
    },
    {
      "epoch": 0.13717144413289492,
      "eval_loss": 1.3058998584747314,
      "eval_runtime": 14.5828,
      "eval_samples_per_second": 3.429,
      "eval_steps_per_second": 1.714,
      "step": 3400
    },
    {
      "epoch": 0.1375748895568152,
      "grad_norm": 1.4361042976379395,
      "learning_rate": 0.00017171159889188257,
      "loss": 1.2974,
      "step": 3410
    },
    {
      "epoch": 0.13797833498073547,
      "grad_norm": 1.1151875257492065,
      "learning_rate": 0.00017167474300029816,
      "loss": 1.3192,
      "step": 3420
    },
    {
      "epoch": 0.13838178040465576,
      "grad_norm": 1.2052732706069946,
      "learning_rate": 0.00017163788710871373,
      "loss": 1.3996,
      "step": 3430
    },
    {
      "epoch": 0.13878522582857605,
      "grad_norm": 1.0848804712295532,
      "learning_rate": 0.0001716010312171293,
      "loss": 1.4423,
      "step": 3440
    },
    {
      "epoch": 0.13918867125249632,
      "grad_norm": 1.0929450988769531,
      "learning_rate": 0.00017156417532554485,
      "loss": 1.3552,
      "step": 3450
    },
    {
      "epoch": 0.1395921166764166,
      "grad_norm": 1.7015883922576904,
      "learning_rate": 0.00017152731943396042,
      "loss": 1.3742,
      "step": 3460
    },
    {
      "epoch": 0.13999556210033687,
      "grad_norm": 1.2085111141204834,
      "learning_rate": 0.00017149046354237598,
      "loss": 1.3757,
      "step": 3470
    },
    {
      "epoch": 0.14039900752425716,
      "grad_norm": 1.0457789897918701,
      "learning_rate": 0.00017145360765079154,
      "loss": 1.2534,
      "step": 3480
    },
    {
      "epoch": 0.14080245294817745,
      "grad_norm": 1.262116551399231,
      "learning_rate": 0.0001714167517592071,
      "loss": 1.2026,
      "step": 3490
    },
    {
      "epoch": 0.1412058983720977,
      "grad_norm": 1.2787901163101196,
      "learning_rate": 0.0001713798958676227,
      "loss": 1.3724,
      "step": 3500
    },
    {
      "epoch": 0.141609343796018,
      "grad_norm": 0.9717180132865906,
      "learning_rate": 0.00017134303997603826,
      "loss": 1.4971,
      "step": 3510
    },
    {
      "epoch": 0.14201278921993826,
      "grad_norm": 1.2881875038146973,
      "learning_rate": 0.00017130618408445382,
      "loss": 1.3184,
      "step": 3520
    },
    {
      "epoch": 0.14241623464385855,
      "grad_norm": 2.2481698989868164,
      "learning_rate": 0.00017126932819286935,
      "loss": 1.2747,
      "step": 3530
    },
    {
      "epoch": 0.14281968006777884,
      "grad_norm": 0.9565686583518982,
      "learning_rate": 0.00017123247230128494,
      "loss": 1.2819,
      "step": 3540
    },
    {
      "epoch": 0.1432231254916991,
      "grad_norm": 0.9990772604942322,
      "learning_rate": 0.0001711956164097005,
      "loss": 1.4111,
      "step": 3550
    },
    {
      "epoch": 0.1436265709156194,
      "grad_norm": 1.0397350788116455,
      "learning_rate": 0.00017115876051811607,
      "loss": 1.4742,
      "step": 3560
    },
    {
      "epoch": 0.14403001633953966,
      "grad_norm": 1.0696839094161987,
      "learning_rate": 0.00017112190462653163,
      "loss": 1.4103,
      "step": 3570
    },
    {
      "epoch": 0.14443346176345995,
      "grad_norm": 1.0399138927459717,
      "learning_rate": 0.0001710850487349472,
      "loss": 1.1838,
      "step": 3580
    },
    {
      "epoch": 0.14483690718738024,
      "grad_norm": 1.0441116094589233,
      "learning_rate": 0.00017104819284336276,
      "loss": 1.3464,
      "step": 3590
    },
    {
      "epoch": 0.1452403526113005,
      "grad_norm": 1.0868221521377563,
      "learning_rate": 0.00017101133695177832,
      "loss": 1.3674,
      "step": 3600
    },
    {
      "epoch": 0.1452403526113005,
      "eval_loss": 1.3034130334854126,
      "eval_runtime": 14.6016,
      "eval_samples_per_second": 3.424,
      "eval_steps_per_second": 1.712,
      "step": 3600
    },
    {
      "epoch": 0.1456437980352208,
      "grad_norm": 0.9668206572532654,
      "learning_rate": 0.00017097448106019388,
      "loss": 1.3686,
      "step": 3610
    },
    {
      "epoch": 0.14604724345914105,
      "grad_norm": 1.226940631866455,
      "learning_rate": 0.00017093762516860947,
      "loss": 1.4192,
      "step": 3620
    },
    {
      "epoch": 0.14645068888306134,
      "grad_norm": 0.9792815446853638,
      "learning_rate": 0.00017090076927702504,
      "loss": 1.3001,
      "step": 3630
    },
    {
      "epoch": 0.14685413430698163,
      "grad_norm": 1.8562318086624146,
      "learning_rate": 0.0001708639133854406,
      "loss": 1.2072,
      "step": 3640
    },
    {
      "epoch": 0.1472575797309019,
      "grad_norm": 1.033068299293518,
      "learning_rate": 0.00017082705749385616,
      "loss": 1.2839,
      "step": 3650
    },
    {
      "epoch": 0.14766102515482218,
      "grad_norm": 1.6660552024841309,
      "learning_rate": 0.00017079020160227172,
      "loss": 1.324,
      "step": 3660
    },
    {
      "epoch": 0.14806447057874247,
      "grad_norm": 1.3776098489761353,
      "learning_rate": 0.0001707533457106873,
      "loss": 1.3619,
      "step": 3670
    },
    {
      "epoch": 0.14846791600266274,
      "grad_norm": 0.9773210287094116,
      "learning_rate": 0.00017071648981910285,
      "loss": 1.432,
      "step": 3680
    },
    {
      "epoch": 0.14887136142658303,
      "grad_norm": 1.2518712282180786,
      "learning_rate": 0.0001706796339275184,
      "loss": 1.509,
      "step": 3690
    },
    {
      "epoch": 0.1492748068505033,
      "grad_norm": 1.4877183437347412,
      "learning_rate": 0.00017064277803593398,
      "loss": 1.2915,
      "step": 3700
    },
    {
      "epoch": 0.14967825227442358,
      "grad_norm": 1.5886911153793335,
      "learning_rate": 0.00017060592214434954,
      "loss": 1.5543,
      "step": 3710
    },
    {
      "epoch": 0.15008169769834387,
      "grad_norm": 1.090306282043457,
      "learning_rate": 0.0001705690662527651,
      "loss": 1.3919,
      "step": 3720
    },
    {
      "epoch": 0.15048514312226413,
      "grad_norm": 1.5582486391067505,
      "learning_rate": 0.00017053221036118066,
      "loss": 1.2652,
      "step": 3730
    },
    {
      "epoch": 0.15088858854618442,
      "grad_norm": 1.3765642642974854,
      "learning_rate": 0.00017049535446959623,
      "loss": 1.4828,
      "step": 3740
    },
    {
      "epoch": 0.15129203397010468,
      "grad_norm": 0.8909485936164856,
      "learning_rate": 0.00017045849857801182,
      "loss": 1.4288,
      "step": 3750
    },
    {
      "epoch": 0.15169547939402497,
      "grad_norm": 1.6998133659362793,
      "learning_rate": 0.00017042164268642738,
      "loss": 1.3569,
      "step": 3760
    },
    {
      "epoch": 0.15209892481794526,
      "grad_norm": 1.3979363441467285,
      "learning_rate": 0.00017038478679484294,
      "loss": 1.4485,
      "step": 3770
    },
    {
      "epoch": 0.15250237024186553,
      "grad_norm": 1.0182441473007202,
      "learning_rate": 0.00017034793090325848,
      "loss": 1.3522,
      "step": 3780
    },
    {
      "epoch": 0.15290581566578582,
      "grad_norm": 1.3812717199325562,
      "learning_rate": 0.00017031107501167407,
      "loss": 1.3737,
      "step": 3790
    },
    {
      "epoch": 0.15330926108970608,
      "grad_norm": 1.0373800992965698,
      "learning_rate": 0.00017027421912008963,
      "loss": 1.3314,
      "step": 3800
    },
    {
      "epoch": 0.15330926108970608,
      "eval_loss": 1.3100062608718872,
      "eval_runtime": 14.5772,
      "eval_samples_per_second": 3.43,
      "eval_steps_per_second": 1.715,
      "step": 3800
    },
    {
      "epoch": 0.15371270651362637,
      "grad_norm": 1.3399207592010498,
      "learning_rate": 0.0001702373632285052,
      "loss": 1.3672,
      "step": 3810
    },
    {
      "epoch": 0.15411615193754666,
      "grad_norm": 1.0844719409942627,
      "learning_rate": 0.00017020050733692076,
      "loss": 1.3568,
      "step": 3820
    },
    {
      "epoch": 0.15451959736146692,
      "grad_norm": 1.117676854133606,
      "learning_rate": 0.00017016365144533632,
      "loss": 1.2827,
      "step": 3830
    },
    {
      "epoch": 0.1549230427853872,
      "grad_norm": 1.855356216430664,
      "learning_rate": 0.00017012679555375188,
      "loss": 1.293,
      "step": 3840
    },
    {
      "epoch": 0.15532648820930747,
      "grad_norm": 0.8143866658210754,
      "learning_rate": 0.00017008993966216744,
      "loss": 1.3775,
      "step": 3850
    },
    {
      "epoch": 0.15572993363322776,
      "grad_norm": 1.1257222890853882,
      "learning_rate": 0.000170053083770583,
      "loss": 1.3045,
      "step": 3860
    },
    {
      "epoch": 0.15613337905714805,
      "grad_norm": 1.4689704179763794,
      "learning_rate": 0.0001700162278789986,
      "loss": 1.3507,
      "step": 3870
    },
    {
      "epoch": 0.15653682448106832,
      "grad_norm": 1.280596137046814,
      "learning_rate": 0.00016997937198741416,
      "loss": 1.3598,
      "step": 3880
    },
    {
      "epoch": 0.1569402699049886,
      "grad_norm": 1.5119003057479858,
      "learning_rate": 0.00016994251609582972,
      "loss": 1.2925,
      "step": 3890
    },
    {
      "epoch": 0.1573437153289089,
      "grad_norm": 1.253999948501587,
      "learning_rate": 0.00016990566020424526,
      "loss": 1.3042,
      "step": 3900
    },
    {
      "epoch": 0.15774716075282916,
      "grad_norm": 1.190528392791748,
      "learning_rate": 0.00016986880431266085,
      "loss": 1.1392,
      "step": 3910
    },
    {
      "epoch": 0.15815060617674945,
      "grad_norm": 1.2014309167861938,
      "learning_rate": 0.0001698319484210764,
      "loss": 1.5015,
      "step": 3920
    },
    {
      "epoch": 0.1585540516006697,
      "grad_norm": 1.6521642208099365,
      "learning_rate": 0.00016979509252949197,
      "loss": 1.2704,
      "step": 3930
    },
    {
      "epoch": 0.15895749702459,
      "grad_norm": 1.1799427270889282,
      "learning_rate": 0.00016975823663790754,
      "loss": 1.2325,
      "step": 3940
    },
    {
      "epoch": 0.1593609424485103,
      "grad_norm": 1.0382519960403442,
      "learning_rate": 0.0001697213807463231,
      "loss": 1.3263,
      "step": 3950
    },
    {
      "epoch": 0.15976438787243055,
      "grad_norm": 1.1051169633865356,
      "learning_rate": 0.00016968452485473866,
      "loss": 1.3341,
      "step": 3960
    },
    {
      "epoch": 0.16016783329635084,
      "grad_norm": 1.677215337753296,
      "learning_rate": 0.00016964766896315422,
      "loss": 1.3931,
      "step": 3970
    },
    {
      "epoch": 0.1605712787202711,
      "grad_norm": 1.1171839237213135,
      "learning_rate": 0.00016961081307156979,
      "loss": 1.3209,
      "step": 3980
    },
    {
      "epoch": 0.1609747241441914,
      "grad_norm": 2.1545400619506836,
      "learning_rate": 0.00016957395717998538,
      "loss": 1.4916,
      "step": 3990
    },
    {
      "epoch": 0.16137816956811168,
      "grad_norm": 1.1570121049880981,
      "learning_rate": 0.00016953710128840094,
      "loss": 1.3144,
      "step": 4000
    },
    {
      "epoch": 0.16137816956811168,
      "eval_loss": 1.308896780014038,
      "eval_runtime": 14.6031,
      "eval_samples_per_second": 3.424,
      "eval_steps_per_second": 1.712,
      "step": 4000
    },
    {
      "epoch": 0.16178161499203195,
      "grad_norm": 1.0833014249801636,
      "learning_rate": 0.0001695002453968165,
      "loss": 1.1942,
      "step": 4010
    },
    {
      "epoch": 0.16218506041595224,
      "grad_norm": 1.140214204788208,
      "learning_rate": 0.00016946338950523206,
      "loss": 1.228,
      "step": 4020
    },
    {
      "epoch": 0.1625885058398725,
      "grad_norm": 1.1539486646652222,
      "learning_rate": 0.00016942653361364763,
      "loss": 1.4322,
      "step": 4030
    },
    {
      "epoch": 0.1629919512637928,
      "grad_norm": 1.943039894104004,
      "learning_rate": 0.0001693896777220632,
      "loss": 1.4152,
      "step": 4040
    },
    {
      "epoch": 0.16339539668771308,
      "grad_norm": 0.9795454144477844,
      "learning_rate": 0.00016935282183047875,
      "loss": 1.3381,
      "step": 4050
    },
    {
      "epoch": 0.16379884211163334,
      "grad_norm": 1.1838270425796509,
      "learning_rate": 0.00016931596593889431,
      "loss": 1.3089,
      "step": 4060
    },
    {
      "epoch": 0.16420228753555363,
      "grad_norm": 1.2741568088531494,
      "learning_rate": 0.00016927911004730988,
      "loss": 1.2121,
      "step": 4070
    },
    {
      "epoch": 0.1646057329594739,
      "grad_norm": 0.8366013765335083,
      "learning_rate": 0.00016924225415572544,
      "loss": 1.2934,
      "step": 4080
    },
    {
      "epoch": 0.16500917838339418,
      "grad_norm": 1.412814974784851,
      "learning_rate": 0.000169205398264141,
      "loss": 1.408,
      "step": 4090
    },
    {
      "epoch": 0.16541262380731447,
      "grad_norm": 1.4148306846618652,
      "learning_rate": 0.00016916854237255657,
      "loss": 1.4689,
      "step": 4100
    },
    {
      "epoch": 0.16581606923123474,
      "grad_norm": 1.4829473495483398,
      "learning_rate": 0.00016913168648097216,
      "loss": 1.2306,
      "step": 4110
    },
    {
      "epoch": 0.16621951465515503,
      "grad_norm": 1.1897556781768799,
      "learning_rate": 0.00016909483058938772,
      "loss": 1.3468,
      "step": 4120
    },
    {
      "epoch": 0.16662296007907532,
      "grad_norm": 1.5554137229919434,
      "learning_rate": 0.00016905797469780328,
      "loss": 1.4916,
      "step": 4130
    },
    {
      "epoch": 0.16702640550299558,
      "grad_norm": 2.1681532859802246,
      "learning_rate": 0.00016902111880621884,
      "loss": 1.3848,
      "step": 4140
    },
    {
      "epoch": 0.16742985092691587,
      "grad_norm": 1.081485390663147,
      "learning_rate": 0.0001689842629146344,
      "loss": 1.3116,
      "step": 4150
    },
    {
      "epoch": 0.16783329635083613,
      "grad_norm": 1.0138553380966187,
      "learning_rate": 0.00016894740702304997,
      "loss": 1.3865,
      "step": 4160
    },
    {
      "epoch": 0.16823674177475642,
      "grad_norm": 1.6488847732543945,
      "learning_rate": 0.00016891055113146553,
      "loss": 1.3511,
      "step": 4170
    },
    {
      "epoch": 0.1686401871986767,
      "grad_norm": 1.0489526987075806,
      "learning_rate": 0.0001688736952398811,
      "loss": 1.2343,
      "step": 4180
    },
    {
      "epoch": 0.16904363262259697,
      "grad_norm": 1.0041970014572144,
      "learning_rate": 0.00016883683934829668,
      "loss": 1.3302,
      "step": 4190
    },
    {
      "epoch": 0.16944707804651726,
      "grad_norm": 1.6744037866592407,
      "learning_rate": 0.00016879998345671222,
      "loss": 1.2497,
      "step": 4200
    },
    {
      "epoch": 0.16944707804651726,
      "eval_loss": 1.3048614263534546,
      "eval_runtime": 14.5958,
      "eval_samples_per_second": 3.426,
      "eval_steps_per_second": 1.713,
      "step": 4200
    },
    {
      "epoch": 0.16985052347043753,
      "grad_norm": 1.2718791961669922,
      "learning_rate": 0.00016876312756512778,
      "loss": 1.3686,
      "step": 4210
    },
    {
      "epoch": 0.17025396889435782,
      "grad_norm": 1.1938347816467285,
      "learning_rate": 0.00016872627167354335,
      "loss": 1.2855,
      "step": 4220
    },
    {
      "epoch": 0.1706574143182781,
      "grad_norm": 1.5580060482025146,
      "learning_rate": 0.00016868941578195894,
      "loss": 1.3374,
      "step": 4230
    },
    {
      "epoch": 0.17106085974219837,
      "grad_norm": 1.0374685525894165,
      "learning_rate": 0.0001686525598903745,
      "loss": 1.3208,
      "step": 4240
    },
    {
      "epoch": 0.17146430516611866,
      "grad_norm": 1.0696040391921997,
      "learning_rate": 0.00016861570399879006,
      "loss": 1.3782,
      "step": 4250
    },
    {
      "epoch": 0.17186775059003892,
      "grad_norm": 1.027581810951233,
      "learning_rate": 0.00016857884810720562,
      "loss": 1.3141,
      "step": 4260
    },
    {
      "epoch": 0.1722711960139592,
      "grad_norm": 1.2386561632156372,
      "learning_rate": 0.00016854199221562119,
      "loss": 1.338,
      "step": 4270
    },
    {
      "epoch": 0.1726746414378795,
      "grad_norm": 2.673295021057129,
      "learning_rate": 0.00016850513632403675,
      "loss": 1.147,
      "step": 4280
    },
    {
      "epoch": 0.17307808686179976,
      "grad_norm": 1.6529533863067627,
      "learning_rate": 0.0001684682804324523,
      "loss": 1.3864,
      "step": 4290
    },
    {
      "epoch": 0.17348153228572005,
      "grad_norm": 1.0053907632827759,
      "learning_rate": 0.00016843142454086787,
      "loss": 1.3371,
      "step": 4300
    },
    {
      "epoch": 0.17388497770964031,
      "grad_norm": 1.497385025024414,
      "learning_rate": 0.00016839456864928346,
      "loss": 1.3243,
      "step": 4310
    },
    {
      "epoch": 0.1742884231335606,
      "grad_norm": 1.4001522064208984,
      "learning_rate": 0.000168357712757699,
      "loss": 1.3463,
      "step": 4320
    },
    {
      "epoch": 0.1746918685574809,
      "grad_norm": 1.4833139181137085,
      "learning_rate": 0.00016832085686611456,
      "loss": 1.2542,
      "step": 4330
    },
    {
      "epoch": 0.17509531398140116,
      "grad_norm": 0.9190767407417297,
      "learning_rate": 0.00016828400097453013,
      "loss": 1.4258,
      "step": 4340
    },
    {
      "epoch": 0.17549875940532145,
      "grad_norm": 1.1594775915145874,
      "learning_rate": 0.00016824714508294572,
      "loss": 1.1679,
      "step": 4350
    },
    {
      "epoch": 0.17590220482924174,
      "grad_norm": 3.8521413803100586,
      "learning_rate": 0.00016821028919136128,
      "loss": 1.2651,
      "step": 4360
    },
    {
      "epoch": 0.176305650253162,
      "grad_norm": 1.0844635963439941,
      "learning_rate": 0.00016817343329977684,
      "loss": 1.3915,
      "step": 4370
    },
    {
      "epoch": 0.1767090956770823,
      "grad_norm": 0.7710549831390381,
      "learning_rate": 0.0001681365774081924,
      "loss": 1.2784,
      "step": 4380
    },
    {
      "epoch": 0.17711254110100255,
      "grad_norm": 0.977699875831604,
      "learning_rate": 0.00016809972151660797,
      "loss": 1.2934,
      "step": 4390
    },
    {
      "epoch": 0.17751598652492284,
      "grad_norm": 1.6441030502319336,
      "learning_rate": 0.00016806286562502353,
      "loss": 1.4071,
      "step": 4400
    },
    {
      "epoch": 0.17751598652492284,
      "eval_loss": 1.3048776388168335,
      "eval_runtime": 14.6086,
      "eval_samples_per_second": 3.423,
      "eval_steps_per_second": 1.711,
      "step": 4400
    },
    {
      "epoch": 0.17791943194884313,
      "grad_norm": 1.0341423749923706,
      "learning_rate": 0.0001680260097334391,
      "loss": 1.2406,
      "step": 4410
    },
    {
      "epoch": 0.1783228773727634,
      "grad_norm": 0.796630322933197,
      "learning_rate": 0.00016798915384185465,
      "loss": 1.1935,
      "step": 4420
    },
    {
      "epoch": 0.17872632279668368,
      "grad_norm": 1.1628544330596924,
      "learning_rate": 0.00016795229795027024,
      "loss": 1.3792,
      "step": 4430
    },
    {
      "epoch": 0.17912976822060395,
      "grad_norm": 1.2941453456878662,
      "learning_rate": 0.00016791544205868578,
      "loss": 1.2628,
      "step": 4440
    },
    {
      "epoch": 0.17953321364452424,
      "grad_norm": 1.30301034450531,
      "learning_rate": 0.00016787858616710134,
      "loss": 1.3015,
      "step": 4450
    },
    {
      "epoch": 0.17993665906844453,
      "grad_norm": 1.1153032779693604,
      "learning_rate": 0.0001678417302755169,
      "loss": 1.3803,
      "step": 4460
    },
    {
      "epoch": 0.1803401044923648,
      "grad_norm": 1.6028149127960205,
      "learning_rate": 0.0001678048743839325,
      "loss": 1.3098,
      "step": 4470
    },
    {
      "epoch": 0.18074354991628508,
      "grad_norm": 1.2778069972991943,
      "learning_rate": 0.00016776801849234806,
      "loss": 1.3324,
      "step": 4480
    },
    {
      "epoch": 0.18114699534020534,
      "grad_norm": 0.9135691523551941,
      "learning_rate": 0.00016773116260076362,
      "loss": 1.1629,
      "step": 4490
    },
    {
      "epoch": 0.18155044076412563,
      "grad_norm": 2.0528247356414795,
      "learning_rate": 0.00016769430670917918,
      "loss": 1.5777,
      "step": 4500
    },
    {
      "epoch": 0.18195388618804592,
      "grad_norm": 1.5941118001937866,
      "learning_rate": 0.00016765745081759475,
      "loss": 1.3854,
      "step": 4510
    },
    {
      "epoch": 0.18235733161196618,
      "grad_norm": 1.550290584564209,
      "learning_rate": 0.0001676205949260103,
      "loss": 1.5371,
      "step": 4520
    },
    {
      "epoch": 0.18276077703588647,
      "grad_norm": 1.473519206047058,
      "learning_rate": 0.00016758373903442587,
      "loss": 1.244,
      "step": 4530
    },
    {
      "epoch": 0.18316422245980674,
      "grad_norm": 1.7294681072235107,
      "learning_rate": 0.00016754688314284143,
      "loss": 1.3688,
      "step": 4540
    },
    {
      "epoch": 0.18356766788372703,
      "grad_norm": 1.093591332435608,
      "learning_rate": 0.00016751002725125702,
      "loss": 1.4084,
      "step": 4550
    },
    {
      "epoch": 0.18397111330764732,
      "grad_norm": 1.009465217590332,
      "learning_rate": 0.0001674731713596726,
      "loss": 1.3549,
      "step": 4560
    },
    {
      "epoch": 0.18437455873156758,
      "grad_norm": 0.9129506945610046,
      "learning_rate": 0.00016743631546808812,
      "loss": 1.5472,
      "step": 4570
    },
    {
      "epoch": 0.18477800415548787,
      "grad_norm": 1.1631903648376465,
      "learning_rate": 0.00016739945957650369,
      "loss": 1.3399,
      "step": 4580
    },
    {
      "epoch": 0.18518144957940816,
      "grad_norm": 0.9217067360877991,
      "learning_rate": 0.00016736260368491927,
      "loss": 1.1931,
      "step": 4590
    },
    {
      "epoch": 0.18558489500332842,
      "grad_norm": 1.3291804790496826,
      "learning_rate": 0.00016732574779333484,
      "loss": 1.3401,
      "step": 4600
    },
    {
      "epoch": 0.18558489500332842,
      "eval_loss": 1.3068056106567383,
      "eval_runtime": 14.5744,
      "eval_samples_per_second": 3.431,
      "eval_steps_per_second": 1.715,
      "step": 4600
    },
    {
      "epoch": 0.1859883404272487,
      "grad_norm": 1.0088752508163452,
      "learning_rate": 0.0001672888919017504,
      "loss": 1.5301,
      "step": 4610
    },
    {
      "epoch": 0.18639178585116897,
      "grad_norm": 1.0704606771469116,
      "learning_rate": 0.00016725203601016596,
      "loss": 1.406,
      "step": 4620
    },
    {
      "epoch": 0.18679523127508926,
      "grad_norm": 1.1523045301437378,
      "learning_rate": 0.00016721518011858153,
      "loss": 1.3418,
      "step": 4630
    },
    {
      "epoch": 0.18719867669900955,
      "grad_norm": 1.2610658407211304,
      "learning_rate": 0.0001671783242269971,
      "loss": 1.3547,
      "step": 4640
    },
    {
      "epoch": 0.18760212212292982,
      "grad_norm": 2.0144588947296143,
      "learning_rate": 0.00016714146833541265,
      "loss": 1.3465,
      "step": 4650
    },
    {
      "epoch": 0.1880055675468501,
      "grad_norm": 1.276303768157959,
      "learning_rate": 0.00016710461244382821,
      "loss": 1.3009,
      "step": 4660
    },
    {
      "epoch": 0.18840901297077037,
      "grad_norm": 0.9927761554718018,
      "learning_rate": 0.0001670677565522438,
      "loss": 1.4689,
      "step": 4670
    },
    {
      "epoch": 0.18881245839469066,
      "grad_norm": 1.200473427772522,
      "learning_rate": 0.00016703090066065937,
      "loss": 1.5035,
      "step": 4680
    },
    {
      "epoch": 0.18921590381861095,
      "grad_norm": 1.323225975036621,
      "learning_rate": 0.0001669940447690749,
      "loss": 1.208,
      "step": 4690
    },
    {
      "epoch": 0.1896193492425312,
      "grad_norm": 0.9896813035011292,
      "learning_rate": 0.00016695718887749046,
      "loss": 1.29,
      "step": 4700
    },
    {
      "epoch": 0.1900227946664515,
      "grad_norm": 1.9970730543136597,
      "learning_rate": 0.00016692033298590605,
      "loss": 1.378,
      "step": 4710
    },
    {
      "epoch": 0.19042624009037176,
      "grad_norm": 1.1284167766571045,
      "learning_rate": 0.00016688347709432162,
      "loss": 1.3957,
      "step": 4720
    },
    {
      "epoch": 0.19082968551429205,
      "grad_norm": 1.0579183101654053,
      "learning_rate": 0.00016684662120273718,
      "loss": 1.256,
      "step": 4730
    },
    {
      "epoch": 0.19123313093821234,
      "grad_norm": 1.0211334228515625,
      "learning_rate": 0.00016680976531115274,
      "loss": 1.2376,
      "step": 4740
    },
    {
      "epoch": 0.1916365763621326,
      "grad_norm": 1.0322500467300415,
      "learning_rate": 0.0001667729094195683,
      "loss": 1.3556,
      "step": 4750
    },
    {
      "epoch": 0.1920400217860529,
      "grad_norm": 0.9421945214271545,
      "learning_rate": 0.00016673605352798387,
      "loss": 1.3937,
      "step": 4760
    },
    {
      "epoch": 0.19244346720997318,
      "grad_norm": 1.2600228786468506,
      "learning_rate": 0.00016669919763639943,
      "loss": 1.4195,
      "step": 4770
    },
    {
      "epoch": 0.19284691263389345,
      "grad_norm": 0.810389518737793,
      "learning_rate": 0.000166662341744815,
      "loss": 1.2858,
      "step": 4780
    },
    {
      "epoch": 0.19325035805781374,
      "grad_norm": 1.0079596042633057,
      "learning_rate": 0.00016662548585323058,
      "loss": 1.4213,
      "step": 4790
    },
    {
      "epoch": 0.193653803481734,
      "grad_norm": 0.9842103719711304,
      "learning_rate": 0.00016658862996164615,
      "loss": 1.2703,
      "step": 4800
    },
    {
      "epoch": 0.193653803481734,
      "eval_loss": 1.3090565204620361,
      "eval_runtime": 14.5776,
      "eval_samples_per_second": 3.43,
      "eval_steps_per_second": 1.715,
      "step": 4800
    },
    {
      "epoch": 0.1940572489056543,
      "grad_norm": 1.466502070426941,
      "learning_rate": 0.00016655177407006168,
      "loss": 1.3602,
      "step": 4810
    },
    {
      "epoch": 0.19446069432957458,
      "grad_norm": 1.202215313911438,
      "learning_rate": 0.00016651491817847724,
      "loss": 1.3936,
      "step": 4820
    },
    {
      "epoch": 0.19486413975349484,
      "grad_norm": 1.1807904243469238,
      "learning_rate": 0.00016647806228689283,
      "loss": 1.2408,
      "step": 4830
    },
    {
      "epoch": 0.19526758517741513,
      "grad_norm": 2.2937886714935303,
      "learning_rate": 0.0001664412063953084,
      "loss": 1.1597,
      "step": 4840
    },
    {
      "epoch": 0.1956710306013354,
      "grad_norm": 1.174443244934082,
      "learning_rate": 0.00016640435050372396,
      "loss": 1.1558,
      "step": 4850
    },
    {
      "epoch": 0.19607447602525568,
      "grad_norm": 1.6218944787979126,
      "learning_rate": 0.00016636749461213952,
      "loss": 1.3366,
      "step": 4860
    },
    {
      "epoch": 0.19647792144917597,
      "grad_norm": 1.0236294269561768,
      "learning_rate": 0.00016633063872055509,
      "loss": 1.3028,
      "step": 4870
    },
    {
      "epoch": 0.19688136687309624,
      "grad_norm": 0.8695847392082214,
      "learning_rate": 0.00016629378282897065,
      "loss": 1.4145,
      "step": 4880
    },
    {
      "epoch": 0.19728481229701653,
      "grad_norm": 0.8067811131477356,
      "learning_rate": 0.0001662569269373862,
      "loss": 1.203,
      "step": 4890
    },
    {
      "epoch": 0.1976882577209368,
      "grad_norm": 1.3805779218673706,
      "learning_rate": 0.00016622007104580177,
      "loss": 1.4851,
      "step": 4900
    },
    {
      "epoch": 0.19809170314485708,
      "grad_norm": 1.3436683416366577,
      "learning_rate": 0.00016618321515421734,
      "loss": 1.3064,
      "step": 4910
    },
    {
      "epoch": 0.19849514856877737,
      "grad_norm": 1.6160935163497925,
      "learning_rate": 0.00016614635926263293,
      "loss": 1.5068,
      "step": 4920
    },
    {
      "epoch": 0.19889859399269763,
      "grad_norm": 1.0392268896102905,
      "learning_rate": 0.0001661095033710485,
      "loss": 1.3302,
      "step": 4930
    },
    {
      "epoch": 0.19930203941661792,
      "grad_norm": 1.2505661249160767,
      "learning_rate": 0.00016607264747946402,
      "loss": 1.2509,
      "step": 4940
    },
    {
      "epoch": 0.19970548484053818,
      "grad_norm": 1.0520434379577637,
      "learning_rate": 0.0001660357915878796,
      "loss": 1.388,
      "step": 4950
    },
    {
      "epoch": 0.20010893026445847,
      "grad_norm": 1.1838692426681519,
      "learning_rate": 0.00016599893569629518,
      "loss": 1.2619,
      "step": 4960
    },
    {
      "epoch": 0.20051237568837876,
      "grad_norm": 0.7508378028869629,
      "learning_rate": 0.00016596207980471074,
      "loss": 1.3502,
      "step": 4970
    },
    {
      "epoch": 0.20091582111229903,
      "grad_norm": 1.174087643623352,
      "learning_rate": 0.0001659252239131263,
      "loss": 1.2883,
      "step": 4980
    },
    {
      "epoch": 0.20131926653621932,
      "grad_norm": 1.3120672702789307,
      "learning_rate": 0.00016588836802154187,
      "loss": 1.4098,
      "step": 4990
    },
    {
      "epoch": 0.2017227119601396,
      "grad_norm": 1.4988707304000854,
      "learning_rate": 0.00016585151212995743,
      "loss": 1.3751,
      "step": 5000
    },
    {
      "epoch": 0.2017227119601396,
      "eval_loss": 1.3082187175750732,
      "eval_runtime": 14.6089,
      "eval_samples_per_second": 3.423,
      "eval_steps_per_second": 1.711,
      "step": 5000
    },
    {
      "epoch": 0.20212615738405987,
      "grad_norm": 1.1314988136291504,
      "learning_rate": 0.000165814656238373,
      "loss": 1.1889,
      "step": 5010
    },
    {
      "epoch": 0.20252960280798016,
      "grad_norm": 1.6624244451522827,
      "learning_rate": 0.00016577780034678855,
      "loss": 1.3421,
      "step": 5020
    },
    {
      "epoch": 0.20293304823190042,
      "grad_norm": 1.4105061292648315,
      "learning_rate": 0.00016574094445520412,
      "loss": 1.3149,
      "step": 5030
    },
    {
      "epoch": 0.2033364936558207,
      "grad_norm": 1.4320347309112549,
      "learning_rate": 0.0001657040885636197,
      "loss": 1.2937,
      "step": 5040
    },
    {
      "epoch": 0.203739939079741,
      "grad_norm": 1.6778666973114014,
      "learning_rate": 0.00016566723267203527,
      "loss": 1.2963,
      "step": 5050
    },
    {
      "epoch": 0.20414338450366126,
      "grad_norm": 1.4462366104125977,
      "learning_rate": 0.0001656303767804508,
      "loss": 1.3847,
      "step": 5060
    },
    {
      "epoch": 0.20454682992758155,
      "grad_norm": 1.2011253833770752,
      "learning_rate": 0.00016559352088886637,
      "loss": 1.2929,
      "step": 5070
    },
    {
      "epoch": 0.20495027535150181,
      "grad_norm": 1.4165693521499634,
      "learning_rate": 0.00016555666499728196,
      "loss": 1.2056,
      "step": 5080
    },
    {
      "epoch": 0.2053537207754221,
      "grad_norm": 1.00048828125,
      "learning_rate": 0.00016551980910569752,
      "loss": 1.5089,
      "step": 5090
    },
    {
      "epoch": 0.2057571661993424,
      "grad_norm": 1.1812902688980103,
      "learning_rate": 0.00016548295321411308,
      "loss": 1.2209,
      "step": 5100
    },
    {
      "epoch": 0.20616061162326266,
      "grad_norm": 1.1989924907684326,
      "learning_rate": 0.00016544609732252865,
      "loss": 1.38,
      "step": 5110
    },
    {
      "epoch": 0.20656405704718295,
      "grad_norm": 1.0272706747055054,
      "learning_rate": 0.0001654092414309442,
      "loss": 1.2192,
      "step": 5120
    },
    {
      "epoch": 0.2069675024711032,
      "grad_norm": 1.3126972913742065,
      "learning_rate": 0.00016537238553935977,
      "loss": 1.494,
      "step": 5130
    },
    {
      "epoch": 0.2073709478950235,
      "grad_norm": 1.1635373830795288,
      "learning_rate": 0.00016533552964777533,
      "loss": 1.3623,
      "step": 5140
    },
    {
      "epoch": 0.2077743933189438,
      "grad_norm": 1.3325774669647217,
      "learning_rate": 0.0001652986737561909,
      "loss": 1.2511,
      "step": 5150
    },
    {
      "epoch": 0.20817783874286405,
      "grad_norm": 1.1191933155059814,
      "learning_rate": 0.00016526181786460649,
      "loss": 1.2982,
      "step": 5160
    },
    {
      "epoch": 0.20858128416678434,
      "grad_norm": 1.1243313550949097,
      "learning_rate": 0.00016522496197302205,
      "loss": 1.236,
      "step": 5170
    },
    {
      "epoch": 0.2089847295907046,
      "grad_norm": 0.8778996467590332,
      "learning_rate": 0.00016518810608143758,
      "loss": 1.2485,
      "step": 5180
    },
    {
      "epoch": 0.2093881750146249,
      "grad_norm": 1.336897611618042,
      "learning_rate": 0.00016515125018985315,
      "loss": 1.1411,
      "step": 5190
    },
    {
      "epoch": 0.20979162043854518,
      "grad_norm": 1.0549900531768799,
      "learning_rate": 0.00016511439429826874,
      "loss": 1.4161,
      "step": 5200
    },
    {
      "epoch": 0.20979162043854518,
      "eval_loss": 1.3097152709960938,
      "eval_runtime": 14.5688,
      "eval_samples_per_second": 3.432,
      "eval_steps_per_second": 1.716,
      "step": 5200
    },
    {
      "epoch": 0.21019506586246545,
      "grad_norm": 1.0415185689926147,
      "learning_rate": 0.0001650775384066843,
      "loss": 1.2749,
      "step": 5210
    },
    {
      "epoch": 0.21059851128638574,
      "grad_norm": 1.6201764345169067,
      "learning_rate": 0.00016504068251509986,
      "loss": 1.2811,
      "step": 5220
    },
    {
      "epoch": 0.21100195671030603,
      "grad_norm": 1.632568597793579,
      "learning_rate": 0.00016500382662351542,
      "loss": 1.3022,
      "step": 5230
    },
    {
      "epoch": 0.2114054021342263,
      "grad_norm": 1.1547797918319702,
      "learning_rate": 0.000164966970731931,
      "loss": 1.4239,
      "step": 5240
    },
    {
      "epoch": 0.21180884755814658,
      "grad_norm": 1.074314832687378,
      "learning_rate": 0.00016493011484034655,
      "loss": 1.364,
      "step": 5250
    },
    {
      "epoch": 0.21221229298206684,
      "grad_norm": 1.5350099802017212,
      "learning_rate": 0.0001648932589487621,
      "loss": 1.352,
      "step": 5260
    },
    {
      "epoch": 0.21261573840598713,
      "grad_norm": 2.565838575363159,
      "learning_rate": 0.00016485640305717768,
      "loss": 1.3144,
      "step": 5270
    },
    {
      "epoch": 0.21301918382990742,
      "grad_norm": 0.8477138876914978,
      "learning_rate": 0.00016481954716559327,
      "loss": 1.3397,
      "step": 5280
    },
    {
      "epoch": 0.21342262925382768,
      "grad_norm": 1.159077763557434,
      "learning_rate": 0.00016478269127400883,
      "loss": 1.3082,
      "step": 5290
    },
    {
      "epoch": 0.21382607467774797,
      "grad_norm": 1.11106276512146,
      "learning_rate": 0.0001647458353824244,
      "loss": 1.3514,
      "step": 5300
    },
    {
      "epoch": 0.21422952010166824,
      "grad_norm": 1.3126295804977417,
      "learning_rate": 0.00016470897949083993,
      "loss": 1.3651,
      "step": 5310
    },
    {
      "epoch": 0.21463296552558853,
      "grad_norm": 1.385805368423462,
      "learning_rate": 0.00016467212359925552,
      "loss": 1.3523,
      "step": 5320
    },
    {
      "epoch": 0.21503641094950882,
      "grad_norm": 0.9074638485908508,
      "learning_rate": 0.00016463526770767108,
      "loss": 1.209,
      "step": 5330
    },
    {
      "epoch": 0.21543985637342908,
      "grad_norm": 1.5169371366500854,
      "learning_rate": 0.00016459841181608664,
      "loss": 1.339,
      "step": 5340
    },
    {
      "epoch": 0.21584330179734937,
      "grad_norm": 2.3898661136627197,
      "learning_rate": 0.0001645615559245022,
      "loss": 1.2897,
      "step": 5350
    },
    {
      "epoch": 0.21624674722126963,
      "grad_norm": 1.2204256057739258,
      "learning_rate": 0.00016452470003291777,
      "loss": 1.2459,
      "step": 5360
    },
    {
      "epoch": 0.21665019264518992,
      "grad_norm": 1.4142215251922607,
      "learning_rate": 0.00016448784414133333,
      "loss": 1.4379,
      "step": 5370
    },
    {
      "epoch": 0.2170536380691102,
      "grad_norm": 1.3360859155654907,
      "learning_rate": 0.0001644509882497489,
      "loss": 1.1907,
      "step": 5380
    },
    {
      "epoch": 0.21745708349303047,
      "grad_norm": 1.9174001216888428,
      "learning_rate": 0.00016441413235816446,
      "loss": 1.3756,
      "step": 5390
    },
    {
      "epoch": 0.21786052891695076,
      "grad_norm": 1.2791557312011719,
      "learning_rate": 0.00016437727646658005,
      "loss": 1.1998,
      "step": 5400
    },
    {
      "epoch": 0.21786052891695076,
      "eval_loss": 1.3092135190963745,
      "eval_runtime": 14.5741,
      "eval_samples_per_second": 3.431,
      "eval_steps_per_second": 1.715,
      "step": 5400
    },
    {
      "epoch": 0.21826397434087103,
      "grad_norm": 1.0819122791290283,
      "learning_rate": 0.0001643404205749956,
      "loss": 1.2145,
      "step": 5410
    },
    {
      "epoch": 0.21866741976479132,
      "grad_norm": 1.4835984706878662,
      "learning_rate": 0.00016430356468341117,
      "loss": 1.4687,
      "step": 5420
    },
    {
      "epoch": 0.2190708651887116,
      "grad_norm": 1.1617544889450073,
      "learning_rate": 0.0001642667087918267,
      "loss": 1.3638,
      "step": 5430
    },
    {
      "epoch": 0.21947431061263187,
      "grad_norm": 0.7526930570602417,
      "learning_rate": 0.0001642298529002423,
      "loss": 1.1561,
      "step": 5440
    },
    {
      "epoch": 0.21987775603655216,
      "grad_norm": 1.4758433103561401,
      "learning_rate": 0.00016419299700865786,
      "loss": 1.4964,
      "step": 5450
    },
    {
      "epoch": 0.22028120146047245,
      "grad_norm": 1.1731624603271484,
      "learning_rate": 0.00016415614111707342,
      "loss": 1.3369,
      "step": 5460
    },
    {
      "epoch": 0.2206846468843927,
      "grad_norm": 1.113282561302185,
      "learning_rate": 0.00016411928522548898,
      "loss": 1.53,
      "step": 5470
    },
    {
      "epoch": 0.221088092308313,
      "grad_norm": 1.0896016359329224,
      "learning_rate": 0.00016408242933390455,
      "loss": 1.195,
      "step": 5480
    },
    {
      "epoch": 0.22149153773223326,
      "grad_norm": 1.1240910291671753,
      "learning_rate": 0.0001640455734423201,
      "loss": 1.2668,
      "step": 5490
    },
    {
      "epoch": 0.22189498315615355,
      "grad_norm": 0.9207218885421753,
      "learning_rate": 0.00016400871755073567,
      "loss": 1.389,
      "step": 5500
    },
    {
      "epoch": 0.22229842858007384,
      "grad_norm": 1.0740742683410645,
      "learning_rate": 0.00016397186165915124,
      "loss": 1.311,
      "step": 5510
    },
    {
      "epoch": 0.2227018740039941,
      "grad_norm": 1.12216055393219,
      "learning_rate": 0.00016393500576756683,
      "loss": 1.285,
      "step": 5520
    },
    {
      "epoch": 0.2231053194279144,
      "grad_norm": 1.125826120376587,
      "learning_rate": 0.0001638981498759824,
      "loss": 1.2744,
      "step": 5530
    },
    {
      "epoch": 0.22350876485183466,
      "grad_norm": 0.7933152914047241,
      "learning_rate": 0.00016386129398439795,
      "loss": 1.2364,
      "step": 5540
    },
    {
      "epoch": 0.22391221027575495,
      "grad_norm": 1.7227412462234497,
      "learning_rate": 0.0001638244380928135,
      "loss": 1.515,
      "step": 5550
    },
    {
      "epoch": 0.22431565569967524,
      "grad_norm": 1.1952577829360962,
      "learning_rate": 0.00016378758220122908,
      "loss": 1.4868,
      "step": 5560
    },
    {
      "epoch": 0.2247191011235955,
      "grad_norm": 0.9518359899520874,
      "learning_rate": 0.00016375072630964464,
      "loss": 1.4601,
      "step": 5570
    },
    {
      "epoch": 0.2251225465475158,
      "grad_norm": 1.0268737077713013,
      "learning_rate": 0.0001637138704180602,
      "loss": 1.1832,
      "step": 5580
    },
    {
      "epoch": 0.22552599197143605,
      "grad_norm": 1.0600135326385498,
      "learning_rate": 0.00016367701452647576,
      "loss": 1.2624,
      "step": 5590
    },
    {
      "epoch": 0.22592943739535634,
      "grad_norm": 1.0705312490463257,
      "learning_rate": 0.00016364015863489133,
      "loss": 1.2528,
      "step": 5600
    },
    {
      "epoch": 0.22592943739535634,
      "eval_loss": 1.3096379041671753,
      "eval_runtime": 14.6096,
      "eval_samples_per_second": 3.422,
      "eval_steps_per_second": 1.711,
      "step": 5600
    },
    {
      "epoch": 0.22633288281927663,
      "grad_norm": 1.3300901651382446,
      "learning_rate": 0.0001636033027433069,
      "loss": 1.5655,
      "step": 5610
    },
    {
      "epoch": 0.2267363282431969,
      "grad_norm": 1.0174243450164795,
      "learning_rate": 0.00016356644685172245,
      "loss": 1.5762,
      "step": 5620
    },
    {
      "epoch": 0.22713977366711718,
      "grad_norm": 1.0390913486480713,
      "learning_rate": 0.00016352959096013802,
      "loss": 1.3468,
      "step": 5630
    },
    {
      "epoch": 0.22754321909103745,
      "grad_norm": 1.0205483436584473,
      "learning_rate": 0.0001634927350685536,
      "loss": 1.1963,
      "step": 5640
    },
    {
      "epoch": 0.22794666451495774,
      "grad_norm": 1.5047856569290161,
      "learning_rate": 0.00016345587917696917,
      "loss": 1.2459,
      "step": 5650
    },
    {
      "epoch": 0.22835010993887803,
      "grad_norm": 1.0178903341293335,
      "learning_rate": 0.00016341902328538473,
      "loss": 1.2746,
      "step": 5660
    },
    {
      "epoch": 0.2287535553627983,
      "grad_norm": 1.253663420677185,
      "learning_rate": 0.0001633821673938003,
      "loss": 1.1231,
      "step": 5670
    },
    {
      "epoch": 0.22915700078671858,
      "grad_norm": 1.338992953300476,
      "learning_rate": 0.00016334531150221586,
      "loss": 1.1488,
      "step": 5680
    },
    {
      "epoch": 0.22956044621063887,
      "grad_norm": 1.0180021524429321,
      "learning_rate": 0.00016330845561063142,
      "loss": 1.3489,
      "step": 5690
    },
    {
      "epoch": 0.22996389163455913,
      "grad_norm": 1.2266722917556763,
      "learning_rate": 0.00016327159971904698,
      "loss": 1.2028,
      "step": 5700
    },
    {
      "epoch": 0.23036733705847942,
      "grad_norm": 1.207329511642456,
      "learning_rate": 0.00016323474382746254,
      "loss": 1.4503,
      "step": 5710
    },
    {
      "epoch": 0.23077078248239968,
      "grad_norm": 1.2693521976470947,
      "learning_rate": 0.00016319788793587813,
      "loss": 1.3074,
      "step": 5720
    },
    {
      "epoch": 0.23117422790631997,
      "grad_norm": 0.9846912622451782,
      "learning_rate": 0.00016316103204429367,
      "loss": 1.2724,
      "step": 5730
    },
    {
      "epoch": 0.23157767333024026,
      "grad_norm": 1.0984426736831665,
      "learning_rate": 0.00016312417615270923,
      "loss": 1.3294,
      "step": 5740
    },
    {
      "epoch": 0.23198111875416053,
      "grad_norm": 1.0553278923034668,
      "learning_rate": 0.0001630873202611248,
      "loss": 1.4445,
      "step": 5750
    },
    {
      "epoch": 0.23238456417808082,
      "grad_norm": 0.8137953877449036,
      "learning_rate": 0.00016305046436954039,
      "loss": 1.3518,
      "step": 5760
    },
    {
      "epoch": 0.23278800960200108,
      "grad_norm": 1.1946455240249634,
      "learning_rate": 0.00016301360847795595,
      "loss": 1.2337,
      "step": 5770
    },
    {
      "epoch": 0.23319145502592137,
      "grad_norm": 1.0540270805358887,
      "learning_rate": 0.0001629767525863715,
      "loss": 1.3278,
      "step": 5780
    },
    {
      "epoch": 0.23359490044984166,
      "grad_norm": 1.3333581686019897,
      "learning_rate": 0.00016293989669478707,
      "loss": 1.2978,
      "step": 5790
    },
    {
      "epoch": 0.23399834587376192,
      "grad_norm": 1.273712158203125,
      "learning_rate": 0.00016290304080320264,
      "loss": 1.3138,
      "step": 5800
    },
    {
      "epoch": 0.23399834587376192,
      "eval_loss": 1.312198281288147,
      "eval_runtime": 14.5802,
      "eval_samples_per_second": 3.429,
      "eval_steps_per_second": 1.715,
      "step": 5800
    },
    {
      "epoch": 0.2344017912976822,
      "grad_norm": 1.3201411962509155,
      "learning_rate": 0.0001628661849116182,
      "loss": 1.1654,
      "step": 5810
    },
    {
      "epoch": 0.23480523672160247,
      "grad_norm": 1.1365476846694946,
      "learning_rate": 0.00016282932902003376,
      "loss": 1.4681,
      "step": 5820
    },
    {
      "epoch": 0.23520868214552276,
      "grad_norm": 1.2055292129516602,
      "learning_rate": 0.00016279247312844932,
      "loss": 1.2879,
      "step": 5830
    },
    {
      "epoch": 0.23561212756944305,
      "grad_norm": 2.595750093460083,
      "learning_rate": 0.00016275561723686491,
      "loss": 1.4389,
      "step": 5840
    },
    {
      "epoch": 0.23601557299336332,
      "grad_norm": 1.6413341760635376,
      "learning_rate": 0.00016271876134528045,
      "loss": 1.3362,
      "step": 5850
    },
    {
      "epoch": 0.2364190184172836,
      "grad_norm": 1.2245341539382935,
      "learning_rate": 0.000162681905453696,
      "loss": 1.2897,
      "step": 5860
    },
    {
      "epoch": 0.23682246384120387,
      "grad_norm": 1.2541626691818237,
      "learning_rate": 0.00016264504956211158,
      "loss": 1.3443,
      "step": 5870
    },
    {
      "epoch": 0.23722590926512416,
      "grad_norm": 1.4455980062484741,
      "learning_rate": 0.00016260819367052716,
      "loss": 1.273,
      "step": 5880
    },
    {
      "epoch": 0.23762935468904445,
      "grad_norm": 1.6040492057800293,
      "learning_rate": 0.00016257133777894273,
      "loss": 1.4006,
      "step": 5890
    },
    {
      "epoch": 0.2380328001129647,
      "grad_norm": 1.0650391578674316,
      "learning_rate": 0.0001625344818873583,
      "loss": 1.4125,
      "step": 5900
    },
    {
      "epoch": 0.238436245536885,
      "grad_norm": 0.9467090368270874,
      "learning_rate": 0.00016249762599577385,
      "loss": 1.1671,
      "step": 5910
    },
    {
      "epoch": 0.2388396909608053,
      "grad_norm": 1.2306623458862305,
      "learning_rate": 0.00016246077010418942,
      "loss": 1.2581,
      "step": 5920
    },
    {
      "epoch": 0.23924313638472555,
      "grad_norm": 1.113088846206665,
      "learning_rate": 0.00016242391421260498,
      "loss": 1.3821,
      "step": 5930
    },
    {
      "epoch": 0.23964658180864584,
      "grad_norm": 1.0530468225479126,
      "learning_rate": 0.00016238705832102054,
      "loss": 1.3221,
      "step": 5940
    },
    {
      "epoch": 0.2400500272325661,
      "grad_norm": 1.4962360858917236,
      "learning_rate": 0.0001623502024294361,
      "loss": 1.3661,
      "step": 5950
    },
    {
      "epoch": 0.2404534726564864,
      "grad_norm": 1.878881573677063,
      "learning_rate": 0.0001623133465378517,
      "loss": 1.2803,
      "step": 5960
    },
    {
      "epoch": 0.24085691808040668,
      "grad_norm": 1.0737371444702148,
      "learning_rate": 0.00016227649064626723,
      "loss": 1.3281,
      "step": 5970
    },
    {
      "epoch": 0.24126036350432695,
      "grad_norm": 1.233620524406433,
      "learning_rate": 0.0001622396347546828,
      "loss": 1.3367,
      "step": 5980
    },
    {
      "epoch": 0.24166380892824724,
      "grad_norm": 1.0442852973937988,
      "learning_rate": 0.00016220277886309835,
      "loss": 1.3698,
      "step": 5990
    },
    {
      "epoch": 0.2420672543521675,
      "grad_norm": 1.1951111555099487,
      "learning_rate": 0.00016216592297151394,
      "loss": 1.2195,
      "step": 6000
    },
    {
      "epoch": 0.2420672543521675,
      "eval_loss": 1.3041917085647583,
      "eval_runtime": 14.5775,
      "eval_samples_per_second": 3.43,
      "eval_steps_per_second": 1.715,
      "step": 6000
    },
    {
      "epoch": 0.2424706997760878,
      "grad_norm": 1.4494329690933228,
      "learning_rate": 0.0001621290670799295,
      "loss": 1.2511,
      "step": 6010
    },
    {
      "epoch": 0.24287414520000808,
      "grad_norm": 1.421880841255188,
      "learning_rate": 0.00016209221118834507,
      "loss": 1.3001,
      "step": 6020
    },
    {
      "epoch": 0.24327759062392834,
      "grad_norm": 1.3238379955291748,
      "learning_rate": 0.00016205535529676063,
      "loss": 1.2884,
      "step": 6030
    },
    {
      "epoch": 0.24368103604784863,
      "grad_norm": 1.2388651371002197,
      "learning_rate": 0.0001620184994051762,
      "loss": 1.3465,
      "step": 6040
    },
    {
      "epoch": 0.2440844814717689,
      "grad_norm": 1.0042108297348022,
      "learning_rate": 0.00016198164351359176,
      "loss": 1.4038,
      "step": 6050
    },
    {
      "epoch": 0.24448792689568918,
      "grad_norm": 1.2097101211547852,
      "learning_rate": 0.00016194478762200732,
      "loss": 1.2905,
      "step": 6060
    },
    {
      "epoch": 0.24489137231960947,
      "grad_norm": 1.0967917442321777,
      "learning_rate": 0.00016190793173042288,
      "loss": 1.384,
      "step": 6070
    },
    {
      "epoch": 0.24529481774352974,
      "grad_norm": 2.0025548934936523,
      "learning_rate": 0.00016187107583883845,
      "loss": 1.2217,
      "step": 6080
    },
    {
      "epoch": 0.24569826316745003,
      "grad_norm": 0.9433799982070923,
      "learning_rate": 0.000161834219947254,
      "loss": 1.2967,
      "step": 6090
    },
    {
      "epoch": 0.24610170859137032,
      "grad_norm": 1.6488063335418701,
      "learning_rate": 0.00016179736405566957,
      "loss": 1.2292,
      "step": 6100
    },
    {
      "epoch": 0.24650515401529058,
      "grad_norm": 1.4508495330810547,
      "learning_rate": 0.00016176050816408513,
      "loss": 1.3563,
      "step": 6110
    },
    {
      "epoch": 0.24690859943921087,
      "grad_norm": 1.3113903999328613,
      "learning_rate": 0.0001617236522725007,
      "loss": 1.538,
      "step": 6120
    },
    {
      "epoch": 0.24731204486313113,
      "grad_norm": 0.9756127595901489,
      "learning_rate": 0.0001616867963809163,
      "loss": 1.3546,
      "step": 6130
    },
    {
      "epoch": 0.24771549028705142,
      "grad_norm": 1.9679473638534546,
      "learning_rate": 0.00016164994048933185,
      "loss": 1.3368,
      "step": 6140
    },
    {
      "epoch": 0.2481189357109717,
      "grad_norm": 0.9109131693840027,
      "learning_rate": 0.0001616130845977474,
      "loss": 1.4704,
      "step": 6150
    },
    {
      "epoch": 0.24852238113489197,
      "grad_norm": 1.0400640964508057,
      "learning_rate": 0.00016157622870616298,
      "loss": 1.3528,
      "step": 6160
    },
    {
      "epoch": 0.24892582655881226,
      "grad_norm": 0.7880954146385193,
      "learning_rate": 0.00016153937281457854,
      "loss": 1.3189,
      "step": 6170
    },
    {
      "epoch": 0.24932927198273253,
      "grad_norm": 1.0277544260025024,
      "learning_rate": 0.0001615025169229941,
      "loss": 1.2279,
      "step": 6180
    },
    {
      "epoch": 0.24973271740665282,
      "grad_norm": 0.8551956415176392,
      "learning_rate": 0.00016146566103140966,
      "loss": 1.379,
      "step": 6190
    },
    {
      "epoch": 0.2501361628305731,
      "grad_norm": 1.108837366104126,
      "learning_rate": 0.00016142880513982523,
      "loss": 1.2399,
      "step": 6200
    },
    {
      "epoch": 0.2501361628305731,
      "eval_loss": 1.3046568632125854,
      "eval_runtime": 14.5797,
      "eval_samples_per_second": 3.429,
      "eval_steps_per_second": 1.715,
      "step": 6200
    },
    {
      "epoch": 0.2505396082544934,
      "grad_norm": 0.9191381931304932,
      "learning_rate": 0.00016139194924824082,
      "loss": 1.2162,
      "step": 6210
    },
    {
      "epoch": 0.25094305367841363,
      "grad_norm": 1.1703499555587769,
      "learning_rate": 0.00016135509335665635,
      "loss": 1.3534,
      "step": 6220
    },
    {
      "epoch": 0.2513464991023339,
      "grad_norm": 2.0096349716186523,
      "learning_rate": 0.00016131823746507191,
      "loss": 1.4708,
      "step": 6230
    },
    {
      "epoch": 0.2517499445262542,
      "grad_norm": 1.6180387735366821,
      "learning_rate": 0.00016128138157348748,
      "loss": 1.2722,
      "step": 6240
    },
    {
      "epoch": 0.2521533899501745,
      "grad_norm": 2.0619001388549805,
      "learning_rate": 0.00016124452568190307,
      "loss": 1.2695,
      "step": 6250
    },
    {
      "epoch": 0.2525568353740948,
      "grad_norm": 1.2324031591415405,
      "learning_rate": 0.00016120766979031863,
      "loss": 1.3386,
      "step": 6260
    },
    {
      "epoch": 0.252960280798015,
      "grad_norm": 1.0923166275024414,
      "learning_rate": 0.0001611708138987342,
      "loss": 1.4169,
      "step": 6270
    },
    {
      "epoch": 0.2533637262219353,
      "grad_norm": 0.9160663485527039,
      "learning_rate": 0.00016113395800714976,
      "loss": 1.3159,
      "step": 6280
    },
    {
      "epoch": 0.2537671716458556,
      "grad_norm": 1.0683828592300415,
      "learning_rate": 0.00016109710211556532,
      "loss": 1.3055,
      "step": 6290
    },
    {
      "epoch": 0.2541706170697759,
      "grad_norm": 0.9992537498474121,
      "learning_rate": 0.00016106024622398088,
      "loss": 1.2649,
      "step": 6300
    },
    {
      "epoch": 0.2545740624936962,
      "grad_norm": 1.0718541145324707,
      "learning_rate": 0.00016102339033239644,
      "loss": 1.204,
      "step": 6310
    },
    {
      "epoch": 0.2549775079176164,
      "grad_norm": 1.7752456665039062,
      "learning_rate": 0.000160986534440812,
      "loss": 1.1946,
      "step": 6320
    },
    {
      "epoch": 0.2553809533415367,
      "grad_norm": 1.3806538581848145,
      "learning_rate": 0.0001609496785492276,
      "loss": 1.3108,
      "step": 6330
    },
    {
      "epoch": 0.255784398765457,
      "grad_norm": 1.5211000442504883,
      "learning_rate": 0.00016091282265764313,
      "loss": 1.4455,
      "step": 6340
    },
    {
      "epoch": 0.2561878441893773,
      "grad_norm": 1.3168050050735474,
      "learning_rate": 0.0001608759667660587,
      "loss": 1.2244,
      "step": 6350
    },
    {
      "epoch": 0.2565912896132976,
      "grad_norm": 1.212843418121338,
      "learning_rate": 0.00016083911087447426,
      "loss": 1.4656,
      "step": 6360
    },
    {
      "epoch": 0.2569947350372178,
      "grad_norm": 2.9230551719665527,
      "learning_rate": 0.00016080225498288985,
      "loss": 1.2274,
      "step": 6370
    },
    {
      "epoch": 0.2573981804611381,
      "grad_norm": 1.1498173475265503,
      "learning_rate": 0.0001607653990913054,
      "loss": 1.3566,
      "step": 6380
    },
    {
      "epoch": 0.2578016258850584,
      "grad_norm": 1.0571184158325195,
      "learning_rate": 0.00016072854319972097,
      "loss": 1.4739,
      "step": 6390
    },
    {
      "epoch": 0.2582050713089787,
      "grad_norm": 0.9422804713249207,
      "learning_rate": 0.00016069168730813654,
      "loss": 1.2991,
      "step": 6400
    },
    {
      "epoch": 0.2582050713089787,
      "eval_loss": 1.305657148361206,
      "eval_runtime": 14.5941,
      "eval_samples_per_second": 3.426,
      "eval_steps_per_second": 1.713,
      "step": 6400
    },
    {
      "epoch": 0.258608516732899,
      "grad_norm": 1.2737152576446533,
      "learning_rate": 0.0001606548314165521,
      "loss": 1.4211,
      "step": 6410
    },
    {
      "epoch": 0.2590119621568192,
      "grad_norm": 1.0495901107788086,
      "learning_rate": 0.00016061797552496766,
      "loss": 1.2806,
      "step": 6420
    },
    {
      "epoch": 0.2594154075807395,
      "grad_norm": 1.1295970678329468,
      "learning_rate": 0.00016058111963338322,
      "loss": 1.2926,
      "step": 6430
    },
    {
      "epoch": 0.2598188530046598,
      "grad_norm": 1.32505464553833,
      "learning_rate": 0.00016054426374179879,
      "loss": 1.1955,
      "step": 6440
    },
    {
      "epoch": 0.2602222984285801,
      "grad_norm": 1.2439013719558716,
      "learning_rate": 0.00016050740785021438,
      "loss": 1.3919,
      "step": 6450
    },
    {
      "epoch": 0.26062574385250037,
      "grad_norm": 1.656984567642212,
      "learning_rate": 0.0001604705519586299,
      "loss": 1.3037,
      "step": 6460
    },
    {
      "epoch": 0.26102918927642066,
      "grad_norm": 1.1557157039642334,
      "learning_rate": 0.00016043369606704547,
      "loss": 1.3513,
      "step": 6470
    },
    {
      "epoch": 0.2614326347003409,
      "grad_norm": 1.2002177238464355,
      "learning_rate": 0.00016039684017546104,
      "loss": 1.2266,
      "step": 6480
    },
    {
      "epoch": 0.2618360801242612,
      "grad_norm": 1.8514459133148193,
      "learning_rate": 0.00016035998428387663,
      "loss": 1.404,
      "step": 6490
    },
    {
      "epoch": 0.2622395255481815,
      "grad_norm": 1.1999289989471436,
      "learning_rate": 0.0001603231283922922,
      "loss": 1.2376,
      "step": 6500
    },
    {
      "epoch": 0.26264297097210176,
      "grad_norm": 1.0508586168289185,
      "learning_rate": 0.00016028627250070775,
      "loss": 1.3566,
      "step": 6510
    },
    {
      "epoch": 0.26304641639602205,
      "grad_norm": 1.6396759748458862,
      "learning_rate": 0.00016024941660912331,
      "loss": 1.3475,
      "step": 6520
    },
    {
      "epoch": 0.2634498618199423,
      "grad_norm": 1.2322795391082764,
      "learning_rate": 0.00016021256071753888,
      "loss": 1.3052,
      "step": 6530
    },
    {
      "epoch": 0.2638533072438626,
      "grad_norm": 1.3852179050445557,
      "learning_rate": 0.00016017570482595444,
      "loss": 1.3393,
      "step": 6540
    },
    {
      "epoch": 0.26425675266778287,
      "grad_norm": 1.2324044704437256,
      "learning_rate": 0.00016013884893437,
      "loss": 1.3748,
      "step": 6550
    },
    {
      "epoch": 0.26466019809170316,
      "grad_norm": 1.4544719457626343,
      "learning_rate": 0.00016010199304278557,
      "loss": 1.3252,
      "step": 6560
    },
    {
      "epoch": 0.26506364351562345,
      "grad_norm": 1.5968157052993774,
      "learning_rate": 0.00016006513715120116,
      "loss": 1.341,
      "step": 6570
    },
    {
      "epoch": 0.2654670889395437,
      "grad_norm": 1.5022251605987549,
      "learning_rate": 0.00016002828125961672,
      "loss": 1.2681,
      "step": 6580
    },
    {
      "epoch": 0.265870534363464,
      "grad_norm": 1.785606861114502,
      "learning_rate": 0.00015999142536803225,
      "loss": 1.3109,
      "step": 6590
    },
    {
      "epoch": 0.26627397978738426,
      "grad_norm": 1.2824028730392456,
      "learning_rate": 0.00015995456947644782,
      "loss": 1.3354,
      "step": 6600
    },
    {
      "epoch": 0.26627397978738426,
      "eval_loss": 1.3039218187332153,
      "eval_runtime": 14.5932,
      "eval_samples_per_second": 3.426,
      "eval_steps_per_second": 1.713,
      "step": 6600
    },
    {
      "epoch": 0.26667742521130455,
      "grad_norm": 1.4761946201324463,
      "learning_rate": 0.0001599177135848634,
      "loss": 1.3604,
      "step": 6610
    },
    {
      "epoch": 0.26708087063522484,
      "grad_norm": 1.4919465780258179,
      "learning_rate": 0.00015988085769327897,
      "loss": 1.3701,
      "step": 6620
    },
    {
      "epoch": 0.2674843160591451,
      "grad_norm": 1.737342357635498,
      "learning_rate": 0.00015984400180169453,
      "loss": 1.3561,
      "step": 6630
    },
    {
      "epoch": 0.26788776148306537,
      "grad_norm": 1.4033468961715698,
      "learning_rate": 0.0001598071459101101,
      "loss": 1.2607,
      "step": 6640
    },
    {
      "epoch": 0.26829120690698566,
      "grad_norm": 1.4556300640106201,
      "learning_rate": 0.00015977029001852566,
      "loss": 1.2763,
      "step": 6650
    },
    {
      "epoch": 0.26869465233090595,
      "grad_norm": 1.3583950996398926,
      "learning_rate": 0.00015973343412694122,
      "loss": 1.3214,
      "step": 6660
    },
    {
      "epoch": 0.26909809775482624,
      "grad_norm": 1.6565982103347778,
      "learning_rate": 0.00015969657823535678,
      "loss": 1.322,
      "step": 6670
    },
    {
      "epoch": 0.26950154317874647,
      "grad_norm": 1.7369829416275024,
      "learning_rate": 0.00015965972234377235,
      "loss": 1.2737,
      "step": 6680
    },
    {
      "epoch": 0.26990498860266676,
      "grad_norm": 1.6655616760253906,
      "learning_rate": 0.00015962286645218794,
      "loss": 1.4659,
      "step": 6690
    },
    {
      "epoch": 0.27030843402658705,
      "grad_norm": 1.0265305042266846,
      "learning_rate": 0.0001595860105606035,
      "loss": 1.4042,
      "step": 6700
    },
    {
      "epoch": 0.27071187945050734,
      "grad_norm": 1.1418380737304688,
      "learning_rate": 0.00015954915466901903,
      "loss": 1.2444,
      "step": 6710
    },
    {
      "epoch": 0.27111532487442763,
      "grad_norm": 1.1335737705230713,
      "learning_rate": 0.0001595122987774346,
      "loss": 1.2928,
      "step": 6720
    },
    {
      "epoch": 0.27151877029834787,
      "grad_norm": 0.9479617476463318,
      "learning_rate": 0.00015947544288585019,
      "loss": 1.3624,
      "step": 6730
    },
    {
      "epoch": 0.27192221572226816,
      "grad_norm": 1.7006545066833496,
      "learning_rate": 0.00015943858699426575,
      "loss": 1.4359,
      "step": 6740
    },
    {
      "epoch": 0.27232566114618845,
      "grad_norm": 2.3040709495544434,
      "learning_rate": 0.0001594017311026813,
      "loss": 1.3766,
      "step": 6750
    },
    {
      "epoch": 0.27272910657010874,
      "grad_norm": 1.5032577514648438,
      "learning_rate": 0.00015936487521109687,
      "loss": 1.2243,
      "step": 6760
    },
    {
      "epoch": 0.273132551994029,
      "grad_norm": 1.2444758415222168,
      "learning_rate": 0.00015932801931951244,
      "loss": 1.4273,
      "step": 6770
    },
    {
      "epoch": 0.27353599741794926,
      "grad_norm": 1.2387052774429321,
      "learning_rate": 0.000159291163427928,
      "loss": 1.2908,
      "step": 6780
    },
    {
      "epoch": 0.27393944284186955,
      "grad_norm": 1.220395803451538,
      "learning_rate": 0.00015925430753634356,
      "loss": 1.2224,
      "step": 6790
    },
    {
      "epoch": 0.27434288826578984,
      "grad_norm": 1.6500095129013062,
      "learning_rate": 0.00015921745164475913,
      "loss": 1.3022,
      "step": 6800
    },
    {
      "epoch": 0.27434288826578984,
      "eval_loss": 1.302370309829712,
      "eval_runtime": 14.6109,
      "eval_samples_per_second": 3.422,
      "eval_steps_per_second": 1.711,
      "step": 6800
    },
    {
      "epoch": 0.27474633368971013,
      "grad_norm": 1.175686240196228,
      "learning_rate": 0.00015918059575317472,
      "loss": 1.2263,
      "step": 6810
    },
    {
      "epoch": 0.2751497791136304,
      "grad_norm": 1.7378053665161133,
      "learning_rate": 0.00015914373986159028,
      "loss": 1.3221,
      "step": 6820
    },
    {
      "epoch": 0.27555322453755066,
      "grad_norm": 0.9330139756202698,
      "learning_rate": 0.00015910688397000581,
      "loss": 1.2523,
      "step": 6830
    },
    {
      "epoch": 0.27595666996147095,
      "grad_norm": 1.0973097085952759,
      "learning_rate": 0.00015907002807842138,
      "loss": 1.3338,
      "step": 6840
    },
    {
      "epoch": 0.27636011538539124,
      "grad_norm": 1.1529425382614136,
      "learning_rate": 0.00015903317218683697,
      "loss": 1.3772,
      "step": 6850
    },
    {
      "epoch": 0.2767635608093115,
      "grad_norm": 1.2198582887649536,
      "learning_rate": 0.00015899631629525253,
      "loss": 1.4184,
      "step": 6860
    },
    {
      "epoch": 0.2771670062332318,
      "grad_norm": 1.097231149673462,
      "learning_rate": 0.0001589594604036681,
      "loss": 1.2543,
      "step": 6870
    },
    {
      "epoch": 0.2775704516571521,
      "grad_norm": 0.8519728779792786,
      "learning_rate": 0.00015892260451208365,
      "loss": 1.3378,
      "step": 6880
    },
    {
      "epoch": 0.27797389708107234,
      "grad_norm": 1.4173675775527954,
      "learning_rate": 0.00015888574862049922,
      "loss": 1.3848,
      "step": 6890
    },
    {
      "epoch": 0.27837734250499263,
      "grad_norm": 1.0898962020874023,
      "learning_rate": 0.00015884889272891478,
      "loss": 1.3594,
      "step": 6900
    },
    {
      "epoch": 0.2787807879289129,
      "grad_norm": 1.2746626138687134,
      "learning_rate": 0.00015881203683733034,
      "loss": 1.2753,
      "step": 6910
    },
    {
      "epoch": 0.2791842333528332,
      "grad_norm": 1.1981810331344604,
      "learning_rate": 0.0001587751809457459,
      "loss": 1.3397,
      "step": 6920
    },
    {
      "epoch": 0.2795876787767535,
      "grad_norm": 1.2736663818359375,
      "learning_rate": 0.0001587383250541615,
      "loss": 1.3052,
      "step": 6930
    },
    {
      "epoch": 0.27999112420067374,
      "grad_norm": 1.705830454826355,
      "learning_rate": 0.00015870146916257706,
      "loss": 1.2904,
      "step": 6940
    },
    {
      "epoch": 0.280394569624594,
      "grad_norm": 0.6809535026550293,
      "learning_rate": 0.00015866461327099262,
      "loss": 1.3011,
      "step": 6950
    },
    {
      "epoch": 0.2807980150485143,
      "grad_norm": 1.5823991298675537,
      "learning_rate": 0.00015862775737940816,
      "loss": 1.4697,
      "step": 6960
    },
    {
      "epoch": 0.2812014604724346,
      "grad_norm": 1.241456151008606,
      "learning_rate": 0.00015859090148782375,
      "loss": 1.3917,
      "step": 6970
    },
    {
      "epoch": 0.2816049058963549,
      "grad_norm": 1.9207581281661987,
      "learning_rate": 0.0001585540455962393,
      "loss": 1.3598,
      "step": 6980
    },
    {
      "epoch": 0.28200835132027513,
      "grad_norm": 2.4323816299438477,
      "learning_rate": 0.00015851718970465487,
      "loss": 1.3636,
      "step": 6990
    },
    {
      "epoch": 0.2824117967441954,
      "grad_norm": 1.1866576671600342,
      "learning_rate": 0.00015848033381307043,
      "loss": 1.2666,
      "step": 7000
    },
    {
      "epoch": 0.2824117967441954,
      "eval_loss": 1.3026607036590576,
      "eval_runtime": 14.5848,
      "eval_samples_per_second": 3.428,
      "eval_steps_per_second": 1.714,
      "step": 7000
    },
    {
      "epoch": 0.2828152421681157,
      "grad_norm": 1.5050411224365234,
      "learning_rate": 0.000158443477921486,
      "loss": 1.3246,
      "step": 7010
    },
    {
      "epoch": 0.283218687592036,
      "grad_norm": 1.4248549938201904,
      "learning_rate": 0.00015840662202990156,
      "loss": 1.2107,
      "step": 7020
    },
    {
      "epoch": 0.2836221330159563,
      "grad_norm": 1.1072092056274414,
      "learning_rate": 0.00015836976613831712,
      "loss": 1.3163,
      "step": 7030
    },
    {
      "epoch": 0.2840255784398765,
      "grad_norm": 1.0881555080413818,
      "learning_rate": 0.00015833291024673269,
      "loss": 1.3225,
      "step": 7040
    },
    {
      "epoch": 0.2844290238637968,
      "grad_norm": 1.4800914525985718,
      "learning_rate": 0.00015829605435514827,
      "loss": 1.3263,
      "step": 7050
    },
    {
      "epoch": 0.2848324692877171,
      "grad_norm": 1.5478116273880005,
      "learning_rate": 0.00015825919846356384,
      "loss": 1.3465,
      "step": 7060
    },
    {
      "epoch": 0.2852359147116374,
      "grad_norm": 1.3051308393478394,
      "learning_rate": 0.0001582223425719794,
      "loss": 1.4333,
      "step": 7070
    },
    {
      "epoch": 0.2856393601355577,
      "grad_norm": 1.5239641666412354,
      "learning_rate": 0.00015818548668039494,
      "loss": 1.3447,
      "step": 7080
    },
    {
      "epoch": 0.2860428055594779,
      "grad_norm": 1.073045253753662,
      "learning_rate": 0.00015814863078881053,
      "loss": 1.4043,
      "step": 7090
    },
    {
      "epoch": 0.2864462509833982,
      "grad_norm": 0.9982278943061829,
      "learning_rate": 0.0001581117748972261,
      "loss": 1.3131,
      "step": 7100
    },
    {
      "epoch": 0.2868496964073185,
      "grad_norm": 0.9543198943138123,
      "learning_rate": 0.00015807491900564165,
      "loss": 1.4951,
      "step": 7110
    },
    {
      "epoch": 0.2872531418312388,
      "grad_norm": 1.9549331665039062,
      "learning_rate": 0.00015803806311405721,
      "loss": 1.376,
      "step": 7120
    },
    {
      "epoch": 0.2876565872551591,
      "grad_norm": 1.3193929195404053,
      "learning_rate": 0.00015800120722247278,
      "loss": 1.3661,
      "step": 7130
    },
    {
      "epoch": 0.2880600326790793,
      "grad_norm": 1.6603482961654663,
      "learning_rate": 0.00015796435133088834,
      "loss": 1.4342,
      "step": 7140
    },
    {
      "epoch": 0.2884634781029996,
      "grad_norm": 1.0808360576629639,
      "learning_rate": 0.0001579274954393039,
      "loss": 1.3333,
      "step": 7150
    },
    {
      "epoch": 0.2888669235269199,
      "grad_norm": 1.4074066877365112,
      "learning_rate": 0.00015789063954771946,
      "loss": 1.3768,
      "step": 7160
    },
    {
      "epoch": 0.2892703689508402,
      "grad_norm": 1.0177525281906128,
      "learning_rate": 0.00015785378365613505,
      "loss": 1.2737,
      "step": 7170
    },
    {
      "epoch": 0.2896738143747605,
      "grad_norm": 1.067641258239746,
      "learning_rate": 0.00015781692776455062,
      "loss": 1.2626,
      "step": 7180
    },
    {
      "epoch": 0.2900772597986807,
      "grad_norm": 1.490696668624878,
      "learning_rate": 0.00015778007187296618,
      "loss": 1.2229,
      "step": 7190
    },
    {
      "epoch": 0.290480705222601,
      "grad_norm": 1.105446219444275,
      "learning_rate": 0.00015774321598138172,
      "loss": 1.1956,
      "step": 7200
    },
    {
      "epoch": 0.290480705222601,
      "eval_loss": 1.3056262731552124,
      "eval_runtime": 14.6001,
      "eval_samples_per_second": 3.425,
      "eval_steps_per_second": 1.712,
      "step": 7200
    },
    {
      "epoch": 0.2908841506465213,
      "grad_norm": 1.56402587890625,
      "learning_rate": 0.00015770636008979728,
      "loss": 1.2757,
      "step": 7210
    },
    {
      "epoch": 0.2912875960704416,
      "grad_norm": 1.5989902019500732,
      "learning_rate": 0.00015766950419821287,
      "loss": 1.3384,
      "step": 7220
    },
    {
      "epoch": 0.29169104149436187,
      "grad_norm": 1.3729084730148315,
      "learning_rate": 0.00015763264830662843,
      "loss": 1.3305,
      "step": 7230
    },
    {
      "epoch": 0.2920944869182821,
      "grad_norm": 1.0958055257797241,
      "learning_rate": 0.000157595792415044,
      "loss": 1.3656,
      "step": 7240
    },
    {
      "epoch": 0.2924979323422024,
      "grad_norm": 1.2716621160507202,
      "learning_rate": 0.00015755893652345956,
      "loss": 1.4332,
      "step": 7250
    },
    {
      "epoch": 0.2929013777661227,
      "grad_norm": 0.9040594696998596,
      "learning_rate": 0.00015752208063187512,
      "loss": 1.2507,
      "step": 7260
    },
    {
      "epoch": 0.293304823190043,
      "grad_norm": 0.8950817584991455,
      "learning_rate": 0.00015748522474029068,
      "loss": 1.2569,
      "step": 7270
    },
    {
      "epoch": 0.29370826861396326,
      "grad_norm": 2.0229785442352295,
      "learning_rate": 0.00015744836884870624,
      "loss": 1.3503,
      "step": 7280
    },
    {
      "epoch": 0.2941117140378835,
      "grad_norm": 1.22894287109375,
      "learning_rate": 0.0001574115129571218,
      "loss": 1.1709,
      "step": 7290
    },
    {
      "epoch": 0.2945151594618038,
      "grad_norm": 1.1958773136138916,
      "learning_rate": 0.0001573746570655374,
      "loss": 1.4005,
      "step": 7300
    },
    {
      "epoch": 0.2949186048857241,
      "grad_norm": 1.2408273220062256,
      "learning_rate": 0.00015733780117395296,
      "loss": 1.3018,
      "step": 7310
    },
    {
      "epoch": 0.29532205030964437,
      "grad_norm": 1.4614871740341187,
      "learning_rate": 0.00015730094528236852,
      "loss": 1.446,
      "step": 7320
    },
    {
      "epoch": 0.29572549573356466,
      "grad_norm": 1.2597159147262573,
      "learning_rate": 0.00015726408939078406,
      "loss": 1.2115,
      "step": 7330
    },
    {
      "epoch": 0.29612894115748495,
      "grad_norm": 1.3993654251098633,
      "learning_rate": 0.00015722723349919965,
      "loss": 1.2836,
      "step": 7340
    },
    {
      "epoch": 0.2965323865814052,
      "grad_norm": 1.2330666780471802,
      "learning_rate": 0.0001571903776076152,
      "loss": 1.4024,
      "step": 7350
    },
    {
      "epoch": 0.2969358320053255,
      "grad_norm": 1.0814471244812012,
      "learning_rate": 0.00015715352171603077,
      "loss": 1.3731,
      "step": 7360
    },
    {
      "epoch": 0.29733927742924576,
      "grad_norm": 1.5754188299179077,
      "learning_rate": 0.00015711666582444634,
      "loss": 1.3021,
      "step": 7370
    },
    {
      "epoch": 0.29774272285316605,
      "grad_norm": 1.3654625415802002,
      "learning_rate": 0.0001570798099328619,
      "loss": 1.2028,
      "step": 7380
    },
    {
      "epoch": 0.29814616827708634,
      "grad_norm": 1.340556263923645,
      "learning_rate": 0.00015704295404127746,
      "loss": 1.2705,
      "step": 7390
    },
    {
      "epoch": 0.2985496137010066,
      "grad_norm": 1.3227962255477905,
      "learning_rate": 0.00015700609814969302,
      "loss": 1.4003,
      "step": 7400
    },
    {
      "epoch": 0.2985496137010066,
      "eval_loss": 1.3046618700027466,
      "eval_runtime": 14.6,
      "eval_samples_per_second": 3.425,
      "eval_steps_per_second": 1.712,
      "step": 7400
    },
    {
      "epoch": 0.29895305912492687,
      "grad_norm": 0.9259518384933472,
      "learning_rate": 0.0001569692422581086,
      "loss": 1.3814,
      "step": 7410
    },
    {
      "epoch": 0.29935650454884716,
      "grad_norm": 0.9594405889511108,
      "learning_rate": 0.00015693238636652418,
      "loss": 1.3234,
      "step": 7420
    },
    {
      "epoch": 0.29975994997276745,
      "grad_norm": 1.0327074527740479,
      "learning_rate": 0.00015689553047493974,
      "loss": 1.1779,
      "step": 7430
    },
    {
      "epoch": 0.30016339539668774,
      "grad_norm": 1.6606215238571167,
      "learning_rate": 0.0001568586745833553,
      "loss": 1.4245,
      "step": 7440
    },
    {
      "epoch": 0.300566840820608,
      "grad_norm": 0.9388776421546936,
      "learning_rate": 0.00015682181869177084,
      "loss": 1.255,
      "step": 7450
    },
    {
      "epoch": 0.30097028624452826,
      "grad_norm": 1.2535606622695923,
      "learning_rate": 0.00015678496280018643,
      "loss": 1.365,
      "step": 7460
    },
    {
      "epoch": 0.30137373166844855,
      "grad_norm": 1.299981713294983,
      "learning_rate": 0.000156748106908602,
      "loss": 1.4582,
      "step": 7470
    },
    {
      "epoch": 0.30177717709236884,
      "grad_norm": 1.1043246984481812,
      "learning_rate": 0.00015671125101701755,
      "loss": 1.2849,
      "step": 7480
    },
    {
      "epoch": 0.30218062251628913,
      "grad_norm": 1.1073235273361206,
      "learning_rate": 0.00015667439512543312,
      "loss": 1.2735,
      "step": 7490
    },
    {
      "epoch": 0.30258406794020937,
      "grad_norm": 1.1974983215332031,
      "learning_rate": 0.00015663753923384868,
      "loss": 1.4603,
      "step": 7500
    },
    {
      "epoch": 0.30298751336412966,
      "grad_norm": 1.3288947343826294,
      "learning_rate": 0.00015660068334226424,
      "loss": 1.3296,
      "step": 7510
    },
    {
      "epoch": 0.30339095878804995,
      "grad_norm": 0.9569342732429504,
      "learning_rate": 0.0001565638274506798,
      "loss": 1.4322,
      "step": 7520
    },
    {
      "epoch": 0.30379440421197024,
      "grad_norm": 1.545423150062561,
      "learning_rate": 0.00015652697155909537,
      "loss": 1.329,
      "step": 7530
    },
    {
      "epoch": 0.3041978496358905,
      "grad_norm": 1.2103095054626465,
      "learning_rate": 0.00015649011566751096,
      "loss": 1.2451,
      "step": 7540
    },
    {
      "epoch": 0.30460129505981076,
      "grad_norm": 1.480891227722168,
      "learning_rate": 0.00015645325977592652,
      "loss": 1.1313,
      "step": 7550
    },
    {
      "epoch": 0.30500474048373105,
      "grad_norm": 1.1896501779556274,
      "learning_rate": 0.00015641640388434208,
      "loss": 1.3842,
      "step": 7560
    },
    {
      "epoch": 0.30540818590765134,
      "grad_norm": 1.705754280090332,
      "learning_rate": 0.00015637954799275762,
      "loss": 1.4018,
      "step": 7570
    },
    {
      "epoch": 0.30581163133157163,
      "grad_norm": 0.9663447737693787,
      "learning_rate": 0.0001563426921011732,
      "loss": 1.3882,
      "step": 7580
    },
    {
      "epoch": 0.3062150767554919,
      "grad_norm": 1.3986517190933228,
      "learning_rate": 0.00015630583620958877,
      "loss": 1.2659,
      "step": 7590
    },
    {
      "epoch": 0.30661852217941216,
      "grad_norm": 2.0771572589874268,
      "learning_rate": 0.00015626898031800433,
      "loss": 1.2788,
      "step": 7600
    },
    {
      "epoch": 0.30661852217941216,
      "eval_loss": 1.3053855895996094,
      "eval_runtime": 14.5598,
      "eval_samples_per_second": 3.434,
      "eval_steps_per_second": 1.717,
      "step": 7600
    },
    {
      "epoch": 0.30702196760333245,
      "grad_norm": 1.9114725589752197,
      "learning_rate": 0.0001562321244264199,
      "loss": 1.2367,
      "step": 7610
    },
    {
      "epoch": 0.30742541302725274,
      "grad_norm": 1.2885570526123047,
      "learning_rate": 0.00015619526853483546,
      "loss": 1.2999,
      "step": 7620
    },
    {
      "epoch": 0.307828858451173,
      "grad_norm": 1.111116647720337,
      "learning_rate": 0.00015615841264325102,
      "loss": 1.2666,
      "step": 7630
    },
    {
      "epoch": 0.3082323038750933,
      "grad_norm": 1.003159523010254,
      "learning_rate": 0.00015612155675166658,
      "loss": 1.3339,
      "step": 7640
    },
    {
      "epoch": 0.30863574929901355,
      "grad_norm": 1.1741735935211182,
      "learning_rate": 0.00015608470086008215,
      "loss": 1.1879,
      "step": 7650
    },
    {
      "epoch": 0.30903919472293384,
      "grad_norm": 1.1622836589813232,
      "learning_rate": 0.00015604784496849774,
      "loss": 1.4183,
      "step": 7660
    },
    {
      "epoch": 0.30944264014685413,
      "grad_norm": 1.0310382843017578,
      "learning_rate": 0.0001560109890769133,
      "loss": 1.4094,
      "step": 7670
    },
    {
      "epoch": 0.3098460855707744,
      "grad_norm": 0.9814184308052063,
      "learning_rate": 0.00015597413318532886,
      "loss": 1.2169,
      "step": 7680
    },
    {
      "epoch": 0.3102495309946947,
      "grad_norm": 1.3106087446212769,
      "learning_rate": 0.00015593727729374443,
      "loss": 1.285,
      "step": 7690
    },
    {
      "epoch": 0.31065297641861495,
      "grad_norm": 1.3434655666351318,
      "learning_rate": 0.00015590042140216,
      "loss": 1.2903,
      "step": 7700
    },
    {
      "epoch": 0.31105642184253524,
      "grad_norm": 1.3675222396850586,
      "learning_rate": 0.00015586356551057555,
      "loss": 1.4427,
      "step": 7710
    },
    {
      "epoch": 0.3114598672664555,
      "grad_norm": 0.9011361002922058,
      "learning_rate": 0.0001558267096189911,
      "loss": 1.1655,
      "step": 7720
    },
    {
      "epoch": 0.3118633126903758,
      "grad_norm": 1.1160658597946167,
      "learning_rate": 0.00015578985372740668,
      "loss": 1.357,
      "step": 7730
    },
    {
      "epoch": 0.3122667581142961,
      "grad_norm": 1.3922265768051147,
      "learning_rate": 0.00015575299783582227,
      "loss": 1.2817,
      "step": 7740
    },
    {
      "epoch": 0.31267020353821634,
      "grad_norm": 1.2112723588943481,
      "learning_rate": 0.0001557161419442378,
      "loss": 1.3658,
      "step": 7750
    },
    {
      "epoch": 0.31307364896213663,
      "grad_norm": 1.5365502834320068,
      "learning_rate": 0.00015567928605265336,
      "loss": 1.4954,
      "step": 7760
    },
    {
      "epoch": 0.3134770943860569,
      "grad_norm": 1.201857328414917,
      "learning_rate": 0.00015564243016106893,
      "loss": 1.3514,
      "step": 7770
    },
    {
      "epoch": 0.3138805398099772,
      "grad_norm": 1.2670130729675293,
      "learning_rate": 0.00015560557426948452,
      "loss": 1.2215,
      "step": 7780
    },
    {
      "epoch": 0.3142839852338975,
      "grad_norm": 1.1323472261428833,
      "learning_rate": 0.00015556871837790008,
      "loss": 1.3819,
      "step": 7790
    },
    {
      "epoch": 0.3146874306578178,
      "grad_norm": 1.7345610857009888,
      "learning_rate": 0.00015553186248631564,
      "loss": 1.2841,
      "step": 7800
    },
    {
      "epoch": 0.3146874306578178,
      "eval_loss": 1.3052458763122559,
      "eval_runtime": 14.57,
      "eval_samples_per_second": 3.432,
      "eval_steps_per_second": 1.716,
      "step": 7800
    },
    {
      "epoch": 0.315090876081738,
      "grad_norm": 0.9643093943595886,
      "learning_rate": 0.0001554950065947312,
      "loss": 1.3782,
      "step": 7810
    },
    {
      "epoch": 0.3154943215056583,
      "grad_norm": 1.5001622438430786,
      "learning_rate": 0.00015545815070314677,
      "loss": 1.2987,
      "step": 7820
    },
    {
      "epoch": 0.3158977669295786,
      "grad_norm": 1.0145984888076782,
      "learning_rate": 0.00015542129481156233,
      "loss": 1.1639,
      "step": 7830
    },
    {
      "epoch": 0.3163012123534989,
      "grad_norm": 1.0105570554733276,
      "learning_rate": 0.0001553844389199779,
      "loss": 1.253,
      "step": 7840
    },
    {
      "epoch": 0.3167046577774192,
      "grad_norm": 1.8848044872283936,
      "learning_rate": 0.00015534758302839346,
      "loss": 1.395,
      "step": 7850
    },
    {
      "epoch": 0.3171081032013394,
      "grad_norm": 1.5656148195266724,
      "learning_rate": 0.00015531072713680905,
      "loss": 1.3577,
      "step": 7860
    },
    {
      "epoch": 0.3175115486252597,
      "grad_norm": 1.1204462051391602,
      "learning_rate": 0.00015527387124522458,
      "loss": 1.4755,
      "step": 7870
    },
    {
      "epoch": 0.31791499404918,
      "grad_norm": 1.5785313844680786,
      "learning_rate": 0.00015523701535364014,
      "loss": 1.2863,
      "step": 7880
    },
    {
      "epoch": 0.3183184394731003,
      "grad_norm": 1.003930926322937,
      "learning_rate": 0.0001552001594620557,
      "loss": 1.2851,
      "step": 7890
    },
    {
      "epoch": 0.3187218848970206,
      "grad_norm": 1.2300317287445068,
      "learning_rate": 0.0001551633035704713,
      "loss": 1.3006,
      "step": 7900
    },
    {
      "epoch": 0.3191253303209408,
      "grad_norm": 1.2335717678070068,
      "learning_rate": 0.00015512644767888686,
      "loss": 1.3018,
      "step": 7910
    },
    {
      "epoch": 0.3195287757448611,
      "grad_norm": 1.113757610321045,
      "learning_rate": 0.00015508959178730242,
      "loss": 1.3818,
      "step": 7920
    },
    {
      "epoch": 0.3199322211687814,
      "grad_norm": 1.949290156364441,
      "learning_rate": 0.00015505273589571798,
      "loss": 1.3951,
      "step": 7930
    },
    {
      "epoch": 0.3203356665927017,
      "grad_norm": 0.9252040982246399,
      "learning_rate": 0.00015501588000413355,
      "loss": 1.4043,
      "step": 7940
    },
    {
      "epoch": 0.320739112016622,
      "grad_norm": 1.653998851776123,
      "learning_rate": 0.0001549790241125491,
      "loss": 1.2469,
      "step": 7950
    },
    {
      "epoch": 0.3211425574405422,
      "grad_norm": 1.406692624092102,
      "learning_rate": 0.00015494216822096467,
      "loss": 1.2761,
      "step": 7960
    },
    {
      "epoch": 0.3215460028644625,
      "grad_norm": 0.9480929970741272,
      "learning_rate": 0.00015490531232938024,
      "loss": 1.6834,
      "step": 7970
    },
    {
      "epoch": 0.3219494482883828,
      "grad_norm": 1.232021450996399,
      "learning_rate": 0.00015486845643779583,
      "loss": 1.3121,
      "step": 7980
    },
    {
      "epoch": 0.3223528937123031,
      "grad_norm": 1.249879240989685,
      "learning_rate": 0.00015483160054621136,
      "loss": 1.3203,
      "step": 7990
    },
    {
      "epoch": 0.32275633913622337,
      "grad_norm": 1.2122706174850464,
      "learning_rate": 0.00015479474465462692,
      "loss": 1.4275,
      "step": 8000
    },
    {
      "epoch": 0.32275633913622337,
      "eval_loss": 1.3054215908050537,
      "eval_runtime": 14.5907,
      "eval_samples_per_second": 3.427,
      "eval_steps_per_second": 1.713,
      "step": 8000
    },
    {
      "epoch": 0.3231597845601436,
      "grad_norm": 1.7130955457687378,
      "learning_rate": 0.0001547578887630425,
      "loss": 1.4972,
      "step": 8010
    },
    {
      "epoch": 0.3235632299840639,
      "grad_norm": 1.227062702178955,
      "learning_rate": 0.00015472103287145808,
      "loss": 1.2229,
      "step": 8020
    },
    {
      "epoch": 0.3239666754079842,
      "grad_norm": 1.4262324571609497,
      "learning_rate": 0.00015468417697987364,
      "loss": 1.4649,
      "step": 8030
    },
    {
      "epoch": 0.3243701208319045,
      "grad_norm": 1.4215726852416992,
      "learning_rate": 0.0001546473210882892,
      "loss": 1.2328,
      "step": 8040
    },
    {
      "epoch": 0.32477356625582476,
      "grad_norm": 1.5271096229553223,
      "learning_rate": 0.00015461046519670476,
      "loss": 1.4576,
      "step": 8050
    },
    {
      "epoch": 0.325177011679745,
      "grad_norm": 1.5832374095916748,
      "learning_rate": 0.00015457360930512033,
      "loss": 1.2519,
      "step": 8060
    },
    {
      "epoch": 0.3255804571036653,
      "grad_norm": 1.3850716352462769,
      "learning_rate": 0.0001545367534135359,
      "loss": 1.2697,
      "step": 8070
    },
    {
      "epoch": 0.3259839025275856,
      "grad_norm": 1.2816880941390991,
      "learning_rate": 0.00015449989752195145,
      "loss": 1.4321,
      "step": 8080
    },
    {
      "epoch": 0.32638734795150587,
      "grad_norm": 1.0610978603363037,
      "learning_rate": 0.00015446304163036702,
      "loss": 1.2455,
      "step": 8090
    },
    {
      "epoch": 0.32679079337542616,
      "grad_norm": 1.1246960163116455,
      "learning_rate": 0.0001544261857387826,
      "loss": 1.3874,
      "step": 8100
    },
    {
      "epoch": 0.3271942387993464,
      "grad_norm": 1.1654863357543945,
      "learning_rate": 0.00015438932984719817,
      "loss": 1.2109,
      "step": 8110
    },
    {
      "epoch": 0.3275976842232667,
      "grad_norm": 1.2142282724380493,
      "learning_rate": 0.0001543524739556137,
      "loss": 1.3707,
      "step": 8120
    },
    {
      "epoch": 0.328001129647187,
      "grad_norm": 1.5812315940856934,
      "learning_rate": 0.00015431561806402927,
      "loss": 1.2556,
      "step": 8130
    },
    {
      "epoch": 0.32840457507110726,
      "grad_norm": 1.4821072816848755,
      "learning_rate": 0.00015427876217244486,
      "loss": 1.3701,
      "step": 8140
    },
    {
      "epoch": 0.32880802049502755,
      "grad_norm": 1.3738051652908325,
      "learning_rate": 0.00015424190628086042,
      "loss": 1.5407,
      "step": 8150
    },
    {
      "epoch": 0.3292114659189478,
      "grad_norm": 1.4110187292099,
      "learning_rate": 0.00015420505038927598,
      "loss": 1.2965,
      "step": 8160
    },
    {
      "epoch": 0.3296149113428681,
      "grad_norm": 1.2946187257766724,
      "learning_rate": 0.00015416819449769154,
      "loss": 1.3484,
      "step": 8170
    },
    {
      "epoch": 0.33001835676678837,
      "grad_norm": 1.1159769296646118,
      "learning_rate": 0.0001541313386061071,
      "loss": 1.3722,
      "step": 8180
    },
    {
      "epoch": 0.33042180219070866,
      "grad_norm": 1.431317687034607,
      "learning_rate": 0.00015409448271452267,
      "loss": 1.4052,
      "step": 8190
    },
    {
      "epoch": 0.33082524761462895,
      "grad_norm": 0.9810423254966736,
      "learning_rate": 0.00015405762682293823,
      "loss": 1.3528,
      "step": 8200
    },
    {
      "epoch": 0.33082524761462895,
      "eval_loss": 1.2981550693511963,
      "eval_runtime": 14.5767,
      "eval_samples_per_second": 3.43,
      "eval_steps_per_second": 1.715,
      "step": 8200
    },
    {
      "epoch": 0.33122869303854924,
      "grad_norm": 0.9072335362434387,
      "learning_rate": 0.0001540207709313538,
      "loss": 1.4108,
      "step": 8210
    },
    {
      "epoch": 0.3316321384624695,
      "grad_norm": 1.0045045614242554,
      "learning_rate": 0.00015398391503976939,
      "loss": 1.1685,
      "step": 8220
    },
    {
      "epoch": 0.33203558388638976,
      "grad_norm": 1.2080128192901611,
      "learning_rate": 0.00015394705914818495,
      "loss": 1.2677,
      "step": 8230
    },
    {
      "epoch": 0.33243902931031005,
      "grad_norm": 2.568943977355957,
      "learning_rate": 0.00015391020325660048,
      "loss": 1.399,
      "step": 8240
    },
    {
      "epoch": 0.33284247473423034,
      "grad_norm": 2.4845521450042725,
      "learning_rate": 0.00015387334736501605,
      "loss": 1.3259,
      "step": 8250
    },
    {
      "epoch": 0.33324592015815063,
      "grad_norm": 1.2774425745010376,
      "learning_rate": 0.00015383649147343164,
      "loss": 1.4824,
      "step": 8260
    },
    {
      "epoch": 0.33364936558207087,
      "grad_norm": 1.0626078844070435,
      "learning_rate": 0.0001537996355818472,
      "loss": 1.204,
      "step": 8270
    },
    {
      "epoch": 0.33405281100599116,
      "grad_norm": 1.3973534107208252,
      "learning_rate": 0.00015376277969026276,
      "loss": 1.366,
      "step": 8280
    },
    {
      "epoch": 0.33445625642991145,
      "grad_norm": 1.0597350597381592,
      "learning_rate": 0.00015372592379867832,
      "loss": 1.3604,
      "step": 8290
    },
    {
      "epoch": 0.33485970185383174,
      "grad_norm": 1.0734130144119263,
      "learning_rate": 0.0001536890679070939,
      "loss": 1.3812,
      "step": 8300
    },
    {
      "epoch": 0.335263147277752,
      "grad_norm": 0.9235755801200867,
      "learning_rate": 0.00015365221201550945,
      "loss": 1.2965,
      "step": 8310
    },
    {
      "epoch": 0.33566659270167226,
      "grad_norm": 1.5412136316299438,
      "learning_rate": 0.000153615356123925,
      "loss": 1.3884,
      "step": 8320
    },
    {
      "epoch": 0.33607003812559255,
      "grad_norm": 0.9610098600387573,
      "learning_rate": 0.00015357850023234058,
      "loss": 1.2653,
      "step": 8330
    },
    {
      "epoch": 0.33647348354951284,
      "grad_norm": 1.1368498802185059,
      "learning_rate": 0.00015354164434075616,
      "loss": 1.195,
      "step": 8340
    },
    {
      "epoch": 0.33687692897343313,
      "grad_norm": 1.043028473854065,
      "learning_rate": 0.00015350478844917173,
      "loss": 1.2693,
      "step": 8350
    },
    {
      "epoch": 0.3372803743973534,
      "grad_norm": 1.9982839822769165,
      "learning_rate": 0.00015346793255758726,
      "loss": 1.4555,
      "step": 8360
    },
    {
      "epoch": 0.33768381982127366,
      "grad_norm": 1.605973482131958,
      "learning_rate": 0.00015343107666600283,
      "loss": 1.2658,
      "step": 8370
    },
    {
      "epoch": 0.33808726524519395,
      "grad_norm": 2.196894884109497,
      "learning_rate": 0.0001533942207744184,
      "loss": 1.4026,
      "step": 8380
    },
    {
      "epoch": 0.33849071066911424,
      "grad_norm": 1.6145834922790527,
      "learning_rate": 0.00015335736488283398,
      "loss": 1.3273,
      "step": 8390
    },
    {
      "epoch": 0.3388941560930345,
      "grad_norm": 1.06155264377594,
      "learning_rate": 0.00015332050899124954,
      "loss": 1.1896,
      "step": 8400
    },
    {
      "epoch": 0.3388941560930345,
      "eval_loss": 1.2991557121276855,
      "eval_runtime": 14.6048,
      "eval_samples_per_second": 3.424,
      "eval_steps_per_second": 1.712,
      "step": 8400
    },
    {
      "epoch": 0.3392976015169548,
      "grad_norm": 1.2431309223175049,
      "learning_rate": 0.0001532836530996651,
      "loss": 1.2353,
      "step": 8410
    },
    {
      "epoch": 0.33970104694087505,
      "grad_norm": 1.0543075799942017,
      "learning_rate": 0.00015324679720808067,
      "loss": 1.3079,
      "step": 8420
    },
    {
      "epoch": 0.34010449236479534,
      "grad_norm": 1.009321689605713,
      "learning_rate": 0.00015320994131649623,
      "loss": 1.3943,
      "step": 8430
    },
    {
      "epoch": 0.34050793778871563,
      "grad_norm": 1.8214068412780762,
      "learning_rate": 0.0001531730854249118,
      "loss": 1.3672,
      "step": 8440
    },
    {
      "epoch": 0.3409113832126359,
      "grad_norm": 1.673352837562561,
      "learning_rate": 0.00015313622953332735,
      "loss": 1.3168,
      "step": 8450
    },
    {
      "epoch": 0.3413148286365562,
      "grad_norm": 1.257371425628662,
      "learning_rate": 0.00015309937364174292,
      "loss": 1.2941,
      "step": 8460
    },
    {
      "epoch": 0.34171827406047645,
      "grad_norm": 1.4110370874404907,
      "learning_rate": 0.0001530625177501585,
      "loss": 1.3029,
      "step": 8470
    },
    {
      "epoch": 0.34212171948439674,
      "grad_norm": 1.0607682466506958,
      "learning_rate": 0.00015302566185857407,
      "loss": 1.5328,
      "step": 8480
    },
    {
      "epoch": 0.342525164908317,
      "grad_norm": 1.7136369943618774,
      "learning_rate": 0.0001529888059669896,
      "loss": 1.2957,
      "step": 8490
    },
    {
      "epoch": 0.3429286103322373,
      "grad_norm": 1.9162499904632568,
      "learning_rate": 0.00015295195007540517,
      "loss": 1.4095,
      "step": 8500
    },
    {
      "epoch": 0.3433320557561576,
      "grad_norm": 1.1724399328231812,
      "learning_rate": 0.00015291509418382076,
      "loss": 1.3721,
      "step": 8510
    },
    {
      "epoch": 0.34373550118007784,
      "grad_norm": 1.48875892162323,
      "learning_rate": 0.00015287823829223632,
      "loss": 1.4819,
      "step": 8520
    },
    {
      "epoch": 0.34413894660399813,
      "grad_norm": 1.2805196046829224,
      "learning_rate": 0.00015284138240065188,
      "loss": 1.1924,
      "step": 8530
    },
    {
      "epoch": 0.3445423920279184,
      "grad_norm": 2.026782274246216,
      "learning_rate": 0.00015280452650906745,
      "loss": 1.3301,
      "step": 8540
    },
    {
      "epoch": 0.3449458374518387,
      "grad_norm": 1.3978705406188965,
      "learning_rate": 0.000152767670617483,
      "loss": 1.4737,
      "step": 8550
    },
    {
      "epoch": 0.345349282875759,
      "grad_norm": 1.9493275880813599,
      "learning_rate": 0.00015273081472589857,
      "loss": 1.3832,
      "step": 8560
    },
    {
      "epoch": 0.34575272829967924,
      "grad_norm": 1.0752320289611816,
      "learning_rate": 0.00015269395883431413,
      "loss": 1.5251,
      "step": 8570
    },
    {
      "epoch": 0.3461561737235995,
      "grad_norm": 1.806758165359497,
      "learning_rate": 0.0001526571029427297,
      "loss": 1.5034,
      "step": 8580
    },
    {
      "epoch": 0.3465596191475198,
      "grad_norm": 1.211056113243103,
      "learning_rate": 0.0001526202470511453,
      "loss": 1.2318,
      "step": 8590
    },
    {
      "epoch": 0.3469630645714401,
      "grad_norm": 1.2338658571243286,
      "learning_rate": 0.00015258339115956085,
      "loss": 1.2748,
      "step": 8600
    },
    {
      "epoch": 0.3469630645714401,
      "eval_loss": 1.3001331090927124,
      "eval_runtime": 14.5865,
      "eval_samples_per_second": 3.428,
      "eval_steps_per_second": 1.714,
      "step": 8600
    },
    {
      "epoch": 0.3473665099953604,
      "grad_norm": 1.6222809553146362,
      "learning_rate": 0.00015254653526797639,
      "loss": 1.3376,
      "step": 8610
    },
    {
      "epoch": 0.34776995541928063,
      "grad_norm": 1.7238526344299316,
      "learning_rate": 0.00015250967937639195,
      "loss": 1.3097,
      "step": 8620
    },
    {
      "epoch": 0.3481734008432009,
      "grad_norm": 1.1679861545562744,
      "learning_rate": 0.00015247282348480754,
      "loss": 1.2657,
      "step": 8630
    },
    {
      "epoch": 0.3485768462671212,
      "grad_norm": 1.002614974975586,
      "learning_rate": 0.0001524359675932231,
      "loss": 1.128,
      "step": 8640
    },
    {
      "epoch": 0.3489802916910415,
      "grad_norm": 1.390554428100586,
      "learning_rate": 0.00015239911170163866,
      "loss": 1.3786,
      "step": 8650
    },
    {
      "epoch": 0.3493837371149618,
      "grad_norm": 1.2349284887313843,
      "learning_rate": 0.00015236225581005423,
      "loss": 1.3421,
      "step": 8660
    },
    {
      "epoch": 0.3497871825388821,
      "grad_norm": 1.0645002126693726,
      "learning_rate": 0.0001523253999184698,
      "loss": 1.2203,
      "step": 8670
    },
    {
      "epoch": 0.3501906279628023,
      "grad_norm": 0.8742120265960693,
      "learning_rate": 0.00015228854402688535,
      "loss": 1.3076,
      "step": 8680
    },
    {
      "epoch": 0.3505940733867226,
      "grad_norm": 1.0232254266738892,
      "learning_rate": 0.00015225168813530091,
      "loss": 1.2475,
      "step": 8690
    },
    {
      "epoch": 0.3509975188106429,
      "grad_norm": 1.307518482208252,
      "learning_rate": 0.00015221483224371648,
      "loss": 1.4428,
      "step": 8700
    },
    {
      "epoch": 0.3514009642345632,
      "grad_norm": 0.9941036105155945,
      "learning_rate": 0.00015217797635213207,
      "loss": 1.2521,
      "step": 8710
    },
    {
      "epoch": 0.3518044096584835,
      "grad_norm": 1.2011868953704834,
      "learning_rate": 0.00015214112046054763,
      "loss": 1.4544,
      "step": 8720
    },
    {
      "epoch": 0.3522078550824037,
      "grad_norm": 2.4222378730773926,
      "learning_rate": 0.00015210426456896317,
      "loss": 1.4758,
      "step": 8730
    },
    {
      "epoch": 0.352611300506324,
      "grad_norm": 1.0442754030227661,
      "learning_rate": 0.00015206740867737873,
      "loss": 1.175,
      "step": 8740
    },
    {
      "epoch": 0.3530147459302443,
      "grad_norm": 1.2923524379730225,
      "learning_rate": 0.00015203055278579432,
      "loss": 1.4583,
      "step": 8750
    },
    {
      "epoch": 0.3534181913541646,
      "grad_norm": 1.7139897346496582,
      "learning_rate": 0.00015199369689420988,
      "loss": 1.3082,
      "step": 8760
    },
    {
      "epoch": 0.35382163677808487,
      "grad_norm": 1.1587193012237549,
      "learning_rate": 0.00015195684100262544,
      "loss": 1.3775,
      "step": 8770
    },
    {
      "epoch": 0.3542250822020051,
      "grad_norm": 1.3194184303283691,
      "learning_rate": 0.000151919985111041,
      "loss": 1.3972,
      "step": 8780
    },
    {
      "epoch": 0.3546285276259254,
      "grad_norm": 0.994456946849823,
      "learning_rate": 0.00015188312921945657,
      "loss": 1.3368,
      "step": 8790
    },
    {
      "epoch": 0.3550319730498457,
      "grad_norm": 1.2352256774902344,
      "learning_rate": 0.00015184627332787213,
      "loss": 1.262,
      "step": 8800
    },
    {
      "epoch": 0.3550319730498457,
      "eval_loss": 1.2929203510284424,
      "eval_runtime": 14.5869,
      "eval_samples_per_second": 3.428,
      "eval_steps_per_second": 1.714,
      "step": 8800
    },
    {
      "epoch": 0.355435418473766,
      "grad_norm": 1.0001436471939087,
      "learning_rate": 0.0001518094174362877,
      "loss": 1.4034,
      "step": 8810
    },
    {
      "epoch": 0.35583886389768626,
      "grad_norm": 1.4469537734985352,
      "learning_rate": 0.00015177256154470326,
      "loss": 1.275,
      "step": 8820
    },
    {
      "epoch": 0.3562423093216065,
      "grad_norm": 1.5077258348464966,
      "learning_rate": 0.00015173570565311885,
      "loss": 1.43,
      "step": 8830
    },
    {
      "epoch": 0.3566457547455268,
      "grad_norm": 1.2960126399993896,
      "learning_rate": 0.0001516988497615344,
      "loss": 1.3934,
      "step": 8840
    },
    {
      "epoch": 0.3570492001694471,
      "grad_norm": 1.4879038333892822,
      "learning_rate": 0.00015166199386994995,
      "loss": 1.304,
      "step": 8850
    },
    {
      "epoch": 0.35745264559336737,
      "grad_norm": 1.3830082416534424,
      "learning_rate": 0.0001516251379783655,
      "loss": 1.2505,
      "step": 8860
    },
    {
      "epoch": 0.35785609101728766,
      "grad_norm": 1.1874029636383057,
      "learning_rate": 0.0001515882820867811,
      "loss": 1.3608,
      "step": 8870
    },
    {
      "epoch": 0.3582595364412079,
      "grad_norm": 1.0965654850006104,
      "learning_rate": 0.00015155142619519666,
      "loss": 1.2956,
      "step": 8880
    },
    {
      "epoch": 0.3586629818651282,
      "grad_norm": 2.118492364883423,
      "learning_rate": 0.00015151457030361222,
      "loss": 1.3434,
      "step": 8890
    },
    {
      "epoch": 0.3590664272890485,
      "grad_norm": 1.4053168296813965,
      "learning_rate": 0.00015147771441202779,
      "loss": 1.2151,
      "step": 8900
    },
    {
      "epoch": 0.35946987271296876,
      "grad_norm": 1.1963515281677246,
      "learning_rate": 0.00015144085852044335,
      "loss": 1.3269,
      "step": 8910
    },
    {
      "epoch": 0.35987331813688905,
      "grad_norm": 1.4064241647720337,
      "learning_rate": 0.0001514040026288589,
      "loss": 1.2745,
      "step": 8920
    },
    {
      "epoch": 0.3602767635608093,
      "grad_norm": 1.3586238622665405,
      "learning_rate": 0.00015136714673727447,
      "loss": 1.3455,
      "step": 8930
    },
    {
      "epoch": 0.3606802089847296,
      "grad_norm": 1.4648780822753906,
      "learning_rate": 0.00015133029084569004,
      "loss": 1.3839,
      "step": 8940
    },
    {
      "epoch": 0.36108365440864987,
      "grad_norm": 1.5256025791168213,
      "learning_rate": 0.00015129343495410563,
      "loss": 1.3125,
      "step": 8950
    },
    {
      "epoch": 0.36148709983257016,
      "grad_norm": 0.9185281991958618,
      "learning_rate": 0.0001512565790625212,
      "loss": 1.3315,
      "step": 8960
    },
    {
      "epoch": 0.36189054525649045,
      "grad_norm": 0.9873983860015869,
      "learning_rate": 0.00015121972317093675,
      "loss": 1.31,
      "step": 8970
    },
    {
      "epoch": 0.3622939906804107,
      "grad_norm": 1.5222935676574707,
      "learning_rate": 0.0001511828672793523,
      "loss": 1.3472,
      "step": 8980
    },
    {
      "epoch": 0.362697436104331,
      "grad_norm": 1.7348766326904297,
      "learning_rate": 0.00015114601138776788,
      "loss": 1.2382,
      "step": 8990
    },
    {
      "epoch": 0.36310088152825126,
      "grad_norm": 1.5030759572982788,
      "learning_rate": 0.00015110915549618344,
      "loss": 1.3164,
      "step": 9000
    },
    {
      "epoch": 0.36310088152825126,
      "eval_loss": 1.2987998723983765,
      "eval_runtime": 14.5715,
      "eval_samples_per_second": 3.431,
      "eval_steps_per_second": 1.716,
      "step": 9000
    },
    {
      "epoch": 0.36350432695217155,
      "grad_norm": 1.0733202695846558,
      "learning_rate": 0.000151072299604599,
      "loss": 1.2985,
      "step": 9010
    },
    {
      "epoch": 0.36390777237609184,
      "grad_norm": 1.2317214012145996,
      "learning_rate": 0.00015103544371301457,
      "loss": 1.3839,
      "step": 9020
    },
    {
      "epoch": 0.3643112178000121,
      "grad_norm": 1.2238720655441284,
      "learning_rate": 0.00015099858782143013,
      "loss": 1.1948,
      "step": 9030
    },
    {
      "epoch": 0.36471466322393237,
      "grad_norm": 1.0949779748916626,
      "learning_rate": 0.0001509617319298457,
      "loss": 1.3321,
      "step": 9040
    },
    {
      "epoch": 0.36511810864785266,
      "grad_norm": 1.8065919876098633,
      "learning_rate": 0.00015092487603826125,
      "loss": 1.3165,
      "step": 9050
    },
    {
      "epoch": 0.36552155407177295,
      "grad_norm": 1.340982437133789,
      "learning_rate": 0.00015088802014667682,
      "loss": 1.3429,
      "step": 9060
    },
    {
      "epoch": 0.36592499949569324,
      "grad_norm": 1.5281308889389038,
      "learning_rate": 0.0001508511642550924,
      "loss": 1.242,
      "step": 9070
    },
    {
      "epoch": 0.36632844491961347,
      "grad_norm": 1.0822166204452515,
      "learning_rate": 0.00015081430836350797,
      "loss": 1.3232,
      "step": 9080
    },
    {
      "epoch": 0.36673189034353376,
      "grad_norm": 0.9281970262527466,
      "learning_rate": 0.00015077745247192353,
      "loss": 1.2345,
      "step": 9090
    },
    {
      "epoch": 0.36713533576745405,
      "grad_norm": 1.2511019706726074,
      "learning_rate": 0.00015074059658033907,
      "loss": 1.2888,
      "step": 9100
    },
    {
      "epoch": 0.36753878119137434,
      "grad_norm": 0.9578696489334106,
      "learning_rate": 0.00015070374068875466,
      "loss": 1.1875,
      "step": 9110
    },
    {
      "epoch": 0.36794222661529463,
      "grad_norm": 1.431504726409912,
      "learning_rate": 0.00015066688479717022,
      "loss": 1.5897,
      "step": 9120
    },
    {
      "epoch": 0.3683456720392149,
      "grad_norm": 1.6647710800170898,
      "learning_rate": 0.00015063002890558578,
      "loss": 1.3755,
      "step": 9130
    },
    {
      "epoch": 0.36874911746313516,
      "grad_norm": 2.1214632987976074,
      "learning_rate": 0.00015059317301400135,
      "loss": 1.1868,
      "step": 9140
    },
    {
      "epoch": 0.36915256288705545,
      "grad_norm": 1.4914888143539429,
      "learning_rate": 0.0001505563171224169,
      "loss": 1.3379,
      "step": 9150
    },
    {
      "epoch": 0.36955600831097574,
      "grad_norm": 1.0506417751312256,
      "learning_rate": 0.00015051946123083247,
      "loss": 1.2571,
      "step": 9160
    },
    {
      "epoch": 0.369959453734896,
      "grad_norm": 1.5164510011672974,
      "learning_rate": 0.00015048260533924803,
      "loss": 1.3802,
      "step": 9170
    },
    {
      "epoch": 0.3703628991588163,
      "grad_norm": 1.8821706771850586,
      "learning_rate": 0.0001504457494476636,
      "loss": 1.2267,
      "step": 9180
    },
    {
      "epoch": 0.37076634458273655,
      "grad_norm": 1.5387517213821411,
      "learning_rate": 0.0001504088935560792,
      "loss": 1.3119,
      "step": 9190
    },
    {
      "epoch": 0.37116979000665684,
      "grad_norm": 1.1796683073043823,
      "learning_rate": 0.00015037203766449475,
      "loss": 1.3353,
      "step": 9200
    },
    {
      "epoch": 0.37116979000665684,
      "eval_loss": 1.299026370048523,
      "eval_runtime": 14.5894,
      "eval_samples_per_second": 3.427,
      "eval_steps_per_second": 1.714,
      "step": 9200
    },
    {
      "epoch": 0.37157323543057713,
      "grad_norm": 1.555233120918274,
      "learning_rate": 0.0001503351817729103,
      "loss": 1.3044,
      "step": 9210
    },
    {
      "epoch": 0.3719766808544974,
      "grad_norm": 1.510833978652954,
      "learning_rate": 0.00015029832588132585,
      "loss": 1.268,
      "step": 9220
    },
    {
      "epoch": 0.3723801262784177,
      "grad_norm": 1.1569507122039795,
      "learning_rate": 0.00015026146998974144,
      "loss": 1.4116,
      "step": 9230
    },
    {
      "epoch": 0.37278357170233795,
      "grad_norm": 1.303889274597168,
      "learning_rate": 0.000150224614098157,
      "loss": 1.3143,
      "step": 9240
    },
    {
      "epoch": 0.37318701712625824,
      "grad_norm": 0.9044002890586853,
      "learning_rate": 0.00015018775820657256,
      "loss": 1.381,
      "step": 9250
    },
    {
      "epoch": 0.3735904625501785,
      "grad_norm": 1.0845547914505005,
      "learning_rate": 0.00015015090231498813,
      "loss": 1.1801,
      "step": 9260
    },
    {
      "epoch": 0.3739939079740988,
      "grad_norm": 0.9850345849990845,
      "learning_rate": 0.0001501140464234037,
      "loss": 1.2755,
      "step": 9270
    },
    {
      "epoch": 0.3743973533980191,
      "grad_norm": 1.2393457889556885,
      "learning_rate": 0.00015007719053181925,
      "loss": 1.3271,
      "step": 9280
    },
    {
      "epoch": 0.37480079882193934,
      "grad_norm": 1.274374008178711,
      "learning_rate": 0.00015004033464023481,
      "loss": 1.4508,
      "step": 9290
    },
    {
      "epoch": 0.37520424424585963,
      "grad_norm": 1.42509126663208,
      "learning_rate": 0.00015000347874865038,
      "loss": 1.3088,
      "step": 9300
    },
    {
      "epoch": 0.3756076896697799,
      "grad_norm": 0.8854919075965881,
      "learning_rate": 0.00014996662285706597,
      "loss": 1.2725,
      "step": 9310
    },
    {
      "epoch": 0.3760111350937002,
      "grad_norm": 1.756007194519043,
      "learning_rate": 0.00014992976696548153,
      "loss": 1.4441,
      "step": 9320
    },
    {
      "epoch": 0.3764145805176205,
      "grad_norm": 1.219397783279419,
      "learning_rate": 0.0001498929110738971,
      "loss": 1.287,
      "step": 9330
    },
    {
      "epoch": 0.37681802594154074,
      "grad_norm": 1.0971859693527222,
      "learning_rate": 0.00014985605518231265,
      "loss": 1.1619,
      "step": 9340
    },
    {
      "epoch": 0.377221471365461,
      "grad_norm": 1.081896424293518,
      "learning_rate": 0.00014981919929072822,
      "loss": 1.3665,
      "step": 9350
    },
    {
      "epoch": 0.3776249167893813,
      "grad_norm": 0.9793527722358704,
      "learning_rate": 0.00014978234339914378,
      "loss": 1.3903,
      "step": 9360
    },
    {
      "epoch": 0.3780283622133016,
      "grad_norm": 1.2317183017730713,
      "learning_rate": 0.00014974548750755934,
      "loss": 1.2041,
      "step": 9370
    },
    {
      "epoch": 0.3784318076372219,
      "grad_norm": 1.2016080617904663,
      "learning_rate": 0.0001497086316159749,
      "loss": 1.1915,
      "step": 9380
    },
    {
      "epoch": 0.37883525306114213,
      "grad_norm": 1.1777726411819458,
      "learning_rate": 0.0001496717757243905,
      "loss": 1.3938,
      "step": 9390
    },
    {
      "epoch": 0.3792386984850624,
      "grad_norm": 1.0999153852462769,
      "learning_rate": 0.00014963491983280603,
      "loss": 1.1677,
      "step": 9400
    },
    {
      "epoch": 0.3792386984850624,
      "eval_loss": 1.2972561120986938,
      "eval_runtime": 14.5903,
      "eval_samples_per_second": 3.427,
      "eval_steps_per_second": 1.713,
      "step": 9400
    },
    {
      "epoch": 0.3796421439089827,
      "grad_norm": 1.2032524347305298,
      "learning_rate": 0.0001495980639412216,
      "loss": 1.3417,
      "step": 9410
    },
    {
      "epoch": 0.380045589332903,
      "grad_norm": 1.093268632888794,
      "learning_rate": 0.00014956120804963716,
      "loss": 1.3518,
      "step": 9420
    },
    {
      "epoch": 0.3804490347568233,
      "grad_norm": 1.2515366077423096,
      "learning_rate": 0.00014952435215805275,
      "loss": 1.4313,
      "step": 9430
    },
    {
      "epoch": 0.3808524801807435,
      "grad_norm": 1.4465267658233643,
      "learning_rate": 0.0001494874962664683,
      "loss": 1.3818,
      "step": 9440
    },
    {
      "epoch": 0.3812559256046638,
      "grad_norm": 1.4131255149841309,
      "learning_rate": 0.00014945064037488387,
      "loss": 1.3013,
      "step": 9450
    },
    {
      "epoch": 0.3816593710285841,
      "grad_norm": 1.0978307723999023,
      "learning_rate": 0.00014941378448329943,
      "loss": 1.2304,
      "step": 9460
    },
    {
      "epoch": 0.3820628164525044,
      "grad_norm": 1.7138919830322266,
      "learning_rate": 0.000149376928591715,
      "loss": 1.2326,
      "step": 9470
    },
    {
      "epoch": 0.3824662618764247,
      "grad_norm": 1.3186619281768799,
      "learning_rate": 0.00014934007270013056,
      "loss": 1.2376,
      "step": 9480
    },
    {
      "epoch": 0.3828697073003449,
      "grad_norm": 1.3403630256652832,
      "learning_rate": 0.00014930321680854612,
      "loss": 1.2665,
      "step": 9490
    },
    {
      "epoch": 0.3832731527242652,
      "grad_norm": 1.0092346668243408,
      "learning_rate": 0.00014926636091696169,
      "loss": 1.3269,
      "step": 9500
    },
    {
      "epoch": 0.3836765981481855,
      "grad_norm": 0.9258514046669006,
      "learning_rate": 0.00014922950502537725,
      "loss": 1.2583,
      "step": 9510
    },
    {
      "epoch": 0.3840800435721058,
      "grad_norm": 1.3347275257110596,
      "learning_rate": 0.0001491926491337928,
      "loss": 1.2911,
      "step": 9520
    },
    {
      "epoch": 0.3844834889960261,
      "grad_norm": 1.683173418045044,
      "learning_rate": 0.00014915579324220837,
      "loss": 1.3889,
      "step": 9530
    },
    {
      "epoch": 0.38488693441994637,
      "grad_norm": 1.8002578020095825,
      "learning_rate": 0.00014911893735062394,
      "loss": 1.6381,
      "step": 9540
    },
    {
      "epoch": 0.3852903798438666,
      "grad_norm": 2.3903441429138184,
      "learning_rate": 0.0001490820814590395,
      "loss": 1.2652,
      "step": 9550
    },
    {
      "epoch": 0.3856938252677869,
      "grad_norm": 1.688773274421692,
      "learning_rate": 0.0001490452255674551,
      "loss": 1.2457,
      "step": 9560
    },
    {
      "epoch": 0.3860972706917072,
      "grad_norm": 0.8172098994255066,
      "learning_rate": 0.00014900836967587065,
      "loss": 1.4659,
      "step": 9570
    },
    {
      "epoch": 0.3865007161156275,
      "grad_norm": 1.0103784799575806,
      "learning_rate": 0.00014897151378428621,
      "loss": 1.4808,
      "step": 9580
    },
    {
      "epoch": 0.38690416153954776,
      "grad_norm": 1.0055145025253296,
      "learning_rate": 0.00014893465789270175,
      "loss": 1.196,
      "step": 9590
    },
    {
      "epoch": 0.387307606963468,
      "grad_norm": 0.8680290579795837,
      "learning_rate": 0.00014889780200111734,
      "loss": 1.4738,
      "step": 9600
    },
    {
      "epoch": 0.387307606963468,
      "eval_loss": 1.2974014282226562,
      "eval_runtime": 14.5956,
      "eval_samples_per_second": 3.426,
      "eval_steps_per_second": 1.713,
      "step": 9600
    },
    {
      "epoch": 0.3877110523873883,
      "grad_norm": 2.6059584617614746,
      "learning_rate": 0.0001488609461095329,
      "loss": 1.2175,
      "step": 9610
    },
    {
      "epoch": 0.3881144978113086,
      "grad_norm": 0.8279848694801331,
      "learning_rate": 0.00014882409021794847,
      "loss": 1.4287,
      "step": 9620
    },
    {
      "epoch": 0.38851794323522887,
      "grad_norm": 1.3128116130828857,
      "learning_rate": 0.00014878723432636403,
      "loss": 1.3696,
      "step": 9630
    },
    {
      "epoch": 0.38892138865914916,
      "grad_norm": 1.397477626800537,
      "learning_rate": 0.0001487503784347796,
      "loss": 1.3852,
      "step": 9640
    },
    {
      "epoch": 0.3893248340830694,
      "grad_norm": 1.7294507026672363,
      "learning_rate": 0.00014871352254319515,
      "loss": 1.3768,
      "step": 9650
    },
    {
      "epoch": 0.3897282795069897,
      "grad_norm": 1.4077092409133911,
      "learning_rate": 0.00014867666665161072,
      "loss": 1.3102,
      "step": 9660
    },
    {
      "epoch": 0.39013172493091,
      "grad_norm": 1.1016572713851929,
      "learning_rate": 0.00014863981076002628,
      "loss": 1.3073,
      "step": 9670
    },
    {
      "epoch": 0.39053517035483026,
      "grad_norm": 1.4327484369277954,
      "learning_rate": 0.00014860295486844187,
      "loss": 1.2915,
      "step": 9680
    },
    {
      "epoch": 0.39093861577875055,
      "grad_norm": 0.7923521995544434,
      "learning_rate": 0.00014856609897685743,
      "loss": 1.2294,
      "step": 9690
    },
    {
      "epoch": 0.3913420612026708,
      "grad_norm": 1.1203832626342773,
      "learning_rate": 0.000148529243085273,
      "loss": 1.4371,
      "step": 9700
    },
    {
      "epoch": 0.3917455066265911,
      "grad_norm": 1.2706019878387451,
      "learning_rate": 0.00014849238719368856,
      "loss": 1.4159,
      "step": 9710
    },
    {
      "epoch": 0.39214895205051137,
      "grad_norm": 1.1917059421539307,
      "learning_rate": 0.00014845553130210412,
      "loss": 1.4245,
      "step": 9720
    },
    {
      "epoch": 0.39255239747443166,
      "grad_norm": 1.0402902364730835,
      "learning_rate": 0.00014841867541051968,
      "loss": 1.4254,
      "step": 9730
    },
    {
      "epoch": 0.39295584289835195,
      "grad_norm": 1.1268408298492432,
      "learning_rate": 0.00014838181951893524,
      "loss": 1.2251,
      "step": 9740
    },
    {
      "epoch": 0.3933592883222722,
      "grad_norm": 1.176422357559204,
      "learning_rate": 0.0001483449636273508,
      "loss": 1.1674,
      "step": 9750
    },
    {
      "epoch": 0.3937627337461925,
      "grad_norm": 1.0096123218536377,
      "learning_rate": 0.0001483081077357664,
      "loss": 1.3853,
      "step": 9760
    },
    {
      "epoch": 0.39416617917011276,
      "grad_norm": 1.4906525611877441,
      "learning_rate": 0.00014827125184418193,
      "loss": 1.3377,
      "step": 9770
    },
    {
      "epoch": 0.39456962459403305,
      "grad_norm": 1.3843872547149658,
      "learning_rate": 0.0001482343959525975,
      "loss": 1.3618,
      "step": 9780
    },
    {
      "epoch": 0.39497307001795334,
      "grad_norm": 1.256363034248352,
      "learning_rate": 0.00014819754006101306,
      "loss": 1.3173,
      "step": 9790
    },
    {
      "epoch": 0.3953765154418736,
      "grad_norm": 1.3507535457611084,
      "learning_rate": 0.00014816068416942865,
      "loss": 1.3241,
      "step": 9800
    },
    {
      "epoch": 0.3953765154418736,
      "eval_loss": 1.2953858375549316,
      "eval_runtime": 14.5831,
      "eval_samples_per_second": 3.429,
      "eval_steps_per_second": 1.714,
      "step": 9800
    },
    {
      "epoch": 0.39577996086579387,
      "grad_norm": 1.8634183406829834,
      "learning_rate": 0.0001481238282778442,
      "loss": 1.3497,
      "step": 9810
    },
    {
      "epoch": 0.39618340628971416,
      "grad_norm": 1.086287260055542,
      "learning_rate": 0.00014808697238625977,
      "loss": 1.2675,
      "step": 9820
    },
    {
      "epoch": 0.39658685171363445,
      "grad_norm": 1.583961009979248,
      "learning_rate": 0.00014805011649467534,
      "loss": 1.2753,
      "step": 9830
    },
    {
      "epoch": 0.39699029713755474,
      "grad_norm": 1.126283049583435,
      "learning_rate": 0.0001480132606030909,
      "loss": 1.3689,
      "step": 9840
    },
    {
      "epoch": 0.39739374256147497,
      "grad_norm": 0.9325582981109619,
      "learning_rate": 0.00014797640471150646,
      "loss": 1.2927,
      "step": 9850
    },
    {
      "epoch": 0.39779718798539526,
      "grad_norm": 0.907645583152771,
      "learning_rate": 0.00014793954881992202,
      "loss": 1.4325,
      "step": 9860
    },
    {
      "epoch": 0.39820063340931555,
      "grad_norm": 1.3166073560714722,
      "learning_rate": 0.0001479026929283376,
      "loss": 1.2925,
      "step": 9870
    },
    {
      "epoch": 0.39860407883323584,
      "grad_norm": 1.1921125650405884,
      "learning_rate": 0.00014786583703675318,
      "loss": 1.3418,
      "step": 9880
    },
    {
      "epoch": 0.39900752425715613,
      "grad_norm": 1.0269770622253418,
      "learning_rate": 0.0001478289811451687,
      "loss": 1.3942,
      "step": 9890
    },
    {
      "epoch": 0.39941096968107637,
      "grad_norm": 1.099066138267517,
      "learning_rate": 0.00014779212525358428,
      "loss": 1.3205,
      "step": 9900
    },
    {
      "epoch": 0.39981441510499666,
      "grad_norm": 1.8999252319335938,
      "learning_rate": 0.00014775526936199984,
      "loss": 1.1957,
      "step": 9910
    },
    {
      "epoch": 0.40021786052891695,
      "grad_norm": 1.3712540864944458,
      "learning_rate": 0.00014771841347041543,
      "loss": 1.3335,
      "step": 9920
    },
    {
      "epoch": 0.40062130595283724,
      "grad_norm": 1.1994205713272095,
      "learning_rate": 0.000147681557578831,
      "loss": 1.2194,
      "step": 9930
    },
    {
      "epoch": 0.4010247513767575,
      "grad_norm": 1.747434377670288,
      "learning_rate": 0.00014764470168724655,
      "loss": 1.2912,
      "step": 9940
    },
    {
      "epoch": 0.40142819680067776,
      "grad_norm": 1.723501205444336,
      "learning_rate": 0.00014760784579566212,
      "loss": 1.2902,
      "step": 9950
    },
    {
      "epoch": 0.40183164222459805,
      "grad_norm": 1.094935655593872,
      "learning_rate": 0.00014757098990407768,
      "loss": 1.1899,
      "step": 9960
    },
    {
      "epoch": 0.40223508764851834,
      "grad_norm": 1.3761564493179321,
      "learning_rate": 0.00014753413401249324,
      "loss": 1.1712,
      "step": 9970
    },
    {
      "epoch": 0.40263853307243863,
      "grad_norm": 1.330179214477539,
      "learning_rate": 0.0001474972781209088,
      "loss": 1.3459,
      "step": 9980
    },
    {
      "epoch": 0.4030419784963589,
      "grad_norm": 1.8763461112976074,
      "learning_rate": 0.00014746042222932437,
      "loss": 1.4956,
      "step": 9990
    },
    {
      "epoch": 0.4034454239202792,
      "grad_norm": 1.140716314315796,
      "learning_rate": 0.00014742356633773996,
      "loss": 1.572,
      "step": 10000
    },
    {
      "epoch": 0.4034454239202792,
      "eval_loss": 1.303328037261963,
      "eval_runtime": 14.5713,
      "eval_samples_per_second": 3.431,
      "eval_steps_per_second": 1.716,
      "step": 10000
    },
    {
      "epoch": 0.40384886934419945,
      "grad_norm": 0.9192447066307068,
      "learning_rate": 0.0001473867104461555,
      "loss": 1.2586,
      "step": 10010
    },
    {
      "epoch": 0.40425231476811974,
      "grad_norm": 1.1359633207321167,
      "learning_rate": 0.00014734985455457106,
      "loss": 1.3979,
      "step": 10020
    },
    {
      "epoch": 0.40465576019204,
      "grad_norm": 1.1601680517196655,
      "learning_rate": 0.00014731299866298662,
      "loss": 1.4963,
      "step": 10030
    },
    {
      "epoch": 0.4050592056159603,
      "grad_norm": 1.261702537536621,
      "learning_rate": 0.0001472761427714022,
      "loss": 1.4174,
      "step": 10040
    },
    {
      "epoch": 0.4054626510398806,
      "grad_norm": 2.4922261238098145,
      "learning_rate": 0.00014723928687981777,
      "loss": 1.2008,
      "step": 10050
    },
    {
      "epoch": 0.40586609646380084,
      "grad_norm": 1.5060789585113525,
      "learning_rate": 0.00014720243098823333,
      "loss": 1.4947,
      "step": 10060
    },
    {
      "epoch": 0.40626954188772113,
      "grad_norm": 0.9200893044471741,
      "learning_rate": 0.0001471655750966489,
      "loss": 1.2111,
      "step": 10070
    },
    {
      "epoch": 0.4066729873116414,
      "grad_norm": 1.3618241548538208,
      "learning_rate": 0.00014712871920506446,
      "loss": 1.0972,
      "step": 10080
    },
    {
      "epoch": 0.4070764327355617,
      "grad_norm": 1.5799131393432617,
      "learning_rate": 0.00014709186331348002,
      "loss": 1.3175,
      "step": 10090
    },
    {
      "epoch": 0.407479878159482,
      "grad_norm": 1.0237160921096802,
      "learning_rate": 0.00014705500742189558,
      "loss": 1.5031,
      "step": 10100
    },
    {
      "epoch": 0.40788332358340224,
      "grad_norm": 1.2864114046096802,
      "learning_rate": 0.00014701815153031115,
      "loss": 1.4578,
      "step": 10110
    },
    {
      "epoch": 0.4082867690073225,
      "grad_norm": 0.8915481567382812,
      "learning_rate": 0.00014698129563872674,
      "loss": 1.2642,
      "step": 10120
    },
    {
      "epoch": 0.4086902144312428,
      "grad_norm": 1.1325926780700684,
      "learning_rate": 0.0001469444397471423,
      "loss": 1.354,
      "step": 10130
    },
    {
      "epoch": 0.4090936598551631,
      "grad_norm": 1.3654546737670898,
      "learning_rate": 0.00014690758385555784,
      "loss": 1.313,
      "step": 10140
    },
    {
      "epoch": 0.4094971052790834,
      "grad_norm": 1.4449520111083984,
      "learning_rate": 0.0001468707279639734,
      "loss": 1.1879,
      "step": 10150
    },
    {
      "epoch": 0.40990055070300363,
      "grad_norm": 1.04892897605896,
      "learning_rate": 0.000146833872072389,
      "loss": 1.3525,
      "step": 10160
    },
    {
      "epoch": 0.4103039961269239,
      "grad_norm": 1.0938856601715088,
      "learning_rate": 0.00014679701618080455,
      "loss": 1.1995,
      "step": 10170
    },
    {
      "epoch": 0.4107074415508442,
      "grad_norm": 1.2961803674697876,
      "learning_rate": 0.0001467601602892201,
      "loss": 1.2442,
      "step": 10180
    },
    {
      "epoch": 0.4111108869747645,
      "grad_norm": 1.159192681312561,
      "learning_rate": 0.00014672330439763568,
      "loss": 1.2921,
      "step": 10190
    },
    {
      "epoch": 0.4115143323986848,
      "grad_norm": 0.8997477889060974,
      "learning_rate": 0.00014668644850605124,
      "loss": 1.3501,
      "step": 10200
    },
    {
      "epoch": 0.4115143323986848,
      "eval_loss": 1.3007832765579224,
      "eval_runtime": 14.5657,
      "eval_samples_per_second": 3.433,
      "eval_steps_per_second": 1.716,
      "step": 10200
    },
    {
      "epoch": 0.411917777822605,
      "grad_norm": 1.646801471710205,
      "learning_rate": 0.0001466495926144668,
      "loss": 1.4171,
      "step": 10210
    },
    {
      "epoch": 0.4123212232465253,
      "grad_norm": 1.1113221645355225,
      "learning_rate": 0.00014661273672288236,
      "loss": 1.2491,
      "step": 10220
    },
    {
      "epoch": 0.4127246686704456,
      "grad_norm": 1.5523762702941895,
      "learning_rate": 0.00014657588083129793,
      "loss": 1.3439,
      "step": 10230
    },
    {
      "epoch": 0.4131281140943659,
      "grad_norm": 1.0541666746139526,
      "learning_rate": 0.00014653902493971352,
      "loss": 1.2086,
      "step": 10240
    },
    {
      "epoch": 0.4135315595182862,
      "grad_norm": 1.6080423593521118,
      "learning_rate": 0.00014650216904812908,
      "loss": 1.3629,
      "step": 10250
    },
    {
      "epoch": 0.4139350049422064,
      "grad_norm": 1.721057653427124,
      "learning_rate": 0.00014646531315654462,
      "loss": 1.3613,
      "step": 10260
    },
    {
      "epoch": 0.4143384503661267,
      "grad_norm": 1.3772850036621094,
      "learning_rate": 0.00014642845726496018,
      "loss": 1.3416,
      "step": 10270
    },
    {
      "epoch": 0.414741895790047,
      "grad_norm": 1.067160964012146,
      "learning_rate": 0.00014639160137337577,
      "loss": 1.3016,
      "step": 10280
    },
    {
      "epoch": 0.4151453412139673,
      "grad_norm": 1.290299892425537,
      "learning_rate": 0.00014635474548179133,
      "loss": 1.199,
      "step": 10290
    },
    {
      "epoch": 0.4155487866378876,
      "grad_norm": 1.658653974533081,
      "learning_rate": 0.0001463178895902069,
      "loss": 1.4028,
      "step": 10300
    },
    {
      "epoch": 0.4159522320618078,
      "grad_norm": 1.2083064317703247,
      "learning_rate": 0.00014628103369862246,
      "loss": 1.342,
      "step": 10310
    },
    {
      "epoch": 0.4163556774857281,
      "grad_norm": 1.165695071220398,
      "learning_rate": 0.00014624417780703802,
      "loss": 1.2466,
      "step": 10320
    },
    {
      "epoch": 0.4167591229096484,
      "grad_norm": 1.8802355527877808,
      "learning_rate": 0.00014620732191545358,
      "loss": 1.343,
      "step": 10330
    },
    {
      "epoch": 0.4171625683335687,
      "grad_norm": 0.7769120931625366,
      "learning_rate": 0.00014617046602386914,
      "loss": 1.3571,
      "step": 10340
    },
    {
      "epoch": 0.417566013757489,
      "grad_norm": 0.947441577911377,
      "learning_rate": 0.0001461336101322847,
      "loss": 1.2786,
      "step": 10350
    },
    {
      "epoch": 0.4179694591814092,
      "grad_norm": 1.251344084739685,
      "learning_rate": 0.0001460967542407003,
      "loss": 1.309,
      "step": 10360
    },
    {
      "epoch": 0.4183729046053295,
      "grad_norm": 1.5103814601898193,
      "learning_rate": 0.00014605989834911586,
      "loss": 1.3474,
      "step": 10370
    },
    {
      "epoch": 0.4187763500292498,
      "grad_norm": 1.224741816520691,
      "learning_rate": 0.0001460230424575314,
      "loss": 1.2488,
      "step": 10380
    },
    {
      "epoch": 0.4191797954531701,
      "grad_norm": 1.3933109045028687,
      "learning_rate": 0.00014598618656594696,
      "loss": 1.4292,
      "step": 10390
    },
    {
      "epoch": 0.41958324087709037,
      "grad_norm": 1.3068081140518188,
      "learning_rate": 0.00014594933067436255,
      "loss": 1.3609,
      "step": 10400
    },
    {
      "epoch": 0.41958324087709037,
      "eval_loss": 1.2996975183486938,
      "eval_runtime": 14.5723,
      "eval_samples_per_second": 3.431,
      "eval_steps_per_second": 1.716,
      "step": 10400
    },
    {
      "epoch": 0.4199866863010106,
      "grad_norm": 1.1851561069488525,
      "learning_rate": 0.0001459124747827781,
      "loss": 1.343,
      "step": 10410
    },
    {
      "epoch": 0.4203901317249309,
      "grad_norm": 1.0693289041519165,
      "learning_rate": 0.00014587561889119367,
      "loss": 1.4766,
      "step": 10420
    },
    {
      "epoch": 0.4207935771488512,
      "grad_norm": 1.2720890045166016,
      "learning_rate": 0.00014583876299960924,
      "loss": 1.1482,
      "step": 10430
    },
    {
      "epoch": 0.4211970225727715,
      "grad_norm": 1.715301275253296,
      "learning_rate": 0.0001458019071080248,
      "loss": 1.3566,
      "step": 10440
    },
    {
      "epoch": 0.42160046799669176,
      "grad_norm": 1.5547029972076416,
      "learning_rate": 0.00014576505121644036,
      "loss": 1.6674,
      "step": 10450
    },
    {
      "epoch": 0.42200391342061205,
      "grad_norm": 1.5340209007263184,
      "learning_rate": 0.00014572819532485592,
      "loss": 1.4705,
      "step": 10460
    },
    {
      "epoch": 0.4224073588445323,
      "grad_norm": 1.9725557565689087,
      "learning_rate": 0.0001456913394332715,
      "loss": 1.3239,
      "step": 10470
    },
    {
      "epoch": 0.4228108042684526,
      "grad_norm": 1.2985285520553589,
      "learning_rate": 0.00014565448354168708,
      "loss": 1.3299,
      "step": 10480
    },
    {
      "epoch": 0.42321424969237287,
      "grad_norm": 1.1696882247924805,
      "learning_rate": 0.00014561762765010264,
      "loss": 1.23,
      "step": 10490
    },
    {
      "epoch": 0.42361769511629316,
      "grad_norm": 1.655707836151123,
      "learning_rate": 0.0001455807717585182,
      "loss": 1.3593,
      "step": 10500
    },
    {
      "epoch": 0.42402114054021345,
      "grad_norm": 1.0490436553955078,
      "learning_rate": 0.00014554391586693374,
      "loss": 1.25,
      "step": 10510
    },
    {
      "epoch": 0.4244245859641337,
      "grad_norm": 2.223924160003662,
      "learning_rate": 0.00014550705997534933,
      "loss": 1.3481,
      "step": 10520
    },
    {
      "epoch": 0.424828031388054,
      "grad_norm": 1.037245512008667,
      "learning_rate": 0.0001454702040837649,
      "loss": 1.2897,
      "step": 10530
    },
    {
      "epoch": 0.42523147681197426,
      "grad_norm": 1.0835472345352173,
      "learning_rate": 0.00014543334819218045,
      "loss": 1.3445,
      "step": 10540
    },
    {
      "epoch": 0.42563492223589455,
      "grad_norm": 1.1812076568603516,
      "learning_rate": 0.00014539649230059602,
      "loss": 1.3609,
      "step": 10550
    },
    {
      "epoch": 0.42603836765981484,
      "grad_norm": 2.2722623348236084,
      "learning_rate": 0.00014535963640901158,
      "loss": 1.3671,
      "step": 10560
    },
    {
      "epoch": 0.4264418130837351,
      "grad_norm": 1.2148429155349731,
      "learning_rate": 0.00014532278051742714,
      "loss": 1.2887,
      "step": 10570
    },
    {
      "epoch": 0.42684525850765537,
      "grad_norm": 1.1180411577224731,
      "learning_rate": 0.0001452859246258427,
      "loss": 1.6387,
      "step": 10580
    },
    {
      "epoch": 0.42724870393157566,
      "grad_norm": 1.346792459487915,
      "learning_rate": 0.00014524906873425827,
      "loss": 1.3336,
      "step": 10590
    },
    {
      "epoch": 0.42765214935549595,
      "grad_norm": 2.065547227859497,
      "learning_rate": 0.00014521221284267386,
      "loss": 1.2517,
      "step": 10600
    },
    {
      "epoch": 0.42765214935549595,
      "eval_loss": 1.2975757122039795,
      "eval_runtime": 14.5658,
      "eval_samples_per_second": 3.433,
      "eval_steps_per_second": 1.716,
      "step": 10600
    },
    {
      "epoch": 0.42805559477941624,
      "grad_norm": 2.325618028640747,
      "learning_rate": 0.00014517535695108942,
      "loss": 1.392,
      "step": 10610
    },
    {
      "epoch": 0.42845904020333647,
      "grad_norm": 2.2579567432403564,
      "learning_rate": 0.00014513850105950498,
      "loss": 1.2724,
      "step": 10620
    },
    {
      "epoch": 0.42886248562725676,
      "grad_norm": 1.2964810132980347,
      "learning_rate": 0.00014510164516792052,
      "loss": 1.2876,
      "step": 10630
    },
    {
      "epoch": 0.42926593105117705,
      "grad_norm": 1.3300546407699585,
      "learning_rate": 0.0001450647892763361,
      "loss": 1.4343,
      "step": 10640
    },
    {
      "epoch": 0.42966937647509734,
      "grad_norm": 1.1825368404388428,
      "learning_rate": 0.00014502793338475167,
      "loss": 1.2879,
      "step": 10650
    },
    {
      "epoch": 0.43007282189901763,
      "grad_norm": 1.13877272605896,
      "learning_rate": 0.00014499107749316723,
      "loss": 1.3378,
      "step": 10660
    },
    {
      "epoch": 0.43047626732293787,
      "grad_norm": 1.0820084810256958,
      "learning_rate": 0.0001449542216015828,
      "loss": 1.2664,
      "step": 10670
    },
    {
      "epoch": 0.43087971274685816,
      "grad_norm": 1.5133036375045776,
      "learning_rate": 0.00014491736570999836,
      "loss": 1.2301,
      "step": 10680
    },
    {
      "epoch": 0.43128315817077845,
      "grad_norm": 1.0128307342529297,
      "learning_rate": 0.00014488050981841392,
      "loss": 1.3594,
      "step": 10690
    },
    {
      "epoch": 0.43168660359469874,
      "grad_norm": 1.469217300415039,
      "learning_rate": 0.00014484365392682948,
      "loss": 1.5531,
      "step": 10700
    },
    {
      "epoch": 0.432090049018619,
      "grad_norm": 1.2627283334732056,
      "learning_rate": 0.00014480679803524505,
      "loss": 1.2852,
      "step": 10710
    },
    {
      "epoch": 0.43249349444253926,
      "grad_norm": 0.9425804615020752,
      "learning_rate": 0.0001447699421436606,
      "loss": 1.2067,
      "step": 10720
    },
    {
      "epoch": 0.43289693986645955,
      "grad_norm": 1.2510391473770142,
      "learning_rate": 0.0001447330862520762,
      "loss": 1.2785,
      "step": 10730
    },
    {
      "epoch": 0.43330038529037984,
      "grad_norm": 1.2636810541152954,
      "learning_rate": 0.00014469623036049176,
      "loss": 1.2872,
      "step": 10740
    },
    {
      "epoch": 0.43370383071430013,
      "grad_norm": 1.391834020614624,
      "learning_rate": 0.0001446593744689073,
      "loss": 1.1897,
      "step": 10750
    },
    {
      "epoch": 0.4341072761382204,
      "grad_norm": 1.0193017721176147,
      "learning_rate": 0.00014462251857732286,
      "loss": 1.2801,
      "step": 10760
    },
    {
      "epoch": 0.43451072156214066,
      "grad_norm": 0.8363711833953857,
      "learning_rate": 0.00014458566268573845,
      "loss": 1.2484,
      "step": 10770
    },
    {
      "epoch": 0.43491416698606095,
      "grad_norm": 0.9403505921363831,
      "learning_rate": 0.000144548806794154,
      "loss": 1.4636,
      "step": 10780
    },
    {
      "epoch": 0.43531761240998124,
      "grad_norm": 2.107142686843872,
      "learning_rate": 0.00014451195090256958,
      "loss": 1.2322,
      "step": 10790
    },
    {
      "epoch": 0.4357210578339015,
      "grad_norm": 1.2793025970458984,
      "learning_rate": 0.00014447509501098514,
      "loss": 1.3377,
      "step": 10800
    },
    {
      "epoch": 0.4357210578339015,
      "eval_loss": 1.2952293157577515,
      "eval_runtime": 14.5952,
      "eval_samples_per_second": 3.426,
      "eval_steps_per_second": 1.713,
      "step": 10800
    },
    {
      "epoch": 0.4361245032578218,
      "grad_norm": 1.0733047723770142,
      "learning_rate": 0.0001444382391194007,
      "loss": 1.3712,
      "step": 10810
    },
    {
      "epoch": 0.43652794868174205,
      "grad_norm": 0.9843810796737671,
      "learning_rate": 0.00014440138322781626,
      "loss": 1.2525,
      "step": 10820
    },
    {
      "epoch": 0.43693139410566234,
      "grad_norm": 1.453837275505066,
      "learning_rate": 0.00014436452733623183,
      "loss": 1.2247,
      "step": 10830
    },
    {
      "epoch": 0.43733483952958263,
      "grad_norm": 1.1058765649795532,
      "learning_rate": 0.0001443276714446474,
      "loss": 1.291,
      "step": 10840
    },
    {
      "epoch": 0.4377382849535029,
      "grad_norm": 1.064955472946167,
      "learning_rate": 0.00014429081555306298,
      "loss": 1.1223,
      "step": 10850
    },
    {
      "epoch": 0.4381417303774232,
      "grad_norm": 1.7418667078018188,
      "learning_rate": 0.00014425395966147854,
      "loss": 1.3116,
      "step": 10860
    },
    {
      "epoch": 0.4385451758013435,
      "grad_norm": 1.9647643566131592,
      "learning_rate": 0.0001442171037698941,
      "loss": 1.326,
      "step": 10870
    },
    {
      "epoch": 0.43894862122526374,
      "grad_norm": 1.4086655378341675,
      "learning_rate": 0.00014418024787830964,
      "loss": 1.2786,
      "step": 10880
    },
    {
      "epoch": 0.439352066649184,
      "grad_norm": 1.1655906438827515,
      "learning_rate": 0.00014414339198672523,
      "loss": 1.3279,
      "step": 10890
    },
    {
      "epoch": 0.4397555120731043,
      "grad_norm": 1.131529450416565,
      "learning_rate": 0.0001441065360951408,
      "loss": 1.3665,
      "step": 10900
    },
    {
      "epoch": 0.4401589574970246,
      "grad_norm": 1.6847813129425049,
      "learning_rate": 0.00014406968020355636,
      "loss": 1.4991,
      "step": 10910
    },
    {
      "epoch": 0.4405624029209449,
      "grad_norm": 1.313727855682373,
      "learning_rate": 0.00014403282431197192,
      "loss": 1.192,
      "step": 10920
    },
    {
      "epoch": 0.44096584834486513,
      "grad_norm": 0.9559886455535889,
      "learning_rate": 0.00014399596842038748,
      "loss": 1.3981,
      "step": 10930
    },
    {
      "epoch": 0.4413692937687854,
      "grad_norm": 1.170361876487732,
      "learning_rate": 0.00014395911252880304,
      "loss": 1.445,
      "step": 10940
    },
    {
      "epoch": 0.4417727391927057,
      "grad_norm": 2.174075126647949,
      "learning_rate": 0.0001439222566372186,
      "loss": 1.5545,
      "step": 10950
    },
    {
      "epoch": 0.442176184616626,
      "grad_norm": 1.329832673072815,
      "learning_rate": 0.00014388540074563417,
      "loss": 1.3573,
      "step": 10960
    },
    {
      "epoch": 0.4425796300405463,
      "grad_norm": 1.7323471307754517,
      "learning_rate": 0.00014384854485404976,
      "loss": 1.2618,
      "step": 10970
    },
    {
      "epoch": 0.4429830754644665,
      "grad_norm": 1.3879704475402832,
      "learning_rate": 0.00014381168896246532,
      "loss": 1.4766,
      "step": 10980
    },
    {
      "epoch": 0.4433865208883868,
      "grad_norm": 1.2856827974319458,
      "learning_rate": 0.00014377483307088088,
      "loss": 1.5216,
      "step": 10990
    },
    {
      "epoch": 0.4437899663123071,
      "grad_norm": 0.9825993776321411,
      "learning_rate": 0.00014373797717929642,
      "loss": 1.3154,
      "step": 11000
    },
    {
      "epoch": 0.4437899663123071,
      "eval_loss": 1.2952803373336792,
      "eval_runtime": 14.5742,
      "eval_samples_per_second": 3.431,
      "eval_steps_per_second": 1.715,
      "step": 11000
    },
    {
      "epoch": 0.4441934117362274,
      "grad_norm": 1.6561998128890991,
      "learning_rate": 0.000143701121287712,
      "loss": 1.4403,
      "step": 11010
    },
    {
      "epoch": 0.4445968571601477,
      "grad_norm": 1.5542134046554565,
      "learning_rate": 0.00014366426539612757,
      "loss": 1.3842,
      "step": 11020
    },
    {
      "epoch": 0.4450003025840679,
      "grad_norm": 1.4762359857559204,
      "learning_rate": 0.00014362740950454313,
      "loss": 1.3527,
      "step": 11030
    },
    {
      "epoch": 0.4454037480079882,
      "grad_norm": 0.921991229057312,
      "learning_rate": 0.0001435905536129587,
      "loss": 1.2802,
      "step": 11040
    },
    {
      "epoch": 0.4458071934319085,
      "grad_norm": 1.5796266794204712,
      "learning_rate": 0.00014355369772137426,
      "loss": 1.4557,
      "step": 11050
    },
    {
      "epoch": 0.4462106388558288,
      "grad_norm": 1.1507071256637573,
      "learning_rate": 0.00014351684182978982,
      "loss": 1.272,
      "step": 11060
    },
    {
      "epoch": 0.4466140842797491,
      "grad_norm": 0.9478894472122192,
      "learning_rate": 0.00014347998593820539,
      "loss": 1.307,
      "step": 11070
    },
    {
      "epoch": 0.4470175297036693,
      "grad_norm": 1.309906005859375,
      "learning_rate": 0.00014344313004662095,
      "loss": 1.3988,
      "step": 11080
    },
    {
      "epoch": 0.4474209751275896,
      "grad_norm": 1.2506126165390015,
      "learning_rate": 0.00014340627415503654,
      "loss": 1.5315,
      "step": 11090
    },
    {
      "epoch": 0.4478244205515099,
      "grad_norm": 1.4265657663345337,
      "learning_rate": 0.0001433694182634521,
      "loss": 1.3915,
      "step": 11100
    },
    {
      "epoch": 0.4482278659754302,
      "grad_norm": 1.2114490270614624,
      "learning_rate": 0.00014333256237186766,
      "loss": 1.3361,
      "step": 11110
    },
    {
      "epoch": 0.4486313113993505,
      "grad_norm": 1.280439019203186,
      "learning_rate": 0.0001432957064802832,
      "loss": 1.4771,
      "step": 11120
    },
    {
      "epoch": 0.4490347568232707,
      "grad_norm": 0.9660835862159729,
      "learning_rate": 0.0001432588505886988,
      "loss": 1.3401,
      "step": 11130
    },
    {
      "epoch": 0.449438202247191,
      "grad_norm": 3.174105405807495,
      "learning_rate": 0.00014322199469711435,
      "loss": 1.3238,
      "step": 11140
    },
    {
      "epoch": 0.4498416476711113,
      "grad_norm": 0.8711169958114624,
      "learning_rate": 0.00014318513880552991,
      "loss": 1.3025,
      "step": 11150
    },
    {
      "epoch": 0.4502450930950316,
      "grad_norm": 0.9830446839332581,
      "learning_rate": 0.00014314828291394548,
      "loss": 1.3204,
      "step": 11160
    },
    {
      "epoch": 0.45064853851895187,
      "grad_norm": 2.3664331436157227,
      "learning_rate": 0.00014311142702236104,
      "loss": 1.4222,
      "step": 11170
    },
    {
      "epoch": 0.4510519839428721,
      "grad_norm": 1.1255710124969482,
      "learning_rate": 0.0001430745711307766,
      "loss": 1.395,
      "step": 11180
    },
    {
      "epoch": 0.4514554293667924,
      "grad_norm": 1.2960633039474487,
      "learning_rate": 0.00014303771523919217,
      "loss": 1.3808,
      "step": 11190
    },
    {
      "epoch": 0.4518588747907127,
      "grad_norm": 1.009971261024475,
      "learning_rate": 0.00014300085934760773,
      "loss": 1.3743,
      "step": 11200
    },
    {
      "epoch": 0.4518588747907127,
      "eval_loss": 1.2932194471359253,
      "eval_runtime": 14.5589,
      "eval_samples_per_second": 3.434,
      "eval_steps_per_second": 1.717,
      "step": 11200
    },
    {
      "epoch": 0.452262320214633,
      "grad_norm": 1.1689993143081665,
      "learning_rate": 0.00014296400345602332,
      "loss": 1.3529,
      "step": 11210
    },
    {
      "epoch": 0.45266576563855326,
      "grad_norm": 1.1338622570037842,
      "learning_rate": 0.00014292714756443888,
      "loss": 1.2285,
      "step": 11220
    },
    {
      "epoch": 0.4530692110624735,
      "grad_norm": 2.1021435260772705,
      "learning_rate": 0.00014289029167285444,
      "loss": 1.3352,
      "step": 11230
    },
    {
      "epoch": 0.4534726564863938,
      "grad_norm": 0.9735090732574463,
      "learning_rate": 0.00014285343578126998,
      "loss": 1.1906,
      "step": 11240
    },
    {
      "epoch": 0.4538761019103141,
      "grad_norm": 0.9404398202896118,
      "learning_rate": 0.00014281657988968557,
      "loss": 1.3784,
      "step": 11250
    },
    {
      "epoch": 0.45427954733423437,
      "grad_norm": 1.615830898284912,
      "learning_rate": 0.00014277972399810113,
      "loss": 1.4993,
      "step": 11260
    },
    {
      "epoch": 0.45468299275815466,
      "grad_norm": 1.35600745677948,
      "learning_rate": 0.0001427428681065167,
      "loss": 1.1841,
      "step": 11270
    },
    {
      "epoch": 0.4550864381820749,
      "grad_norm": 1.1767948865890503,
      "learning_rate": 0.00014270601221493226,
      "loss": 1.2342,
      "step": 11280
    },
    {
      "epoch": 0.4554898836059952,
      "grad_norm": 1.8933650255203247,
      "learning_rate": 0.00014266915632334782,
      "loss": 1.3907,
      "step": 11290
    },
    {
      "epoch": 0.4558933290299155,
      "grad_norm": 1.1180756092071533,
      "learning_rate": 0.00014263230043176338,
      "loss": 1.2408,
      "step": 11300
    },
    {
      "epoch": 0.45629677445383576,
      "grad_norm": 1.4622392654418945,
      "learning_rate": 0.00014259544454017895,
      "loss": 1.3356,
      "step": 11310
    },
    {
      "epoch": 0.45670021987775605,
      "grad_norm": 1.1322214603424072,
      "learning_rate": 0.0001425585886485945,
      "loss": 1.3714,
      "step": 11320
    },
    {
      "epoch": 0.45710366530167634,
      "grad_norm": 1.0633985996246338,
      "learning_rate": 0.0001425217327570101,
      "loss": 1.2586,
      "step": 11330
    },
    {
      "epoch": 0.4575071107255966,
      "grad_norm": 1.0338870286941528,
      "learning_rate": 0.00014248487686542566,
      "loss": 1.3384,
      "step": 11340
    },
    {
      "epoch": 0.45791055614951687,
      "grad_norm": 2.226590871810913,
      "learning_rate": 0.00014244802097384122,
      "loss": 1.4196,
      "step": 11350
    },
    {
      "epoch": 0.45831400157343716,
      "grad_norm": 1.750335454940796,
      "learning_rate": 0.00014241116508225679,
      "loss": 1.2728,
      "step": 11360
    },
    {
      "epoch": 0.45871744699735745,
      "grad_norm": 1.3774069547653198,
      "learning_rate": 0.00014237430919067235,
      "loss": 1.4414,
      "step": 11370
    },
    {
      "epoch": 0.45912089242127774,
      "grad_norm": 1.3661662340164185,
      "learning_rate": 0.0001423374532990879,
      "loss": 1.4652,
      "step": 11380
    },
    {
      "epoch": 0.45952433784519797,
      "grad_norm": 1.3323259353637695,
      "learning_rate": 0.00014230059740750347,
      "loss": 1.3055,
      "step": 11390
    },
    {
      "epoch": 0.45992778326911826,
      "grad_norm": 0.958681583404541,
      "learning_rate": 0.00014226374151591904,
      "loss": 1.2292,
      "step": 11400
    },
    {
      "epoch": 0.45992778326911826,
      "eval_loss": 1.2976170778274536,
      "eval_runtime": 14.5674,
      "eval_samples_per_second": 3.432,
      "eval_steps_per_second": 1.716,
      "step": 11400
    },
    {
      "epoch": 0.46033122869303855,
      "grad_norm": 1.1375330686569214,
      "learning_rate": 0.00014222688562433463,
      "loss": 1.1804,
      "step": 11410
    },
    {
      "epoch": 0.46073467411695884,
      "grad_norm": 1.45292329788208,
      "learning_rate": 0.00014219002973275016,
      "loss": 1.4634,
      "step": 11420
    },
    {
      "epoch": 0.46113811954087913,
      "grad_norm": 1.0094249248504639,
      "learning_rate": 0.00014215317384116573,
      "loss": 1.473,
      "step": 11430
    },
    {
      "epoch": 0.46154156496479937,
      "grad_norm": 0.9986270666122437,
      "learning_rate": 0.0001421163179495813,
      "loss": 1.1427,
      "step": 11440
    },
    {
      "epoch": 0.46194501038871966,
      "grad_norm": 1.2180103063583374,
      "learning_rate": 0.00014207946205799688,
      "loss": 1.1501,
      "step": 11450
    },
    {
      "epoch": 0.46234845581263995,
      "grad_norm": 1.2204680442810059,
      "learning_rate": 0.00014204260616641244,
      "loss": 1.4335,
      "step": 11460
    },
    {
      "epoch": 0.46275190123656024,
      "grad_norm": 1.2542405128479004,
      "learning_rate": 0.000142005750274828,
      "loss": 1.2924,
      "step": 11470
    },
    {
      "epoch": 0.4631553466604805,
      "grad_norm": 2.028923749923706,
      "learning_rate": 0.00014196889438324357,
      "loss": 1.3246,
      "step": 11480
    },
    {
      "epoch": 0.46355879208440076,
      "grad_norm": 1.5018858909606934,
      "learning_rate": 0.00014193203849165913,
      "loss": 1.2124,
      "step": 11490
    },
    {
      "epoch": 0.46396223750832105,
      "grad_norm": 1.8873416185379028,
      "learning_rate": 0.0001418951826000747,
      "loss": 1.2965,
      "step": 11500
    },
    {
      "epoch": 0.46436568293224134,
      "grad_norm": 1.629609227180481,
      "learning_rate": 0.00014185832670849025,
      "loss": 1.3201,
      "step": 11510
    },
    {
      "epoch": 0.46476912835616163,
      "grad_norm": 1.346497893333435,
      "learning_rate": 0.00014182147081690582,
      "loss": 1.348,
      "step": 11520
    },
    {
      "epoch": 0.4651725737800819,
      "grad_norm": 1.1580290794372559,
      "learning_rate": 0.0001417846149253214,
      "loss": 1.5113,
      "step": 11530
    },
    {
      "epoch": 0.46557601920400216,
      "grad_norm": 1.214003562927246,
      "learning_rate": 0.00014174775903373694,
      "loss": 1.2781,
      "step": 11540
    },
    {
      "epoch": 0.46597946462792245,
      "grad_norm": 1.4990606307983398,
      "learning_rate": 0.0001417109031421525,
      "loss": 1.396,
      "step": 11550
    },
    {
      "epoch": 0.46638291005184274,
      "grad_norm": 1.2386846542358398,
      "learning_rate": 0.00014167404725056807,
      "loss": 1.3524,
      "step": 11560
    },
    {
      "epoch": 0.466786355475763,
      "grad_norm": 1.0196218490600586,
      "learning_rate": 0.00014163719135898366,
      "loss": 1.2542,
      "step": 11570
    },
    {
      "epoch": 0.4671898008996833,
      "grad_norm": 1.7630150318145752,
      "learning_rate": 0.00014160033546739922,
      "loss": 1.3015,
      "step": 11580
    },
    {
      "epoch": 0.46759324632360355,
      "grad_norm": 1.4528708457946777,
      "learning_rate": 0.00014156347957581478,
      "loss": 1.2122,
      "step": 11590
    },
    {
      "epoch": 0.46799669174752384,
      "grad_norm": 1.136226773262024,
      "learning_rate": 0.00014152662368423035,
      "loss": 1.4369,
      "step": 11600
    },
    {
      "epoch": 0.46799669174752384,
      "eval_loss": 1.2982122898101807,
      "eval_runtime": 14.5967,
      "eval_samples_per_second": 3.425,
      "eval_steps_per_second": 1.713,
      "step": 11600
    },
    {
      "epoch": 0.46840013717144413,
      "grad_norm": 1.0543394088745117,
      "learning_rate": 0.0001414897677926459,
      "loss": 1.2302,
      "step": 11610
    },
    {
      "epoch": 0.4688035825953644,
      "grad_norm": 1.651011347770691,
      "learning_rate": 0.00014145291190106147,
      "loss": 1.3321,
      "step": 11620
    },
    {
      "epoch": 0.4692070280192847,
      "grad_norm": 1.4333596229553223,
      "learning_rate": 0.00014141605600947703,
      "loss": 1.2837,
      "step": 11630
    },
    {
      "epoch": 0.46961047344320495,
      "grad_norm": 1.2919337749481201,
      "learning_rate": 0.0001413792001178926,
      "loss": 1.4167,
      "step": 11640
    },
    {
      "epoch": 0.47001391886712524,
      "grad_norm": 1.5855634212493896,
      "learning_rate": 0.0001413423442263082,
      "loss": 1.4073,
      "step": 11650
    },
    {
      "epoch": 0.4704173642910455,
      "grad_norm": 1.1299042701721191,
      "learning_rate": 0.00014130548833472372,
      "loss": 1.4031,
      "step": 11660
    },
    {
      "epoch": 0.4708208097149658,
      "grad_norm": 1.6074718236923218,
      "learning_rate": 0.00014126863244313928,
      "loss": 1.4559,
      "step": 11670
    },
    {
      "epoch": 0.4712242551388861,
      "grad_norm": 1.37173330783844,
      "learning_rate": 0.00014123177655155485,
      "loss": 1.3306,
      "step": 11680
    },
    {
      "epoch": 0.47162770056280634,
      "grad_norm": 3.133197784423828,
      "learning_rate": 0.00014119492065997044,
      "loss": 1.2703,
      "step": 11690
    },
    {
      "epoch": 0.47203114598672663,
      "grad_norm": 1.1355526447296143,
      "learning_rate": 0.000141158064768386,
      "loss": 1.1437,
      "step": 11700
    },
    {
      "epoch": 0.4724345914106469,
      "grad_norm": 1.5758579969406128,
      "learning_rate": 0.00014112120887680156,
      "loss": 1.4097,
      "step": 11710
    },
    {
      "epoch": 0.4728380368345672,
      "grad_norm": 1.5036957263946533,
      "learning_rate": 0.00014108435298521713,
      "loss": 1.1359,
      "step": 11720
    },
    {
      "epoch": 0.4732414822584875,
      "grad_norm": 1.2014644145965576,
      "learning_rate": 0.0001410474970936327,
      "loss": 1.4419,
      "step": 11730
    },
    {
      "epoch": 0.47364492768240773,
      "grad_norm": 1.0068299770355225,
      "learning_rate": 0.00014101064120204825,
      "loss": 1.3917,
      "step": 11740
    },
    {
      "epoch": 0.474048373106328,
      "grad_norm": 1.1365538835525513,
      "learning_rate": 0.00014097378531046381,
      "loss": 1.3823,
      "step": 11750
    },
    {
      "epoch": 0.4744518185302483,
      "grad_norm": 1.3992637395858765,
      "learning_rate": 0.00014093692941887938,
      "loss": 1.4599,
      "step": 11760
    },
    {
      "epoch": 0.4748552639541686,
      "grad_norm": 1.7518773078918457,
      "learning_rate": 0.00014090007352729497,
      "loss": 1.3958,
      "step": 11770
    },
    {
      "epoch": 0.4752587093780889,
      "grad_norm": 1.684525966644287,
      "learning_rate": 0.00014086321763571053,
      "loss": 1.3014,
      "step": 11780
    },
    {
      "epoch": 0.4756621548020092,
      "grad_norm": 1.1724282503128052,
      "learning_rate": 0.00014082636174412606,
      "loss": 1.3972,
      "step": 11790
    },
    {
      "epoch": 0.4760656002259294,
      "grad_norm": 1.7009196281433105,
      "learning_rate": 0.00014078950585254163,
      "loss": 1.3888,
      "step": 11800
    },
    {
      "epoch": 0.4760656002259294,
      "eval_loss": 1.2960084676742554,
      "eval_runtime": 14.5515,
      "eval_samples_per_second": 3.436,
      "eval_steps_per_second": 1.718,
      "step": 11800
    },
    {
      "epoch": 0.4764690456498497,
      "grad_norm": 2.390235185623169,
      "learning_rate": 0.00014075264996095722,
      "loss": 1.3198,
      "step": 11810
    },
    {
      "epoch": 0.47687249107377,
      "grad_norm": 1.1965909004211426,
      "learning_rate": 0.00014071579406937278,
      "loss": 1.336,
      "step": 11820
    },
    {
      "epoch": 0.4772759364976903,
      "grad_norm": 1.6072022914886475,
      "learning_rate": 0.00014067893817778834,
      "loss": 1.3657,
      "step": 11830
    },
    {
      "epoch": 0.4776793819216106,
      "grad_norm": 1.228609561920166,
      "learning_rate": 0.0001406420822862039,
      "loss": 1.3397,
      "step": 11840
    },
    {
      "epoch": 0.4780828273455308,
      "grad_norm": 1.4680123329162598,
      "learning_rate": 0.00014060522639461947,
      "loss": 1.2968,
      "step": 11850
    },
    {
      "epoch": 0.4784862727694511,
      "grad_norm": 1.6855149269104004,
      "learning_rate": 0.00014056837050303503,
      "loss": 1.3108,
      "step": 11860
    },
    {
      "epoch": 0.4788897181933714,
      "grad_norm": 1.20967698097229,
      "learning_rate": 0.0001405315146114506,
      "loss": 1.0429,
      "step": 11870
    },
    {
      "epoch": 0.4792931636172917,
      "grad_norm": 1.5515353679656982,
      "learning_rate": 0.00014049465871986616,
      "loss": 1.3039,
      "step": 11880
    },
    {
      "epoch": 0.479696609041212,
      "grad_norm": 1.1790424585342407,
      "learning_rate": 0.00014045780282828172,
      "loss": 1.3268,
      "step": 11890
    },
    {
      "epoch": 0.4801000544651322,
      "grad_norm": 1.0815341472625732,
      "learning_rate": 0.0001404209469366973,
      "loss": 1.2506,
      "step": 11900
    },
    {
      "epoch": 0.4805034998890525,
      "grad_norm": 1.1744567155838013,
      "learning_rate": 0.00014038409104511284,
      "loss": 1.2957,
      "step": 11910
    },
    {
      "epoch": 0.4809069453129728,
      "grad_norm": 1.7226797342300415,
      "learning_rate": 0.0001403472351535284,
      "loss": 1.3819,
      "step": 11920
    },
    {
      "epoch": 0.4813103907368931,
      "grad_norm": 1.9478305578231812,
      "learning_rate": 0.00014031037926194397,
      "loss": 1.3184,
      "step": 11930
    },
    {
      "epoch": 0.48171383616081337,
      "grad_norm": 1.7889761924743652,
      "learning_rate": 0.00014027352337035956,
      "loss": 1.3758,
      "step": 11940
    },
    {
      "epoch": 0.4821172815847336,
      "grad_norm": 0.9628816843032837,
      "learning_rate": 0.00014023666747877512,
      "loss": 1.2974,
      "step": 11950
    },
    {
      "epoch": 0.4825207270086539,
      "grad_norm": 1.436465859413147,
      "learning_rate": 0.00014019981158719069,
      "loss": 1.2013,
      "step": 11960
    },
    {
      "epoch": 0.4829241724325742,
      "grad_norm": 1.803099513053894,
      "learning_rate": 0.00014016295569560625,
      "loss": 1.4044,
      "step": 11970
    },
    {
      "epoch": 0.4833276178564945,
      "grad_norm": 0.9739583134651184,
      "learning_rate": 0.0001401260998040218,
      "loss": 1.3694,
      "step": 11980
    },
    {
      "epoch": 0.48373106328041476,
      "grad_norm": 0.8639478087425232,
      "learning_rate": 0.00014008924391243737,
      "loss": 1.3069,
      "step": 11990
    },
    {
      "epoch": 0.484134508704335,
      "grad_norm": 1.6555577516555786,
      "learning_rate": 0.00014005238802085294,
      "loss": 1.1981,
      "step": 12000
    },
    {
      "epoch": 0.484134508704335,
      "eval_loss": 1.2995212078094482,
      "eval_runtime": 14.5754,
      "eval_samples_per_second": 3.43,
      "eval_steps_per_second": 1.715,
      "step": 12000
    },
    {
      "epoch": 0.4845379541282553,
      "grad_norm": 1.1424273252487183,
      "learning_rate": 0.0001400155321292685,
      "loss": 1.3772,
      "step": 12010
    },
    {
      "epoch": 0.4849413995521756,
      "grad_norm": 0.903019368648529,
      "learning_rate": 0.0001399786762376841,
      "loss": 1.3752,
      "step": 12020
    },
    {
      "epoch": 0.48534484497609587,
      "grad_norm": 0.8461456894874573,
      "learning_rate": 0.00013994182034609962,
      "loss": 1.2516,
      "step": 12030
    },
    {
      "epoch": 0.48574829040001616,
      "grad_norm": 1.4734337329864502,
      "learning_rate": 0.0001399049644545152,
      "loss": 1.2022,
      "step": 12040
    },
    {
      "epoch": 0.4861517358239364,
      "grad_norm": 1.3457375764846802,
      "learning_rate": 0.00013986810856293075,
      "loss": 1.2548,
      "step": 12050
    },
    {
      "epoch": 0.4865551812478567,
      "grad_norm": 1.3196734189987183,
      "learning_rate": 0.00013983125267134634,
      "loss": 1.3195,
      "step": 12060
    },
    {
      "epoch": 0.486958626671777,
      "grad_norm": 1.3516359329223633,
      "learning_rate": 0.0001397943967797619,
      "loss": 1.2684,
      "step": 12070
    },
    {
      "epoch": 0.48736207209569726,
      "grad_norm": 2.850208282470703,
      "learning_rate": 0.00013975754088817747,
      "loss": 1.184,
      "step": 12080
    },
    {
      "epoch": 0.48776551751961755,
      "grad_norm": 1.5190794467926025,
      "learning_rate": 0.00013972068499659303,
      "loss": 1.2703,
      "step": 12090
    },
    {
      "epoch": 0.4881689629435378,
      "grad_norm": 1.5745946168899536,
      "learning_rate": 0.0001396838291050086,
      "loss": 1.2755,
      "step": 12100
    },
    {
      "epoch": 0.4885724083674581,
      "grad_norm": 1.7426337003707886,
      "learning_rate": 0.00013964697321342415,
      "loss": 1.4136,
      "step": 12110
    },
    {
      "epoch": 0.48897585379137837,
      "grad_norm": 1.326758623123169,
      "learning_rate": 0.00013961011732183972,
      "loss": 1.407,
      "step": 12120
    },
    {
      "epoch": 0.48937929921529866,
      "grad_norm": 1.1329096555709839,
      "learning_rate": 0.00013957326143025528,
      "loss": 1.1857,
      "step": 12130
    },
    {
      "epoch": 0.48978274463921895,
      "grad_norm": 1.6852612495422363,
      "learning_rate": 0.00013953640553867087,
      "loss": 1.2716,
      "step": 12140
    },
    {
      "epoch": 0.4901861900631392,
      "grad_norm": 0.8085800409317017,
      "learning_rate": 0.00013949954964708643,
      "loss": 1.2601,
      "step": 12150
    },
    {
      "epoch": 0.49058963548705947,
      "grad_norm": 1.43917715549469,
      "learning_rate": 0.00013946269375550197,
      "loss": 1.4774,
      "step": 12160
    },
    {
      "epoch": 0.49099308091097976,
      "grad_norm": 1.3866277933120728,
      "learning_rate": 0.00013942583786391753,
      "loss": 1.2136,
      "step": 12170
    },
    {
      "epoch": 0.49139652633490005,
      "grad_norm": 0.8928629755973816,
      "learning_rate": 0.00013938898197233312,
      "loss": 1.4845,
      "step": 12180
    },
    {
      "epoch": 0.49179997175882034,
      "grad_norm": 1.1892530918121338,
      "learning_rate": 0.00013935212608074868,
      "loss": 1.2909,
      "step": 12190
    },
    {
      "epoch": 0.49220341718274063,
      "grad_norm": 1.7320926189422607,
      "learning_rate": 0.00013931527018916424,
      "loss": 1.4498,
      "step": 12200
    },
    {
      "epoch": 0.49220341718274063,
      "eval_loss": 1.2991923093795776,
      "eval_runtime": 14.5746,
      "eval_samples_per_second": 3.431,
      "eval_steps_per_second": 1.715,
      "step": 12200
    },
    {
      "epoch": 0.49260686260666087,
      "grad_norm": 1.2721985578536987,
      "learning_rate": 0.0001392784142975798,
      "loss": 1.2389,
      "step": 12210
    },
    {
      "epoch": 0.49301030803058116,
      "grad_norm": 1.5386794805526733,
      "learning_rate": 0.00013924155840599537,
      "loss": 1.2642,
      "step": 12220
    },
    {
      "epoch": 0.49341375345450145,
      "grad_norm": 1.0842833518981934,
      "learning_rate": 0.00013920470251441093,
      "loss": 1.1763,
      "step": 12230
    },
    {
      "epoch": 0.49381719887842174,
      "grad_norm": 1.3964943885803223,
      "learning_rate": 0.0001391678466228265,
      "loss": 1.3715,
      "step": 12240
    },
    {
      "epoch": 0.494220644302342,
      "grad_norm": 1.57864511013031,
      "learning_rate": 0.00013913099073124206,
      "loss": 1.5272,
      "step": 12250
    },
    {
      "epoch": 0.49462408972626226,
      "grad_norm": 0.997279167175293,
      "learning_rate": 0.00013909413483965765,
      "loss": 1.2615,
      "step": 12260
    },
    {
      "epoch": 0.49502753515018255,
      "grad_norm": 1.3616448640823364,
      "learning_rate": 0.0001390572789480732,
      "loss": 1.4147,
      "step": 12270
    },
    {
      "epoch": 0.49543098057410284,
      "grad_norm": 2.0364627838134766,
      "learning_rate": 0.00013902042305648875,
      "loss": 1.1567,
      "step": 12280
    },
    {
      "epoch": 0.49583442599802313,
      "grad_norm": 1.4079300165176392,
      "learning_rate": 0.0001389835671649043,
      "loss": 1.4118,
      "step": 12290
    },
    {
      "epoch": 0.4962378714219434,
      "grad_norm": 1.392163872718811,
      "learning_rate": 0.0001389467112733199,
      "loss": 1.3494,
      "step": 12300
    },
    {
      "epoch": 0.49664131684586366,
      "grad_norm": 1.2048064470291138,
      "learning_rate": 0.00013890985538173546,
      "loss": 1.2188,
      "step": 12310
    },
    {
      "epoch": 0.49704476226978395,
      "grad_norm": 1.238540768623352,
      "learning_rate": 0.00013887299949015102,
      "loss": 1.455,
      "step": 12320
    },
    {
      "epoch": 0.49744820769370424,
      "grad_norm": 1.3187528848648071,
      "learning_rate": 0.0001388361435985666,
      "loss": 1.4377,
      "step": 12330
    },
    {
      "epoch": 0.4978516531176245,
      "grad_norm": 1.4411334991455078,
      "learning_rate": 0.00013879928770698215,
      "loss": 1.3974,
      "step": 12340
    },
    {
      "epoch": 0.4982550985415448,
      "grad_norm": 1.3674697875976562,
      "learning_rate": 0.0001387624318153977,
      "loss": 1.3029,
      "step": 12350
    },
    {
      "epoch": 0.49865854396546505,
      "grad_norm": 1.3153669834136963,
      "learning_rate": 0.00013872557592381328,
      "loss": 1.3819,
      "step": 12360
    },
    {
      "epoch": 0.49906198938938534,
      "grad_norm": 1.253146767616272,
      "learning_rate": 0.00013868872003222884,
      "loss": 1.2747,
      "step": 12370
    },
    {
      "epoch": 0.49946543481330563,
      "grad_norm": 1.2767260074615479,
      "learning_rate": 0.00013865186414064443,
      "loss": 1.4492,
      "step": 12380
    },
    {
      "epoch": 0.4998688802372259,
      "grad_norm": 0.8112522959709167,
      "learning_rate": 0.00013861500824906,
      "loss": 1.2145,
      "step": 12390
    },
    {
      "epoch": 0.5002723256611462,
      "grad_norm": 1.6541485786437988,
      "learning_rate": 0.00013857815235747553,
      "loss": 1.1884,
      "step": 12400
    },
    {
      "epoch": 0.5002723256611462,
      "eval_loss": 1.2979843616485596,
      "eval_runtime": 14.5861,
      "eval_samples_per_second": 3.428,
      "eval_steps_per_second": 1.714,
      "step": 12400
    },
    {
      "epoch": 0.5006757710850664,
      "grad_norm": 1.7226015329360962,
      "learning_rate": 0.0001385412964658911,
      "loss": 1.3543,
      "step": 12410
    },
    {
      "epoch": 0.5010792165089868,
      "grad_norm": 1.4177247285842896,
      "learning_rate": 0.00013850444057430668,
      "loss": 1.3859,
      "step": 12420
    },
    {
      "epoch": 0.501482661932907,
      "grad_norm": 1.1795294284820557,
      "learning_rate": 0.00013846758468272224,
      "loss": 1.178,
      "step": 12430
    },
    {
      "epoch": 0.5018861073568273,
      "grad_norm": 1.7397379875183105,
      "learning_rate": 0.0001384307287911378,
      "loss": 1.4305,
      "step": 12440
    },
    {
      "epoch": 0.5022895527807476,
      "grad_norm": 1.3854095935821533,
      "learning_rate": 0.00013839387289955337,
      "loss": 1.2676,
      "step": 12450
    },
    {
      "epoch": 0.5026929982046678,
      "grad_norm": 0.8939155340194702,
      "learning_rate": 0.00013835701700796893,
      "loss": 1.4968,
      "step": 12460
    },
    {
      "epoch": 0.5030964436285882,
      "grad_norm": 1.251481294631958,
      "learning_rate": 0.0001383201611163845,
      "loss": 1.3407,
      "step": 12470
    },
    {
      "epoch": 0.5034998890525084,
      "grad_norm": 1.2387830018997192,
      "learning_rate": 0.00013828330522480006,
      "loss": 1.3977,
      "step": 12480
    },
    {
      "epoch": 0.5039033344764287,
      "grad_norm": 1.148327112197876,
      "learning_rate": 0.00013824644933321562,
      "loss": 1.4525,
      "step": 12490
    },
    {
      "epoch": 0.504306779900349,
      "grad_norm": 1.6908366680145264,
      "learning_rate": 0.0001382095934416312,
      "loss": 1.3958,
      "step": 12500
    },
    {
      "epoch": 0.5047102253242692,
      "grad_norm": 0.9852026700973511,
      "learning_rate": 0.00013817273755004677,
      "loss": 1.2165,
      "step": 12510
    },
    {
      "epoch": 0.5051136707481896,
      "grad_norm": 1.0458868741989136,
      "learning_rate": 0.00013813588165846233,
      "loss": 1.3206,
      "step": 12520
    },
    {
      "epoch": 0.5055171161721098,
      "grad_norm": 1.2891411781311035,
      "learning_rate": 0.00013809902576687787,
      "loss": 1.3623,
      "step": 12530
    },
    {
      "epoch": 0.50592056159603,
      "grad_norm": 1.1286063194274902,
      "learning_rate": 0.00013806216987529346,
      "loss": 1.3981,
      "step": 12540
    },
    {
      "epoch": 0.5063240070199504,
      "grad_norm": 1.697217583656311,
      "learning_rate": 0.00013802531398370902,
      "loss": 1.314,
      "step": 12550
    },
    {
      "epoch": 0.5067274524438706,
      "grad_norm": 1.5774387121200562,
      "learning_rate": 0.00013798845809212458,
      "loss": 1.2307,
      "step": 12560
    },
    {
      "epoch": 0.507130897867791,
      "grad_norm": 1.2847986221313477,
      "learning_rate": 0.00013795160220054015,
      "loss": 1.2503,
      "step": 12570
    },
    {
      "epoch": 0.5075343432917112,
      "grad_norm": 1.2491387128829956,
      "learning_rate": 0.0001379147463089557,
      "loss": 1.2417,
      "step": 12580
    },
    {
      "epoch": 0.5079377887156314,
      "grad_norm": 1.2935991287231445,
      "learning_rate": 0.00013787789041737127,
      "loss": 1.4704,
      "step": 12590
    },
    {
      "epoch": 0.5083412341395518,
      "grad_norm": 1.3550376892089844,
      "learning_rate": 0.00013784103452578684,
      "loss": 1.3245,
      "step": 12600
    },
    {
      "epoch": 0.5083412341395518,
      "eval_loss": 1.2966101169586182,
      "eval_runtime": 14.5805,
      "eval_samples_per_second": 3.429,
      "eval_steps_per_second": 1.715,
      "step": 12600
    },
    {
      "epoch": 0.508744679563472,
      "grad_norm": 1.0643208026885986,
      "learning_rate": 0.0001378041786342024,
      "loss": 1.3756,
      "step": 12610
    },
    {
      "epoch": 0.5091481249873924,
      "grad_norm": 1.4047006368637085,
      "learning_rate": 0.000137767322742618,
      "loss": 1.1968,
      "step": 12620
    },
    {
      "epoch": 0.5095515704113126,
      "grad_norm": 1.2452832460403442,
      "learning_rate": 0.00013773046685103355,
      "loss": 1.3634,
      "step": 12630
    },
    {
      "epoch": 0.5099550158352328,
      "grad_norm": 1.2402061223983765,
      "learning_rate": 0.0001376936109594491,
      "loss": 1.2712,
      "step": 12640
    },
    {
      "epoch": 0.5103584612591532,
      "grad_norm": 1.5822986364364624,
      "learning_rate": 0.00013765675506786465,
      "loss": 1.3693,
      "step": 12650
    },
    {
      "epoch": 0.5107619066830734,
      "grad_norm": 1.6820436716079712,
      "learning_rate": 0.00013761989917628024,
      "loss": 1.5256,
      "step": 12660
    },
    {
      "epoch": 0.5111653521069938,
      "grad_norm": 1.4094467163085938,
      "learning_rate": 0.0001375830432846958,
      "loss": 1.3116,
      "step": 12670
    },
    {
      "epoch": 0.511568797530914,
      "grad_norm": 1.4858183860778809,
      "learning_rate": 0.00013754618739311136,
      "loss": 1.2514,
      "step": 12680
    },
    {
      "epoch": 0.5119722429548342,
      "grad_norm": 1.068766474723816,
      "learning_rate": 0.00013750933150152693,
      "loss": 1.4735,
      "step": 12690
    },
    {
      "epoch": 0.5123756883787546,
      "grad_norm": 0.9507576823234558,
      "learning_rate": 0.0001374724756099425,
      "loss": 1.3374,
      "step": 12700
    },
    {
      "epoch": 0.5127791338026748,
      "grad_norm": 1.665513277053833,
      "learning_rate": 0.00013743561971835805,
      "loss": 1.2255,
      "step": 12710
    },
    {
      "epoch": 0.5131825792265952,
      "grad_norm": 1.4487273693084717,
      "learning_rate": 0.00013739876382677362,
      "loss": 1.2947,
      "step": 12720
    },
    {
      "epoch": 0.5135860246505154,
      "grad_norm": 1.3763017654418945,
      "learning_rate": 0.00013736190793518918,
      "loss": 1.4181,
      "step": 12730
    },
    {
      "epoch": 0.5139894700744356,
      "grad_norm": 1.368825078010559,
      "learning_rate": 0.00013732505204360477,
      "loss": 1.5132,
      "step": 12740
    },
    {
      "epoch": 0.514392915498356,
      "grad_norm": 1.1357533931732178,
      "learning_rate": 0.00013728819615202033,
      "loss": 1.3788,
      "step": 12750
    },
    {
      "epoch": 0.5147963609222762,
      "grad_norm": 1.6500053405761719,
      "learning_rate": 0.0001372513402604359,
      "loss": 1.4193,
      "step": 12760
    },
    {
      "epoch": 0.5151998063461966,
      "grad_norm": 1.1289724111557007,
      "learning_rate": 0.00013721448436885143,
      "loss": 1.1455,
      "step": 12770
    },
    {
      "epoch": 0.5156032517701168,
      "grad_norm": 1.0505051612854004,
      "learning_rate": 0.00013717762847726702,
      "loss": 1.3501,
      "step": 12780
    },
    {
      "epoch": 0.516006697194037,
      "grad_norm": 1.0393091440200806,
      "learning_rate": 0.00013714077258568258,
      "loss": 1.2109,
      "step": 12790
    },
    {
      "epoch": 0.5164101426179574,
      "grad_norm": 1.586856722831726,
      "learning_rate": 0.00013710391669409814,
      "loss": 1.2145,
      "step": 12800
    },
    {
      "epoch": 0.5164101426179574,
      "eval_loss": 1.3009300231933594,
      "eval_runtime": 14.8453,
      "eval_samples_per_second": 3.368,
      "eval_steps_per_second": 1.684,
      "step": 12800
    },
    {
      "epoch": 0.5168135880418776,
      "grad_norm": 0.9409909844398499,
      "learning_rate": 0.0001370670608025137,
      "loss": 1.3591,
      "step": 12810
    },
    {
      "epoch": 0.517217033465798,
      "grad_norm": 1.3660520315170288,
      "learning_rate": 0.00013703020491092927,
      "loss": 1.2693,
      "step": 12820
    },
    {
      "epoch": 0.5176204788897182,
      "grad_norm": 1.4808342456817627,
      "learning_rate": 0.00013699334901934483,
      "loss": 1.295,
      "step": 12830
    },
    {
      "epoch": 0.5180239243136384,
      "grad_norm": 1.44339919090271,
      "learning_rate": 0.0001369564931277604,
      "loss": 1.1094,
      "step": 12840
    },
    {
      "epoch": 0.5184273697375588,
      "grad_norm": 1.2745680809020996,
      "learning_rate": 0.00013691963723617596,
      "loss": 1.404,
      "step": 12850
    },
    {
      "epoch": 0.518830815161479,
      "grad_norm": 1.2057253122329712,
      "learning_rate": 0.00013688278134459155,
      "loss": 1.4216,
      "step": 12860
    },
    {
      "epoch": 0.5192342605853993,
      "grad_norm": 1.3658338785171509,
      "learning_rate": 0.0001368459254530071,
      "loss": 1.3531,
      "step": 12870
    },
    {
      "epoch": 0.5196377060093196,
      "grad_norm": 0.9432334899902344,
      "learning_rate": 0.00013680906956142267,
      "loss": 1.3438,
      "step": 12880
    },
    {
      "epoch": 0.5200411514332399,
      "grad_norm": 1.3425343036651611,
      "learning_rate": 0.00013677221366983824,
      "loss": 1.4162,
      "step": 12890
    },
    {
      "epoch": 0.5204445968571602,
      "grad_norm": 1.865858793258667,
      "learning_rate": 0.0001367353577782538,
      "loss": 1.2725,
      "step": 12900
    },
    {
      "epoch": 0.5208480422810804,
      "grad_norm": 1.24549400806427,
      "learning_rate": 0.00013669850188666936,
      "loss": 1.2853,
      "step": 12910
    },
    {
      "epoch": 0.5212514877050007,
      "grad_norm": 1.3545176982879639,
      "learning_rate": 0.00013666164599508492,
      "loss": 1.1988,
      "step": 12920
    },
    {
      "epoch": 0.521654933128921,
      "grad_norm": 1.2779746055603027,
      "learning_rate": 0.0001366247901035005,
      "loss": 1.2205,
      "step": 12930
    },
    {
      "epoch": 0.5220583785528413,
      "grad_norm": 1.420196294784546,
      "learning_rate": 0.00013658793421191608,
      "loss": 1.3133,
      "step": 12940
    },
    {
      "epoch": 0.5224618239767616,
      "grad_norm": 0.9274053573608398,
      "learning_rate": 0.0001365510783203316,
      "loss": 1.4071,
      "step": 12950
    },
    {
      "epoch": 0.5228652694006818,
      "grad_norm": 0.8904498815536499,
      "learning_rate": 0.00013651422242874717,
      "loss": 1.5602,
      "step": 12960
    },
    {
      "epoch": 0.5232687148246021,
      "grad_norm": 1.0200846195220947,
      "learning_rate": 0.00013647736653716274,
      "loss": 1.4528,
      "step": 12970
    },
    {
      "epoch": 0.5236721602485224,
      "grad_norm": 0.9034342169761658,
      "learning_rate": 0.0001364405106455783,
      "loss": 1.3336,
      "step": 12980
    },
    {
      "epoch": 0.5240756056724427,
      "grad_norm": 1.5852224826812744,
      "learning_rate": 0.0001364036547539939,
      "loss": 1.4191,
      "step": 12990
    },
    {
      "epoch": 0.524479051096363,
      "grad_norm": 1.4793379306793213,
      "learning_rate": 0.00013636679886240945,
      "loss": 1.4294,
      "step": 13000
    },
    {
      "epoch": 0.524479051096363,
      "eval_loss": 1.2965750694274902,
      "eval_runtime": 14.8393,
      "eval_samples_per_second": 3.369,
      "eval_steps_per_second": 1.685,
      "step": 13000
    },
    {
      "epoch": 0.5248824965202832,
      "grad_norm": 1.2967662811279297,
      "learning_rate": 0.00013632994297082502,
      "loss": 1.4276,
      "step": 13010
    },
    {
      "epoch": 0.5252859419442035,
      "grad_norm": 1.180393099784851,
      "learning_rate": 0.00013629308707924055,
      "loss": 1.369,
      "step": 13020
    },
    {
      "epoch": 0.5256893873681238,
      "grad_norm": 1.1530303955078125,
      "learning_rate": 0.00013625623118765614,
      "loss": 1.2891,
      "step": 13030
    },
    {
      "epoch": 0.5260928327920441,
      "grad_norm": 1.3461809158325195,
      "learning_rate": 0.0001362193752960717,
      "loss": 1.308,
      "step": 13040
    },
    {
      "epoch": 0.5264962782159643,
      "grad_norm": 1.2325074672698975,
      "learning_rate": 0.00013618251940448727,
      "loss": 1.3015,
      "step": 13050
    },
    {
      "epoch": 0.5268997236398846,
      "grad_norm": 1.1556544303894043,
      "learning_rate": 0.00013614566351290283,
      "loss": 1.2972,
      "step": 13060
    },
    {
      "epoch": 0.5273031690638049,
      "grad_norm": 1.4689961671829224,
      "learning_rate": 0.0001361088076213184,
      "loss": 1.4147,
      "step": 13070
    },
    {
      "epoch": 0.5277066144877252,
      "grad_norm": 1.5473339557647705,
      "learning_rate": 0.00013607195172973395,
      "loss": 1.3682,
      "step": 13080
    },
    {
      "epoch": 0.5281100599116455,
      "grad_norm": 0.9131230711936951,
      "learning_rate": 0.00013603509583814952,
      "loss": 1.3225,
      "step": 13090
    },
    {
      "epoch": 0.5285135053355657,
      "grad_norm": 1.2172151803970337,
      "learning_rate": 0.00013599823994656508,
      "loss": 1.2099,
      "step": 13100
    },
    {
      "epoch": 0.528916950759486,
      "grad_norm": 1.5144784450531006,
      "learning_rate": 0.00013596138405498067,
      "loss": 1.3315,
      "step": 13110
    },
    {
      "epoch": 0.5293203961834063,
      "grad_norm": 1.2959859371185303,
      "learning_rate": 0.00013592452816339623,
      "loss": 1.1836,
      "step": 13120
    },
    {
      "epoch": 0.5297238416073266,
      "grad_norm": 1.6628402471542358,
      "learning_rate": 0.0001358876722718118,
      "loss": 1.4016,
      "step": 13130
    },
    {
      "epoch": 0.5301272870312469,
      "grad_norm": 0.8488547205924988,
      "learning_rate": 0.00013585081638022733,
      "loss": 1.1723,
      "step": 13140
    },
    {
      "epoch": 0.5305307324551671,
      "grad_norm": 1.5991772413253784,
      "learning_rate": 0.00013581396048864292,
      "loss": 1.4352,
      "step": 13150
    },
    {
      "epoch": 0.5309341778790874,
      "grad_norm": 0.9457444548606873,
      "learning_rate": 0.00013577710459705848,
      "loss": 1.1715,
      "step": 13160
    },
    {
      "epoch": 0.5313376233030077,
      "grad_norm": 1.448968529701233,
      "learning_rate": 0.00013574024870547405,
      "loss": 1.359,
      "step": 13170
    },
    {
      "epoch": 0.531741068726928,
      "grad_norm": 1.6511027812957764,
      "learning_rate": 0.0001357033928138896,
      "loss": 1.4121,
      "step": 13180
    },
    {
      "epoch": 0.5321445141508483,
      "grad_norm": 2.2065682411193848,
      "learning_rate": 0.00013566653692230517,
      "loss": 1.2759,
      "step": 13190
    },
    {
      "epoch": 0.5325479595747685,
      "grad_norm": 1.8917250633239746,
      "learning_rate": 0.00013562968103072073,
      "loss": 1.3604,
      "step": 13200
    },
    {
      "epoch": 0.5325479595747685,
      "eval_loss": 1.2952549457550049,
      "eval_runtime": 14.9392,
      "eval_samples_per_second": 3.347,
      "eval_steps_per_second": 1.673,
      "step": 13200
    },
    {
      "epoch": 0.5329514049986888,
      "grad_norm": 1.0236797332763672,
      "learning_rate": 0.0001355928251391363,
      "loss": 1.3215,
      "step": 13210
    },
    {
      "epoch": 0.5333548504226091,
      "grad_norm": 2.1985647678375244,
      "learning_rate": 0.00013555596924755186,
      "loss": 1.3005,
      "step": 13220
    },
    {
      "epoch": 0.5337582958465293,
      "grad_norm": 1.5832624435424805,
      "learning_rate": 0.00013551911335596745,
      "loss": 1.234,
      "step": 13230
    },
    {
      "epoch": 0.5341617412704497,
      "grad_norm": 1.4701805114746094,
      "learning_rate": 0.000135482257464383,
      "loss": 1.3228,
      "step": 13240
    },
    {
      "epoch": 0.5345651866943699,
      "grad_norm": 1.7982057332992554,
      "learning_rate": 0.00013544540157279858,
      "loss": 1.239,
      "step": 13250
    },
    {
      "epoch": 0.5349686321182902,
      "grad_norm": 1.29546058177948,
      "learning_rate": 0.00013540854568121414,
      "loss": 1.359,
      "step": 13260
    },
    {
      "epoch": 0.5353720775422105,
      "grad_norm": 1.1037358045578003,
      "learning_rate": 0.0001353716897896297,
      "loss": 1.2094,
      "step": 13270
    },
    {
      "epoch": 0.5357755229661307,
      "grad_norm": 1.3861016035079956,
      "learning_rate": 0.00013533483389804526,
      "loss": 1.2298,
      "step": 13280
    },
    {
      "epoch": 0.5361789683900511,
      "grad_norm": 1.4483237266540527,
      "learning_rate": 0.00013529797800646083,
      "loss": 1.2743,
      "step": 13290
    },
    {
      "epoch": 0.5365824138139713,
      "grad_norm": 1.7047330141067505,
      "learning_rate": 0.0001352611221148764,
      "loss": 1.3581,
      "step": 13300
    },
    {
      "epoch": 0.5369858592378915,
      "grad_norm": 0.9895704388618469,
      "learning_rate": 0.00013522426622329195,
      "loss": 1.3113,
      "step": 13310
    },
    {
      "epoch": 0.5373893046618119,
      "grad_norm": 1.1482239961624146,
      "learning_rate": 0.00013518741033170751,
      "loss": 1.3608,
      "step": 13320
    },
    {
      "epoch": 0.5377927500857321,
      "grad_norm": 1.1085999011993408,
      "learning_rate": 0.00013515055444012308,
      "loss": 1.4208,
      "step": 13330
    },
    {
      "epoch": 0.5381961955096525,
      "grad_norm": 1.2356319427490234,
      "learning_rate": 0.00013511369854853864,
      "loss": 1.2711,
      "step": 13340
    },
    {
      "epoch": 0.5385996409335727,
      "grad_norm": 1.3401522636413574,
      "learning_rate": 0.00013507684265695423,
      "loss": 1.5472,
      "step": 13350
    },
    {
      "epoch": 0.5390030863574929,
      "grad_norm": 1.4453908205032349,
      "learning_rate": 0.0001350399867653698,
      "loss": 1.2586,
      "step": 13360
    },
    {
      "epoch": 0.5394065317814133,
      "grad_norm": 2.345353603363037,
      "learning_rate": 0.00013500313087378536,
      "loss": 1.2407,
      "step": 13370
    },
    {
      "epoch": 0.5398099772053335,
      "grad_norm": 1.6860123872756958,
      "learning_rate": 0.00013496627498220092,
      "loss": 1.3163,
      "step": 13380
    },
    {
      "epoch": 0.5402134226292539,
      "grad_norm": 1.6139030456542969,
      "learning_rate": 0.00013492941909061648,
      "loss": 1.3048,
      "step": 13390
    },
    {
      "epoch": 0.5406168680531741,
      "grad_norm": 1.397336721420288,
      "learning_rate": 0.00013489256319903204,
      "loss": 1.3076,
      "step": 13400
    },
    {
      "epoch": 0.5406168680531741,
      "eval_loss": 1.2960609197616577,
      "eval_runtime": 14.8425,
      "eval_samples_per_second": 3.369,
      "eval_steps_per_second": 1.684,
      "step": 13400
    },
    {
      "epoch": 0.5410203134770943,
      "grad_norm": 1.672774076461792,
      "learning_rate": 0.0001348557073074476,
      "loss": 1.2016,
      "step": 13410
    },
    {
      "epoch": 0.5414237589010147,
      "grad_norm": 1.7374894618988037,
      "learning_rate": 0.00013481885141586317,
      "loss": 1.5423,
      "step": 13420
    },
    {
      "epoch": 0.5418272043249349,
      "grad_norm": 1.5033751726150513,
      "learning_rate": 0.00013478199552427876,
      "loss": 1.2783,
      "step": 13430
    },
    {
      "epoch": 0.5422306497488553,
      "grad_norm": 1.1128416061401367,
      "learning_rate": 0.0001347451396326943,
      "loss": 1.1636,
      "step": 13440
    },
    {
      "epoch": 0.5426340951727755,
      "grad_norm": 1.3100991249084473,
      "learning_rate": 0.00013470828374110986,
      "loss": 1.3966,
      "step": 13450
    },
    {
      "epoch": 0.5430375405966957,
      "grad_norm": 1.0849171876907349,
      "learning_rate": 0.00013467142784952542,
      "loss": 1.357,
      "step": 13460
    },
    {
      "epoch": 0.5434409860206161,
      "grad_norm": 1.6730660200119019,
      "learning_rate": 0.000134634571957941,
      "loss": 1.3427,
      "step": 13470
    },
    {
      "epoch": 0.5438444314445363,
      "grad_norm": 1.022652268409729,
      "learning_rate": 0.00013459771606635657,
      "loss": 1.4155,
      "step": 13480
    },
    {
      "epoch": 0.5442478768684567,
      "grad_norm": 1.2875120639801025,
      "learning_rate": 0.00013456086017477213,
      "loss": 1.2309,
      "step": 13490
    },
    {
      "epoch": 0.5446513222923769,
      "grad_norm": 1.282968282699585,
      "learning_rate": 0.0001345240042831877,
      "loss": 1.2469,
      "step": 13500
    },
    {
      "epoch": 0.5450547677162971,
      "grad_norm": 1.8507263660430908,
      "learning_rate": 0.00013448714839160326,
      "loss": 1.3123,
      "step": 13510
    },
    {
      "epoch": 0.5454582131402175,
      "grad_norm": 1.307843565940857,
      "learning_rate": 0.00013445029250001882,
      "loss": 1.1927,
      "step": 13520
    },
    {
      "epoch": 0.5458616585641377,
      "grad_norm": 1.2541338205337524,
      "learning_rate": 0.00013441343660843439,
      "loss": 1.3478,
      "step": 13530
    },
    {
      "epoch": 0.546265103988058,
      "grad_norm": 1.9253686666488647,
      "learning_rate": 0.00013437658071684995,
      "loss": 1.4054,
      "step": 13540
    },
    {
      "epoch": 0.5466685494119783,
      "grad_norm": 1.5640558004379272,
      "learning_rate": 0.00013433972482526554,
      "loss": 1.2491,
      "step": 13550
    },
    {
      "epoch": 0.5470719948358985,
      "grad_norm": 1.3337163925170898,
      "learning_rate": 0.00013430286893368107,
      "loss": 1.2224,
      "step": 13560
    },
    {
      "epoch": 0.5474754402598189,
      "grad_norm": 0.8001792430877686,
      "learning_rate": 0.00013426601304209664,
      "loss": 1.2605,
      "step": 13570
    },
    {
      "epoch": 0.5478788856837391,
      "grad_norm": 1.0047250986099243,
      "learning_rate": 0.0001342291571505122,
      "loss": 1.3094,
      "step": 13580
    },
    {
      "epoch": 0.5482823311076594,
      "grad_norm": 1.0650426149368286,
      "learning_rate": 0.0001341923012589278,
      "loss": 1.2732,
      "step": 13590
    },
    {
      "epoch": 0.5486857765315797,
      "grad_norm": 2.516629219055176,
      "learning_rate": 0.00013415544536734335,
      "loss": 1.3992,
      "step": 13600
    },
    {
      "epoch": 0.5486857765315797,
      "eval_loss": 1.2974644899368286,
      "eval_runtime": 14.8784,
      "eval_samples_per_second": 3.361,
      "eval_steps_per_second": 1.68,
      "step": 13600
    },
    {
      "epoch": 0.5490892219554999,
      "grad_norm": 1.2751710414886475,
      "learning_rate": 0.00013411858947575891,
      "loss": 1.2351,
      "step": 13610
    },
    {
      "epoch": 0.5494926673794203,
      "grad_norm": 1.1994268894195557,
      "learning_rate": 0.00013408173358417448,
      "loss": 1.4681,
      "step": 13620
    },
    {
      "epoch": 0.5498961128033405,
      "grad_norm": 1.3435167074203491,
      "learning_rate": 0.00013404487769259004,
      "loss": 1.4258,
      "step": 13630
    },
    {
      "epoch": 0.5502995582272608,
      "grad_norm": 1.2123277187347412,
      "learning_rate": 0.0001340080218010056,
      "loss": 1.3302,
      "step": 13640
    },
    {
      "epoch": 0.5507030036511811,
      "grad_norm": 1.4518605470657349,
      "learning_rate": 0.00013397116590942117,
      "loss": 1.3525,
      "step": 13650
    },
    {
      "epoch": 0.5511064490751013,
      "grad_norm": 1.2560169696807861,
      "learning_rate": 0.00013393431001783673,
      "loss": 1.3898,
      "step": 13660
    },
    {
      "epoch": 0.5515098944990217,
      "grad_norm": 1.415674090385437,
      "learning_rate": 0.00013389745412625232,
      "loss": 1.4259,
      "step": 13670
    },
    {
      "epoch": 0.5519133399229419,
      "grad_norm": 1.4394817352294922,
      "learning_rate": 0.00013386059823466785,
      "loss": 1.347,
      "step": 13680
    },
    {
      "epoch": 0.5523167853468622,
      "grad_norm": 1.2174159288406372,
      "learning_rate": 0.00013382374234308342,
      "loss": 1.1273,
      "step": 13690
    },
    {
      "epoch": 0.5527202307707825,
      "grad_norm": 1.0574296712875366,
      "learning_rate": 0.00013378688645149898,
      "loss": 1.1855,
      "step": 13700
    },
    {
      "epoch": 0.5531236761947027,
      "grad_norm": 1.83211350440979,
      "learning_rate": 0.00013375003055991457,
      "loss": 1.3885,
      "step": 13710
    },
    {
      "epoch": 0.553527121618623,
      "grad_norm": 1.959878921508789,
      "learning_rate": 0.00013371317466833013,
      "loss": 1.4935,
      "step": 13720
    },
    {
      "epoch": 0.5539305670425433,
      "grad_norm": 0.9732250571250916,
      "learning_rate": 0.0001336763187767457,
      "loss": 1.4023,
      "step": 13730
    },
    {
      "epoch": 0.5543340124664636,
      "grad_norm": 1.209715723991394,
      "learning_rate": 0.00013363946288516126,
      "loss": 1.2576,
      "step": 13740
    },
    {
      "epoch": 0.5547374578903839,
      "grad_norm": 1.3271706104278564,
      "learning_rate": 0.00013360260699357682,
      "loss": 1.2828,
      "step": 13750
    },
    {
      "epoch": 0.5551409033143042,
      "grad_norm": 1.6689412593841553,
      "learning_rate": 0.00013356575110199238,
      "loss": 1.1894,
      "step": 13760
    },
    {
      "epoch": 0.5555443487382244,
      "grad_norm": 1.242072343826294,
      "learning_rate": 0.00013352889521040795,
      "loss": 1.2253,
      "step": 13770
    },
    {
      "epoch": 0.5559477941621447,
      "grad_norm": 1.422061562538147,
      "learning_rate": 0.0001334920393188235,
      "loss": 1.2715,
      "step": 13780
    },
    {
      "epoch": 0.556351239586065,
      "grad_norm": 0.9502666592597961,
      "learning_rate": 0.0001334551834272391,
      "loss": 1.2776,
      "step": 13790
    },
    {
      "epoch": 0.5567546850099853,
      "grad_norm": 1.484028935432434,
      "learning_rate": 0.00013341832753565466,
      "loss": 1.2032,
      "step": 13800
    },
    {
      "epoch": 0.5567546850099853,
      "eval_loss": 1.2989126443862915,
      "eval_runtime": 14.5969,
      "eval_samples_per_second": 3.425,
      "eval_steps_per_second": 1.713,
      "step": 13800
    },
    {
      "epoch": 0.5571581304339056,
      "grad_norm": 1.437515377998352,
      "learning_rate": 0.0001333814716440702,
      "loss": 1.3393,
      "step": 13810
    },
    {
      "epoch": 0.5575615758578258,
      "grad_norm": 1.315672516822815,
      "learning_rate": 0.00013334461575248576,
      "loss": 1.2554,
      "step": 13820
    },
    {
      "epoch": 0.5579650212817461,
      "grad_norm": 1.6212412118911743,
      "learning_rate": 0.00013330775986090135,
      "loss": 1.2503,
      "step": 13830
    },
    {
      "epoch": 0.5583684667056664,
      "grad_norm": 1.0432552099227905,
      "learning_rate": 0.0001332709039693169,
      "loss": 1.1469,
      "step": 13840
    },
    {
      "epoch": 0.5587719121295867,
      "grad_norm": 1.8922579288482666,
      "learning_rate": 0.00013323404807773247,
      "loss": 1.3811,
      "step": 13850
    },
    {
      "epoch": 0.559175357553507,
      "grad_norm": 1.073272705078125,
      "learning_rate": 0.00013319719218614804,
      "loss": 1.209,
      "step": 13860
    },
    {
      "epoch": 0.5595788029774272,
      "grad_norm": 1.0290396213531494,
      "learning_rate": 0.0001331603362945636,
      "loss": 1.4221,
      "step": 13870
    },
    {
      "epoch": 0.5599822484013475,
      "grad_norm": 1.0588741302490234,
      "learning_rate": 0.00013312348040297916,
      "loss": 1.2885,
      "step": 13880
    },
    {
      "epoch": 0.5603856938252678,
      "grad_norm": 1.2518644332885742,
      "learning_rate": 0.00013308662451139473,
      "loss": 1.237,
      "step": 13890
    },
    {
      "epoch": 0.560789139249188,
      "grad_norm": 1.7136344909667969,
      "learning_rate": 0.0001330497686198103,
      "loss": 1.2728,
      "step": 13900
    },
    {
      "epoch": 0.5611925846731084,
      "grad_norm": 1.3089303970336914,
      "learning_rate": 0.00013301291272822588,
      "loss": 1.3989,
      "step": 13910
    },
    {
      "epoch": 0.5615960300970286,
      "grad_norm": 1.1833561658859253,
      "learning_rate": 0.00013297605683664144,
      "loss": 1.2318,
      "step": 13920
    },
    {
      "epoch": 0.5619994755209489,
      "grad_norm": 1.5568327903747559,
      "learning_rate": 0.00013293920094505698,
      "loss": 1.3546,
      "step": 13930
    },
    {
      "epoch": 0.5624029209448692,
      "grad_norm": 1.0502243041992188,
      "learning_rate": 0.00013290234505347254,
      "loss": 1.2387,
      "step": 13940
    },
    {
      "epoch": 0.5628063663687894,
      "grad_norm": 1.639212727546692,
      "learning_rate": 0.00013286548916188813,
      "loss": 1.3357,
      "step": 13950
    },
    {
      "epoch": 0.5632098117927098,
      "grad_norm": 1.379833459854126,
      "learning_rate": 0.0001328286332703037,
      "loss": 1.3555,
      "step": 13960
    },
    {
      "epoch": 0.56361325721663,
      "grad_norm": 1.1230286359786987,
      "learning_rate": 0.00013279177737871925,
      "loss": 1.2854,
      "step": 13970
    },
    {
      "epoch": 0.5640167026405503,
      "grad_norm": 1.3431313037872314,
      "learning_rate": 0.00013275492148713482,
      "loss": 1.5558,
      "step": 13980
    },
    {
      "epoch": 0.5644201480644706,
      "grad_norm": 1.5526864528656006,
      "learning_rate": 0.00013271806559555038,
      "loss": 1.237,
      "step": 13990
    },
    {
      "epoch": 0.5648235934883908,
      "grad_norm": 1.7174382209777832,
      "learning_rate": 0.00013268120970396594,
      "loss": 1.4776,
      "step": 14000
    },
    {
      "epoch": 0.5648235934883908,
      "eval_loss": 1.296846628189087,
      "eval_runtime": 14.825,
      "eval_samples_per_second": 3.373,
      "eval_steps_per_second": 1.686,
      "step": 14000
    }
  ],
  "logging_steps": 10,
  "max_steps": 50000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 250,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.0401450492194e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
