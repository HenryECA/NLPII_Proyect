{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# NLP II: Finetunning Llama\n",
    "\n",
    "This notebook serves as the main pipeline for processing data, creating a model, training it, and evaluating its performance on a text classification task.\n",
    "\n",
    "---\n",
    "## Objectives\n",
    "1. **Data Processing**: Load and preprocess text data.\n",
    "2. **Model Creation**: Define a machine learning or deep learning model for the task.\n",
    "3. **Training**: Train the model on the dataset.\n",
    "4. **Evaluation**: Assess the model's performance on a test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from evaluate import load\n",
    "import time\n",
    "\n",
    "from train2 import train\n",
    "from evaluate import evaluate_model\n",
    "from utils import get_dataset\n",
    "from keys_file import TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Data adquisition and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"READ_DATA\"       # If \"READ_DATA\" searches for folder data and uploads all data there\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### **Configurations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Quantization\n",
    "\n",
    "Quantizing BitsAndBytesConfig reduces memory usage and speeds up inference. The parameters are:\n",
    "\n",
    "* load_in_4bit: Loads the model in 4-bit precision to save memory. (Boolean)\n",
    "\n",
    "* bnb_4bit_quant_type: Sets quantization type (\"nf4\" for accuracy, \"fp4\" for speed).\n",
    "\n",
    "* bnb_4bit_compute_dtype: Defines the computation data type (float16, bfloat16, float32).\n",
    "\n",
    "* bnb_4bit_use_double_quant: Enables double quantization for improved accuracy.\n",
    "\n",
    "**Double quantization**\n",
    "\n",
    "Double quantization reduces quantization error by applying two rounds of quantization.\n",
    "\n",
    "    - The first round for is for the mains weights\n",
    "    - The second round is to capture residual errors, resulting in better model accuracy at a slight cost to speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "compute_dtype = getattr(torch, \"bfloat16\")  # Set computation data type to bfloat16\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                    # Enable loading the model in 4-bit precision\n",
    "    bnb_4bit_quant_type=\"nf4\",            # Specify quantization type as Normal Float 4\n",
    "    bnb_4bit_compute_dtype=compute_dtype, # Set computation data type\n",
    "    bnb_4bit_use_double_quant=True,       # Use double quantization for better accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B\"\n",
    "OUTPUT_DIR = \"./\" + MODEL_NAME + \"_results\"\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        quantization_config=bnb_config,  # Apply quantization configuration\n",
    "        device_map=\"auto\",                # Automatically map layers to devices\n",
    "        use_auth_token=TOKEN\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    add_eos_token=True,      # Add end-of-sequence token to the tokenizer\n",
    "    use_fast=True,           # Use the fast tokenizer implementation\n",
    "    padding_side='left',      # Pad sequences on the left side,\n",
    "    use_auth_token=TOKEN)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL INSTANTIATION\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id  # Set the model's padding token ID\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Training Parameters\n",
    "\n",
    "* output_dir: Directory to save checkpoints and logs.\n",
    "* eval_strategy: When to run evaluation (\"steps\" or \"epoch\").\n",
    "* do_eval: Enable/disable evaluation during training.\n",
    "* optim: Optimizer type (\"paged_adamw_8bit\" for memory-efficient AdamW).\n",
    "* per_device_train_batch_size: Batch size per device for training.\n",
    "* gradient_accumulation_steps: Accumulate gradients over steps for larger effective batch size.\n",
    "* per_device_eval_batch_size: Batch size per device for evaluation.\n",
    "* log_level: Logging verbosity level (\"debug\" for detailed logs).\n",
    "* logging_steps: Log metrics every N steps.\n",
    "* learning_rate: Initial learning rate for optimization.\n",
    "* eval_steps: Run evaluation every N steps.\n",
    "* max_steps: Total number of training steps.\n",
    "* save_steps: Save model checkpoints every N steps.\n",
    "* warmup_steps: Steps to gradually increase learning rate.\n",
    "* lr_scheduler_type: Type of learning rate scheduler (\"linear\" for steady decay)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,  # Directory for saving model checkpoints and logs\n",
    "    eval_strategy=\"steps\",                # Evaluation strategy: evaluate every few steps\n",
    "    do_eval=True,                         # Enable evaluation during training\n",
    "    optim=\"paged_adamw_8bit\",             # Use 8-bit AdamW optimizer for memory efficiency\n",
    "    per_device_train_batch_size=4,        # Batch size per device during training\n",
    "    gradient_accumulation_steps=2,        # Accumulate gradients over multiple steps\n",
    "    per_device_eval_batch_size=2,         # Batch size per device during evaluation\n",
    "    log_level=\"debug\",                    # Set logging level to debug for detailed logs\n",
    "    logging_steps=10,                     # Log metrics every 10 steps\n",
    "    learning_rate=LEARNING_RATE,                   # Initial learning rate\n",
    "    eval_steps=25,                        # Evaluate the model every 25 steps\n",
    "    max_steps=100,                        # Total number of training steps\n",
    "    save_steps=25,                        # Save checkpoints every 25 steps\n",
    "    warmup_steps=25,                      # Number of warmup steps for learning rate scheduler\n",
    "    lr_scheduler_type=\"linear\",           # Use a linear learning rate scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Finetuning Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 - LoRA\n",
    "\n",
    "Applies low-rank updates to pretrained models, enabling efficient fine-tuning by learning only small, additional matrices instead of updating all model weights. Hereâ€™s what each parameter does:\n",
    "\n",
    "* lora_alpha: Scaling factor for updates; higher values (16, 32) increase update impact, improving adaptation but may risk overfitting.\n",
    "\n",
    "* lora_dropout: Dropout rate for LoRA layers; typical values (0.0, 0.05) help prevent overfitting with minimal regularization.\n",
    "\n",
    "* r: Rank of LoRA matrices; lower values (4, 8) reduce parameters and memory, while higher values (16) offer more flexibility.\n",
    "\n",
    "* bias: Adds bias term (\"none\", \"all\", \"lora_only\") to control if and where bias adjustments are made.\n",
    "\n",
    "* target_modules: Specifies layers to apply LoRA (['k_proj', 'v_proj']); selecting fewer layers reduces compute cost but may limit effectiveness.\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "            lora_alpha=16,             # Scaling factor for LoRA updates\n",
    "            lora_dropout=0.05,         # Dropout rate applied to LoRA layers\n",
    "            r=16,                      # Rank of the LoRA decomposition\n",
    "            bias=\"none\",               # No bias is added to the LoRA layers\n",
    "            task_type=\"CAUSAL_LM\",     # Specify the task as causal language modeling\n",
    "            target_modules=[           # Modules to apply LoRA to\n",
    "                'k_proj', 'q_proj', 'v_proj', 'o_proj',\n",
    "                'gate_proj', 'down_proj', 'up_proj'\n",
    "            ]\n",
    "        )\n",
    "\n",
    "# Uncomment to avoid LoRA\n",
    "# lora_config = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 - PEFT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config= \"\"\n",
    "\n",
    "# Uncomment to avoid using PEFT\n",
    "# peft_config = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 - Supervised Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_config = \"\"\n",
    "\n",
    "# Uncomment to avoid SFT\n",
    "# sft_config = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 - RLHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlhf_config = \"\"\n",
    "\n",
    "# Uncomment to avoid RLHF\n",
    "# rlhf_config = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the specified training arguments\n",
    "train(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    training_arguments=training_arguments,\n",
    "\n",
    "    dataset=DATASET,\n",
    "    device=DEVICE,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "\n",
    "    lora_config=lora_config,\n",
    "    peft_config=peft_config,\n",
    "    sft_config=sft_config,\n",
    "    rlhf_config=rlhf_config,\n",
    ")\n",
    "\n",
    "# Make sure the model is retrieved or saved after training!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "\n",
    "# Load the trained model\n",
    "model = \"get_trained_model()\"\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model(model, tokenizer, dataset=\"test\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
