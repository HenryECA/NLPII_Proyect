{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: langdetect in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (1.0.9)\n",
      "Requirement already satisfied: nltk in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: immutabledict in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (4.2.1)\n",
      "Requirement already satisfied: datasets in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (3.0.2)\n",
      "Requirement already satisfied: bitsandbytes in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (0.44.1)\n",
      "Requirement already satisfied: six in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from langdetect) (1.16.0)\n",
      "Requirement already satisfied: click in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from nltk) (4.67.0)\n",
      "Requirement already satisfied: filelock in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: torch in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from bitsandbytes) (2.4.1+cu121)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: sympy in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.68)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install absl-py langdetect nltk immutabledict datasets bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 17:55:10.776396: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-25 17:55:10.782560: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732553710.791274   12583 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732553710.793952   12583 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-25 17:55:10.804263: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbcfd642c0049228e24f2b0a1779be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   0%|          | 0/271 [00:00<?, ?batch/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   0%|          | 1/271 [00:39<2:58:59, 39.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   1%|          | 2/271 [01:19<2:57:25, 39.57s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   1%|          | 3/271 [01:58<2:56:21, 39.48s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   1%|▏         | 4/271 [02:37<2:55:30, 39.44s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   2%|▏         | 5/271 [03:17<2:54:44, 39.42s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   2%|▏         | 6/271 [03:56<2:54:00, 39.40s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   3%|▎         | 7/271 [04:36<2:53:19, 39.39s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   3%|▎         | 8/271 [05:15<2:52:39, 39.39s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   3%|▎         | 9/271 [05:54<2:51:59, 39.39s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   4%|▎         | 10/271 [06:34<2:51:15, 39.37s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   4%|▍         | 11/271 [07:13<2:50:35, 39.37s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   4%|▍         | 12/271 [07:52<2:50:02, 39.39s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   5%|▍         | 13/271 [08:32<2:49:22, 39.39s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   5%|▌         | 14/271 [09:11<2:48:45, 39.40s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   6%|▌         | 15/271 [09:51<2:48:10, 39.42s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   6%|▌         | 16/271 [10:30<2:47:28, 39.41s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   6%|▋         | 17/271 [11:11<2:48:16, 39.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   7%|▋         | 18/271 [11:50<2:47:02, 39.61s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   7%|▋         | 19/271 [12:30<2:46:19, 39.60s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   7%|▋         | 20/271 [13:09<2:44:58, 39.44s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   8%|▊         | 21/271 [13:47<2:43:30, 39.24s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   8%|▊         | 22/271 [14:26<2:42:27, 39.15s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   8%|▊         | 23/271 [15:05<2:41:25, 39.05s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   9%|▉         | 24/271 [15:44<2:40:33, 39.00s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   9%|▉         | 25/271 [16:23<2:39:41, 38.95s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  10%|▉         | 26/271 [17:02<2:38:59, 38.94s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  10%|▉         | 27/271 [17:41<2:38:28, 38.97s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  10%|█         | 28/271 [18:20<2:37:48, 38.96s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  11%|█         | 29/271 [18:59<2:37:05, 38.95s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  11%|█         | 30/271 [19:38<2:36:26, 38.95s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  11%|█▏        | 31/271 [20:17<2:35:46, 38.94s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  12%|█▏        | 32/271 [20:56<2:35:09, 38.95s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  12%|█▏        | 33/271 [21:35<2:34:35, 38.97s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  13%|█▎        | 34/271 [22:14<2:34:12, 39.04s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  13%|█▎        | 35/271 [22:53<2:33:27, 39.02s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  13%|█▎        | 36/271 [23:31<2:32:32, 38.95s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  14%|█▎        | 37/271 [24:10<2:31:55, 38.95s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  14%|█▍        | 38/271 [24:49<2:31:08, 38.92s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  14%|█▍        | 39/271 [25:28<2:30:27, 38.91s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  15%|█▍        | 40/271 [26:07<2:29:52, 38.93s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  15%|█▌        | 41/271 [26:46<2:29:39, 39.04s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  15%|█▌        | 42/271 [27:25<2:28:55, 39.02s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  16%|█▌        | 43/271 [28:04<2:28:07, 38.98s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  16%|█▌        | 44/271 [28:43<2:27:23, 38.96s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  17%|█▋        | 45/271 [29:22<2:26:47, 38.97s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  17%|█▋        | 46/271 [30:01<2:26:04, 38.95s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  17%|█▋        | 47/271 [30:40<2:25:29, 38.97s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  18%|█▊        | 48/271 [31:19<2:24:48, 38.96s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  18%|█▊        | 49/271 [31:58<2:24:05, 38.94s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  18%|█▊        | 50/271 [32:37<2:23:29, 38.96s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  19%|█▉        | 51/271 [33:17<2:23:57, 39.26s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  19%|█▉        | 52/271 [33:56<2:23:10, 39.23s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  20%|█▉        | 53/271 [34:35<2:22:37, 39.25s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  20%|█▉        | 54/271 [35:15<2:22:08, 39.30s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  20%|██        | 55/271 [35:54<2:21:46, 39.38s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  21%|██        | 56/271 [36:36<2:23:01, 39.91s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  21%|██        | 57/271 [37:15<2:21:49, 39.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  21%|██▏       | 58/271 [37:54<2:20:53, 39.69s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  22%|██▏       | 59/271 [38:33<2:18:53, 39.31s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  22%|██▏       | 60/271 [39:11<2:17:23, 39.07s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  23%|██▎       | 61/271 [39:50<2:16:03, 38.87s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  23%|██▎       | 62/271 [40:29<2:15:19, 38.85s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  23%|██▎       | 63/271 [41:08<2:14:58, 38.93s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  24%|██▎       | 64/271 [41:46<2:14:00, 38.84s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  24%|██▍       | 65/271 [42:25<2:12:46, 38.67s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  24%|██▍       | 66/271 [43:03<2:11:52, 38.60s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  25%|██▍       | 67/271 [43:41<2:11:01, 38.54s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  25%|██▌       | 68/271 [44:20<2:10:15, 38.50s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  25%|██▌       | 69/271 [44:59<2:09:48, 38.56s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  26%|██▌       | 70/271 [45:38<2:10:01, 38.81s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  26%|██▌       | 71/271 [46:18<2:10:04, 39.02s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  27%|██▋       | 72/271 [46:57<2:09:46, 39.13s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  27%|██▋       | 73/271 [47:36<2:09:26, 39.23s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  27%|██▋       | 74/271 [48:16<2:08:56, 39.27s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  28%|██▊       | 75/271 [48:55<2:08:23, 39.31s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  28%|██▊       | 76/271 [49:34<2:07:44, 39.30s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  28%|██▊       | 77/271 [50:14<2:07:06, 39.31s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  29%|██▉       | 78/271 [50:53<2:06:30, 39.33s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  29%|██▉       | 79/271 [51:33<2:06:03, 39.39s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  30%|██▉       | 80/271 [52:12<2:05:18, 39.36s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  30%|██▉       | 81/271 [52:51<2:04:34, 39.34s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  30%|███       | 82/271 [53:30<2:03:51, 39.32s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  31%|███       | 83/271 [54:10<2:03:07, 39.29s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  31%|███       | 84/271 [54:49<2:02:33, 39.32s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  31%|███▏      | 85/271 [55:28<2:01:56, 39.33s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  32%|███▏      | 86/271 [56:08<2:01:22, 39.36s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  32%|███▏      | 87/271 [56:47<2:00:46, 39.38s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  32%|███▏      | 88/271 [57:27<2:00:10, 39.40s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  33%|███▎      | 89/271 [58:06<1:59:33, 39.41s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  33%|███▎      | 90/271 [58:46<1:58:54, 39.41s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  34%|███▎      | 91/271 [59:25<1:58:08, 39.38s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  34%|███▍      | 92/271 [1:00:04<1:57:24, 39.36s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  34%|███▍      | 93/271 [1:00:44<1:56:58, 39.43s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  35%|███▍      | 94/271 [1:01:23<1:56:11, 39.39s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  35%|███▌      | 95/271 [1:02:02<1:55:25, 39.35s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  35%|███▌      | 96/271 [1:02:42<1:54:47, 39.36s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  36%|███▌      | 97/271 [1:03:21<1:54:05, 39.34s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  36%|███▌      | 98/271 [1:04:00<1:53:25, 39.34s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  37%|███▋      | 99/271 [1:04:40<1:52:43, 39.32s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  37%|███▋      | 100/271 [1:05:19<1:52:04, 39.33s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  37%|███▋      | 101/271 [1:05:58<1:51:21, 39.30s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  38%|███▊      | 102/271 [1:06:38<1:50:41, 39.30s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  38%|███▊      | 103/271 [1:07:17<1:49:59, 39.28s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  38%|███▊      | 104/271 [1:07:56<1:49:19, 39.28s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  39%|███▊      | 105/271 [1:08:35<1:48:39, 39.27s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  39%|███▉      | 106/271 [1:09:15<1:48:02, 39.29s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  39%|███▉      | 107/271 [1:09:54<1:47:23, 39.29s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  40%|███▉      | 108/271 [1:10:33<1:46:47, 39.31s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  40%|████      | 109/271 [1:11:13<1:46:14, 39.35s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  41%|████      | 110/271 [1:11:52<1:45:38, 39.37s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  41%|████      | 111/271 [1:12:32<1:45:02, 39.39s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  41%|████▏     | 112/271 [1:13:11<1:44:24, 39.40s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  42%|████▏     | 113/271 [1:13:50<1:43:42, 39.38s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  42%|████▏     | 114/271 [1:14:30<1:43:06, 39.40s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  42%|████▏     | 115/271 [1:15:09<1:42:25, 39.40s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  43%|████▎     | 116/271 [1:15:49<1:41:46, 39.40s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  43%|████▎     | 117/271 [1:16:28<1:41:01, 39.36s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  44%|████▎     | 118/271 [1:17:07<1:40:19, 39.34s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  44%|████▍     | 119/271 [1:17:46<1:39:38, 39.33s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  44%|████▍     | 120/271 [1:18:26<1:38:57, 39.32s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  45%|████▍     | 121/271 [1:19:05<1:38:16, 39.31s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  45%|████▌     | 122/271 [1:19:44<1:37:37, 39.31s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  45%|████▌     | 123/271 [1:20:24<1:36:56, 39.30s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  46%|████▌     | 124/271 [1:21:03<1:36:17, 39.30s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  46%|████▌     | 125/271 [1:21:42<1:35:42, 39.33s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  46%|████▋     | 126/271 [1:22:22<1:35:03, 39.34s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  47%|████▋     | 127/271 [1:23:01<1:34:24, 39.34s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  47%|████▋     | 128/271 [1:23:40<1:33:46, 39.35s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  48%|████▊     | 129/271 [1:24:20<1:33:07, 39.35s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  48%|████▊     | 130/271 [1:24:59<1:32:30, 39.36s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  48%|████▊     | 131/271 [1:25:39<1:31:52, 39.38s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  49%|████▊     | 132/271 [1:26:18<1:31:14, 39.38s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  49%|████▉     | 133/271 [1:26:57<1:30:31, 39.36s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  49%|████▉     | 134/271 [1:27:37<1:29:49, 39.34s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  50%|████▉     | 135/271 [1:28:16<1:29:08, 39.32s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  50%|█████     | 136/271 [1:28:55<1:28:28, 39.33s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  51%|█████     | 137/271 [1:29:34<1:27:48, 39.31s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  51%|█████     | 138/271 [1:30:14<1:27:09, 39.32s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  51%|█████▏    | 139/271 [1:30:53<1:26:31, 39.33s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  52%|█████▏    | 140/271 [1:31:32<1:25:51, 39.33s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  52%|█████▏    | 141/271 [1:32:12<1:25:13, 39.34s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  52%|█████▏    | 142/271 [1:32:51<1:24:33, 39.33s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  53%|█████▎    | 143/271 [1:33:30<1:23:53, 39.33s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  53%|█████▎    | 144/271 [1:34:10<1:23:18, 39.36s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  54%|█████▎    | 145/271 [1:34:49<1:22:39, 39.36s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  54%|█████▍    | 146/271 [1:35:29<1:21:59, 39.36s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  54%|█████▍    | 147/271 [1:36:08<1:21:17, 39.33s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  55%|█████▍    | 148/271 [1:36:47<1:20:37, 39.33s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  55%|█████▍    | 149/271 [1:37:27<1:19:59, 39.34s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  55%|█████▌    | 150/271 [1:38:06<1:19:22, 39.36s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  56%|█████▌    | 151/271 [1:38:45<1:18:42, 39.35s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  56%|█████▌    | 152/271 [1:39:25<1:18:02, 39.35s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  56%|█████▋    | 153/271 [1:40:04<1:17:22, 39.34s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  57%|█████▋    | 154/271 [1:40:43<1:16:45, 39.36s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  57%|█████▋    | 155/271 [1:41:23<1:15:57, 39.29s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  58%|█████▊    | 156/271 [1:42:01<1:14:47, 39.03s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  58%|█████▊    | 157/271 [1:42:39<1:13:49, 38.85s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  58%|█████▊    | 158/271 [1:43:18<1:12:55, 38.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  59%|█████▊    | 159/271 [1:43:56<1:12:07, 38.64s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  59%|█████▉    | 160/271 [1:44:35<1:11:21, 38.58s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  59%|█████▉    | 161/271 [1:45:13<1:10:39, 38.54s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  60%|█████▉    | 162/271 [1:45:51<1:09:52, 38.47s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  60%|██████    | 163/271 [1:46:30<1:09:13, 38.46s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  61%|██████    | 164/271 [1:47:08<1:08:32, 38.44s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  61%|██████    | 165/271 [1:47:47<1:07:52, 38.42s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  61%|██████▏   | 166/271 [1:48:25<1:07:15, 38.43s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  62%|██████▏   | 167/271 [1:49:03<1:06:35, 38.42s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  62%|██████▏   | 168/271 [1:49:42<1:05:56, 38.41s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  62%|██████▏   | 169/271 [1:50:20<1:05:17, 38.41s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  63%|██████▎   | 170/271 [1:50:59<1:04:39, 38.41s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  63%|██████▎   | 171/271 [1:51:37<1:04:00, 38.40s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  63%|██████▎   | 172/271 [1:52:15<1:03:21, 38.40s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  64%|██████▍   | 173/271 [1:52:54<1:02:43, 38.41s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  64%|██████▍   | 174/271 [1:53:32<1:02:03, 38.38s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  65%|██████▍   | 175/271 [1:54:11<1:01:24, 38.38s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  65%|██████▍   | 176/271 [1:54:49<1:00:45, 38.38s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  65%|██████▌   | 177/271 [1:55:27<1:00:09, 38.40s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  66%|██████▌   | 178/271 [1:56:06<59:32, 38.41s/batch]  Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  66%|██████▌   | 179/271 [1:56:44<58:53, 38.41s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  66%|██████▋   | 180/271 [1:57:24<58:47, 38.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  67%|██████▋   | 181/271 [1:58:02<58:02, 38.70s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  67%|██████▋   | 182/271 [1:58:42<57:40, 38.88s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  68%|██████▊   | 183/271 [1:59:21<57:13, 39.02s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  68%|██████▊   | 184/271 [2:00:00<56:41, 39.10s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  68%|██████▊   | 185/271 [2:00:40<56:07, 39.16s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  69%|██████▊   | 186/271 [2:01:19<55:32, 39.20s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  69%|██████▉   | 187/271 [2:01:58<54:54, 39.22s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  69%|██████▉   | 188/271 [2:02:37<54:16, 39.23s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  70%|██████▉   | 189/271 [2:03:17<53:40, 39.27s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  70%|███████   | 190/271 [2:03:56<53:02, 39.29s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  70%|███████   | 191/271 [2:04:36<52:25, 39.31s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  71%|███████   | 192/271 [2:05:15<51:47, 39.33s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  71%|███████   | 193/271 [2:05:54<51:09, 39.35s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  72%|███████▏  | 194/271 [2:06:34<50:29, 39.35s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  72%|███████▏  | 195/271 [2:07:13<49:50, 39.35s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  72%|███████▏  | 196/271 [2:07:52<49:10, 39.34s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  73%|███████▎  | 197/271 [2:08:32<48:33, 39.37s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  73%|███████▎  | 198/271 [2:09:11<47:53, 39.37s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  73%|███████▎  | 199/271 [2:09:50<47:14, 39.37s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  74%|███████▍  | 200/271 [2:10:30<46:35, 39.38s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  74%|███████▍  | 201/271 [2:11:09<45:56, 39.38s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  75%|███████▍  | 202/271 [2:11:49<45:17, 39.38s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  75%|███████▍  | 203/271 [2:12:28<44:39, 39.41s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  75%|███████▌  | 204/271 [2:13:07<43:46, 39.20s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  76%|███████▌  | 205/271 [2:13:46<42:57, 39.05s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  76%|███████▌  | 206/271 [2:14:24<42:11, 38.95s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  76%|███████▋  | 207/271 [2:15:03<41:29, 38.90s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  77%|███████▋  | 208/271 [2:15:42<40:48, 38.87s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  77%|███████▋  | 209/271 [2:16:21<40:07, 38.83s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  77%|███████▋  | 210/271 [2:16:59<39:27, 38.81s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  78%|███████▊  | 211/271 [2:17:38<38:47, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  78%|███████▊  | 212/271 [2:18:17<38:07, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  79%|███████▊  | 213/271 [2:18:56<37:28, 38.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  79%|███████▉  | 214/271 [2:19:34<36:49, 38.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  79%|███████▉  | 215/271 [2:20:13<36:10, 38.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  80%|███████▉  | 216/271 [2:20:52<35:31, 38.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  80%|████████  | 217/271 [2:21:31<34:53, 38.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  80%|████████  | 218/271 [2:22:09<34:14, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  81%|████████  | 219/271 [2:22:48<33:36, 38.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  81%|████████  | 220/271 [2:23:27<32:57, 38.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  82%|████████▏ | 221/271 [2:24:06<32:19, 38.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  82%|████████▏ | 222/271 [2:24:44<31:40, 38.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  82%|████████▏ | 223/271 [2:25:23<31:01, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  83%|████████▎ | 224/271 [2:26:02<30:22, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  83%|████████▎ | 225/271 [2:26:41<29:44, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  83%|████████▎ | 226/271 [2:27:20<29:05, 38.80s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  84%|████████▍ | 227/271 [2:27:58<28:27, 38.80s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  84%|████████▍ | 228/271 [2:28:37<27:48, 38.80s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  85%|████████▍ | 229/271 [2:29:16<27:09, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  85%|████████▍ | 230/271 [2:29:55<26:30, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  85%|████████▌ | 231/271 [2:30:34<25:51, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  86%|████████▌ | 232/271 [2:31:12<25:12, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  86%|████████▌ | 233/271 [2:31:51<24:33, 38.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  86%|████████▋ | 234/271 [2:32:30<23:54, 38.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  87%|████████▋ | 235/271 [2:33:09<23:16, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  87%|████████▋ | 236/271 [2:33:48<22:37, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  87%|████████▋ | 237/271 [2:34:26<21:58, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  88%|████████▊ | 238/271 [2:35:05<21:20, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  88%|████████▊ | 239/271 [2:35:44<20:41, 38.80s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  89%|████████▊ | 240/271 [2:36:23<20:02, 38.80s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  89%|████████▉ | 241/271 [2:37:02<19:24, 38.80s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  89%|████████▉ | 242/271 [2:37:40<18:45, 38.80s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  90%|████████▉ | 243/271 [2:38:19<18:06, 38.80s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  90%|█████████ | 244/271 [2:38:58<17:27, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  90%|█████████ | 245/271 [2:39:37<16:48, 38.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  91%|█████████ | 246/271 [2:40:16<16:09, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  91%|█████████ | 247/271 [2:40:54<15:30, 38.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  92%|█████████▏| 248/271 [2:41:33<14:51, 38.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  92%|█████████▏| 249/271 [2:42:12<14:13, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  92%|█████████▏| 250/271 [2:42:51<13:33, 38.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  93%|█████████▎| 251/271 [2:43:29<12:55, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  93%|█████████▎| 252/271 [2:44:08<12:16, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  93%|█████████▎| 253/271 [2:44:47<11:37, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  94%|█████████▎| 254/271 [2:45:26<10:59, 38.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  94%|█████████▍| 255/271 [2:46:04<10:20, 38.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  94%|█████████▍| 256/271 [2:46:43<09:41, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  95%|█████████▍| 257/271 [2:47:22<09:02, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  95%|█████████▌| 258/271 [2:48:01<08:23, 38.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  96%|█████████▌| 259/271 [2:48:39<07:45, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  96%|█████████▌| 260/271 [2:49:18<07:06, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  96%|█████████▋| 261/271 [2:49:57<06:27, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  97%|█████████▋| 262/271 [2:50:36<05:49, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  97%|█████████▋| 263/271 [2:51:15<05:10, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  97%|█████████▋| 264/271 [2:51:53<04:31, 38.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  98%|█████████▊| 265/271 [2:52:32<03:52, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  98%|█████████▊| 266/271 [2:53:11<03:13, 38.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  99%|█████████▊| 267/271 [2:53:50<02:35, 38.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  99%|█████████▉| 268/271 [2:54:29<01:56, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  99%|█████████▉| 269/271 [2:55:07<01:17, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches: 100%|█████████▉| 270/271 [2:55:46<00:38, 38.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches: 100%|██████████| 271/271 [2:56:05<00:00, 38.99s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses saved to data/input_response_data.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"google/IFEval\")\n",
    "\n",
    "# Model name\n",
    "#model_name = \"Qwen/Qwen2.5-7B\"\n",
    "model_name = \"../models/meta-llama/Llama-3.1-8B_lora_FINAL/checkpoint-14000\"\n",
    "\n",
    "# Quantization configuration using bitsandbytes library\n",
    "compute_dtype = getattr(torch, \"bfloat16\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load the pre-trained model with the specified quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load the tokenizer for Mistral\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    add_eos_token=True,\n",
    "    use_fast=True,\n",
    "    padding_side='left'\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token to EOS token\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id  # Set the model's padding token ID\n",
    "\n",
    "# Disable gradients to save memory and computation\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)  # Disable gradient computation globally\n",
    "\n",
    "# Prepare the output file\n",
    "output_dir = \"data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"input_response_data.jsonl\")\n",
    "\n",
    "# Batch processing\n",
    "batch_size = 2  # Adjust based on your GPU memory capacity\n",
    "max_length = 256  # Limit output length to avoid excessive memory usage\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, len(dataset['train']), batch_size), desc=\"Processing Batches\", unit=\"batch\"):\n",
    "        try:\n",
    "            if (i + batch_size) > len(dataset['train']):\n",
    "                batch_prompts = dataset['train']['prompt'][i:len(dataset['train'])]\n",
    "            else:\n",
    "                batch_prompts = dataset['train']['prompt'][i:i + batch_size]\n",
    "            # Tokenize inputs\n",
    "            inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            \n",
    "            # Generate responses\n",
    "            with torch.no_grad():  # Ensure gradients are disabled during generation\n",
    "                if max_length:\n",
    "                    outputs = model.generate(**inputs, max_new_tokens=max_length)\n",
    "                else:\n",
    "                    outputs = model.generate(**inputs)\n",
    "            # Decode responses\n",
    "            responses = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "\n",
    "            # Write each response directly to the file\n",
    "            for prompt, response in zip(batch_prompts, responses):\n",
    "                f.write(json.dumps({\"prompt\": prompt, \"response\": response}) + '\\n')\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {i}: {e}\")\n",
    "\n",
    "print(f\"Responses saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"prompt\": \"Write a 300+ word summary of the wikipedia page \\\"https://en.wikipedia.org/wiki/Raymond_III,_Count_of_Tripoli\\\". Do not use any commas and highlight at least 3 sections that has titles in markdown format, for example *highlighted section part 1*, *highlighted section part 2*, *highlighted section part 3*.\", \"response\": \"Raymond III was the Count of Tripoli from 1152 to 1187 and Prince of Galilee and Tiberias in the Kingdom of Jerusalem. He was born in 1140 to Raymond II of Tripoli and Hodierna of Jerusalem. His mother was the daughter of Baldwin II of Jerusalem. \\n\\n*Early Life and Succession*\\n\\nRaymond III was only a child when his father was murdered. His mother Hodierna was regent until Raymond came of age. In 1155 Raymond married Eschiva the daughter of Walter I of Beirut. They had three children: Raymond IV Bertrand and a daughter who married Guy of Lusignan. \\n\\n*Reign*\\n\\nRaymond III's reign was marked by a series of conflicts and alliances with the Muslim world. He was involved in the defense of the Kingdom of Jerusalem against Nur ad-Din and later Saladin. He was also a key figure in the internal politics of the kingdom. He was a supporter of the queen mother Amalric of Jerusalem and opposed the succession of Guy of Lusignan. \\n\\n*Later Life and Death*\\n\\nIn 1187 Raymond III was part of the disastrous Battle of Hattin where the Christian forces were defeated by Saladin. He was one of the few to escape the battlefield but died later that year. His son Raymond IV succeeded him as Count of Tripoli. \\n\\nRaymond III's life and reign were marked by the complex politics and warfare of the Crusader states. He was a key figure in the defense of the Kingdom of Jerusalem and his death marked a significant loss for the Christian forces in the region. His legacy is a testament to the turbulent times in which he lived and the challenges faced by the Crusader states in their relations with the Muslim world.\"}\n",
    "b = {\"prompt\": \"I am planning a trip to Japan, and I would like thee to write an itinerary for my journey in a Shakespearean style. You are not allowed to use any commas in your response.\", \"response\": \"Hark! Hearken to the tale of thy journey to the land of the rising sun, Japan. \\n\\nUpon the morrow of thy arrival, thou shalt find thyself in Tokyo, the city of lights and towers. In the morn, thou shalt explore the grandeur of the Imperial Palace, a sight to behold. As the sun reaches its zenith, thou shalt partake in a feast of sushi, a delicacy of the land. As the day wanes, thou shalt wander through the electric streets of Akihabara, a realm of technology and animation.\\n\\nOn the second day, thou shalt journey to the ancient city of Kyoto. In the soft light of dawn, thou shalt visit the golden pavilion of Kinkaku-ji, a vision of beauty and tranquility. As the day unfolds, thou shalt wander through the bamboo grove of Arashiyama, a place of peace and serenity. As the sun sets, thou shalt partake in a traditional tea ceremony, a ritual of grace and harmony.\\n\\nOn the third day, thou shalt travel to the city of Hiroshima. In the morning, thou shalt pay thy respects at the Peace Memorial Park, a place of remembrance and hope. As the day progresses, thou shalt journey to the island of Miyajima, home to the floating torii gate, a sight of wonder and awe. As the day ends, thou shalt feast on okonomiyaki, a dish of delight and satisfaction.\\n\\nOn the fourth day, thou shalt return to Tokyo. In the morning, thou shalt ascend the Tokyo Skytree, a tower of height and grandeur. As the day unfolds, thou shalt explore the bustling streets of Shibuya, a realm of fashion and culture. As the sun sets, thou shalt dine in the vibrant district of Roppongi, a place of gastronomy and nightlife.\\n\\nOn the fifth and final day, thou shalt bid farewell to the land of the rising sun. With memories of beauty and wonder, thou shalt embark on thy journey home, carrying with thee the spirit of Japan. \\n\\nThus ends the tale of thy journey, a tale of exploration and discovery. May thy travels be filled with joy and adventure, and may the land of the rising sun forever hold a place in thy heart.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt\n",
      "\n",
      " I am planning a trip to Japan, and I would like thee to write an itinerary for my journey in a Shakespearean style. You are not allowed to use any commas in your response.\n",
      "response\n",
      "\n",
      " Hark! Hearken to the tale of thy journey to the land of the rising sun, Japan. \n",
      "\n",
      "Upon the morrow of thy arrival, thou shalt find thyself in Tokyo, the city of lights and towers. In the morn, thou shalt explore the grandeur of the Imperial Palace, a sight to behold. As the sun reaches its zenith, thou shalt partake in a feast of sushi, a delicacy of the land. As the day wanes, thou shalt wander through the electric streets of Akihabara, a realm of technology and animation.\n",
      "\n",
      "On the second day, thou shalt journey to the ancient city of Kyoto. In the soft light of dawn, thou shalt visit the golden pavilion of Kinkaku-ji, a vision of beauty and tranquility. As the day unfolds, thou shalt wander through the bamboo grove of Arashiyama, a place of peace and serenity. As the sun sets, thou shalt partake in a traditional tea ceremony, a ritual of grace and harmony.\n",
      "\n",
      "On the third day, thou shalt travel to the city of Hiroshima. In the morning, thou shalt pay thy respects at the Peace Memorial Park, a place of remembrance and hope. As the day progresses, thou shalt journey to the island of Miyajima, home to the floating torii gate, a sight of wonder and awe. As the day ends, thou shalt feast on okonomiyaki, a dish of delight and satisfaction.\n",
      "\n",
      "On the fourth day, thou shalt return to Tokyo. In the morning, thou shalt ascend the Tokyo Skytree, a tower of height and grandeur. As the day unfolds, thou shalt explore the bustling streets of Shibuya, a realm of fashion and culture. As the sun sets, thou shalt dine in the vibrant district of Roppongi, a place of gastronomy and nightlife.\n",
      "\n",
      "On the fifth and final day, thou shalt bid farewell to the land of the rising sun. With memories of beauty and wonder, thou shalt embark on thy journey home, carrying with thee the spirit of Japan. \n",
      "\n",
      "Thus ends the tale of thy journey, a tale of exploration and discovery. May thy travels be filled with joy and adventure, and may the land of the rising sun forever hold a place in thy heart.\n"
     ]
    }
   ],
   "source": [
    "for key in b.keys():\n",
    "    print(key)\n",
    "    print(\"\\n\",b[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
