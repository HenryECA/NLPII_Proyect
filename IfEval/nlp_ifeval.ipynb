{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: langdetect in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (1.0.9)\n",
      "Requirement already satisfied: nltk in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: immutabledict in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (4.2.1)\n",
      "Requirement already satisfied: datasets in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (3.0.2)\n",
      "Requirement already satisfied: bitsandbytes in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (0.44.1)\n",
      "Requirement already satisfied: six in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from langdetect) (1.16.0)\n",
      "Requirement already satisfied: click in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: filelock in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: xxhash in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: torch in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from bitsandbytes) (2.4.1+cu121)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: sympy in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from torch->bitsandbytes) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.68)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/joaquinmirma/PracticaNLP/.venv/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Using cached tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.0\n",
      "    Uninstalling tqdm-4.64.0:\n",
      "      Successfully uninstalled tqdm-4.64.0\n",
      "Successfully installed tqdm-4.67.0\n"
     ]
    }
   ],
   "source": [
    "!pip install absl-py langdetect nltk immutabledict datasets bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 12:52:51.369247: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-24 12:52:51.378213: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732449171.399625   15942 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732449171.408225   15942 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-24 12:52:51.422182: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bd7b38d981430db9338159f8621d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   0%|          | 0/271 [00:00<?, ?batch/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   0%|          | 1/271 [00:20<1:30:34, 20.13s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   1%|          | 2/271 [00:39<1:29:06, 19.88s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   1%|          | 3/271 [00:59<1:28:24, 19.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   1%|▏         | 4/271 [01:19<1:27:52, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   2%|▏         | 5/271 [01:38<1:27:24, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   2%|▏         | 6/271 [01:58<1:27:01, 19.70s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   3%|▎         | 7/271 [02:18<1:26:41, 19.70s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   3%|▎         | 8/271 [02:37<1:26:18, 19.69s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   3%|▎         | 9/271 [02:57<1:25:56, 19.68s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   4%|▎         | 10/271 [03:17<1:25:34, 19.67s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   4%|▍         | 11/271 [03:36<1:25:14, 19.67s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   4%|▍         | 12/271 [03:56<1:24:58, 19.69s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   5%|▍         | 13/271 [04:16<1:24:40, 19.69s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   5%|▌         | 14/271 [04:36<1:24:22, 19.70s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   6%|▌         | 15/271 [04:55<1:24:03, 19.70s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   6%|▌         | 16/271 [05:15<1:23:43, 19.70s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   6%|▋         | 17/271 [05:35<1:23:25, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   7%|▋         | 18/271 [05:54<1:23:05, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   7%|▋         | 19/271 [06:14<1:22:45, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   7%|▋         | 20/271 [06:34<1:22:26, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   8%|▊         | 21/271 [06:53<1:22:07, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   8%|▊         | 22/271 [07:13<1:21:49, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   8%|▊         | 23/271 [07:33<1:21:30, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   9%|▉         | 24/271 [07:53<1:21:10, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   9%|▉         | 25/271 [08:12<1:20:52, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  10%|▉         | 26/271 [08:32<1:20:33, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  10%|▉         | 27/271 [08:52<1:20:12, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  10%|█         | 28/271 [09:12<1:19:55, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  11%|█         | 29/271 [09:31<1:19:36, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  11%|█         | 30/271 [09:51<1:19:16, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  11%|█▏        | 31/271 [10:11<1:18:56, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  12%|█▏        | 32/271 [10:31<1:18:36, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  12%|█▏        | 33/271 [10:50<1:18:17, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  13%|█▎        | 34/271 [11:10<1:17:59, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  13%|█▎        | 35/271 [11:30<1:17:40, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  13%|█▎        | 36/271 [11:50<1:17:19, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  14%|█▎        | 37/271 [12:09<1:17:01, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  14%|█▍        | 38/271 [12:29<1:16:42, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  14%|█▍        | 39/271 [12:49<1:16:22, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  15%|█▍        | 40/271 [13:09<1:16:05, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  15%|█▌        | 41/271 [13:28<1:15:45, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  15%|█▌        | 42/271 [13:48<1:15:26, 19.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  16%|█▌        | 43/271 [14:08<1:15:05, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  16%|█▌        | 44/271 [14:28<1:14:47, 19.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  17%|█▋        | 45/271 [14:47<1:14:29, 19.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  17%|█▋        | 46/271 [15:07<1:14:07, 19.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  17%|█▋        | 47/271 [15:27<1:13:48, 19.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  18%|█▊        | 48/271 [15:47<1:13:27, 19.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  18%|█▊        | 49/271 [16:07<1:13:06, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  18%|█▊        | 50/271 [16:26<1:12:46, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  19%|█▉        | 51/271 [16:46<1:12:26, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  19%|█▉        | 52/271 [17:06<1:12:07, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  20%|█▉        | 53/271 [17:26<1:11:48, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  20%|█▉        | 54/271 [17:45<1:11:27, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  20%|██        | 55/271 [18:05<1:11:12, 19.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  21%|██        | 56/271 [18:25<1:10:51, 19.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  21%|██        | 57/271 [18:45<1:10:29, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  21%|██▏       | 58/271 [19:04<1:10:10, 19.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  22%|██▏       | 59/271 [19:24<1:09:49, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  22%|██▏       | 60/271 [19:44<1:09:28, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  23%|██▎       | 61/271 [20:04<1:09:08, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  23%|██▎       | 62/271 [20:23<1:08:48, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  23%|██▎       | 63/271 [20:43<1:08:29, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  24%|██▎       | 64/271 [21:03<1:08:09, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  24%|██▍       | 65/271 [21:23<1:07:45, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  24%|██▍       | 66/271 [21:42<1:07:27, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  25%|██▍       | 67/271 [22:02<1:07:09, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  25%|██▌       | 68/271 [22:22<1:06:50, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  25%|██▌       | 69/271 [22:42<1:06:30, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  26%|██▌       | 70/271 [23:01<1:06:10, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  26%|██▌       | 71/271 [23:21<1:05:52, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  27%|██▋       | 72/271 [23:41<1:05:32, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  27%|██▋       | 73/271 [24:01<1:05:12, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  27%|██▋       | 74/271 [24:20<1:04:51, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  28%|██▊       | 75/271 [24:40<1:04:31, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  28%|██▊       | 76/271 [25:00<1:04:11, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  28%|██▊       | 77/271 [25:20<1:03:50, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  29%|██▉       | 78/271 [25:39<1:03:30, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  29%|██▉       | 79/271 [25:59<1:03:09, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  30%|██▉       | 80/271 [26:19<1:02:50, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  30%|██▉       | 81/271 [26:39<1:02:29, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  30%|███       | 82/271 [26:58<1:02:09, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  31%|███       | 83/271 [27:18<1:01:45, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  31%|███       | 84/271 [27:38<1:01:27, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  31%|███▏      | 85/271 [27:57<1:01:08, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  32%|███▏      | 86/271 [28:17<1:00:50, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  32%|███▏      | 87/271 [28:37<1:00:31, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  32%|███▏      | 88/271 [28:57<1:00:13, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  33%|███▎      | 89/271 [29:17<59:54, 19.75s/batch]  Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  33%|███▎      | 90/271 [29:36<59:33, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  34%|███▎      | 91/271 [29:56<59:12, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  34%|███▍      | 92/271 [30:16<58:53, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  34%|███▍      | 93/271 [30:36<58:42, 19.79s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  35%|███▍      | 94/271 [30:55<58:19, 19.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  35%|███▌      | 95/271 [31:15<57:57, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  35%|███▌      | 96/271 [31:35<57:38, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  36%|███▌      | 97/271 [31:55<57:18, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  36%|███▌      | 98/271 [32:14<56:58, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  37%|███▋      | 99/271 [32:34<56:38, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  37%|███▋      | 100/271 [32:54<56:18, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  37%|███▋      | 101/271 [33:14<56:07, 19.81s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  38%|███▊      | 102/271 [33:34<55:43, 19.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  38%|███▊      | 103/271 [33:53<55:20, 19.76s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  38%|███▊      | 104/271 [34:13<54:58, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  39%|███▊      | 105/271 [34:33<54:38, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  39%|███▉      | 106/271 [34:52<54:18, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  39%|███▉      | 107/271 [35:12<53:56, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  40%|███▉      | 108/271 [35:32<53:36, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  40%|████      | 109/271 [35:52<53:17, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  41%|████      | 110/271 [36:11<52:58, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  41%|████      | 111/271 [36:31<52:39, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  41%|████▏     | 112/271 [36:51<52:19, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  42%|████▏     | 113/271 [37:11<51:59, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  42%|████▏     | 114/271 [37:30<51:39, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  42%|████▏     | 115/271 [37:50<51:18, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  43%|████▎     | 116/271 [38:10<50:57, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  43%|████▎     | 117/271 [38:29<50:36, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  44%|████▎     | 118/271 [38:49<50:17, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  44%|████▍     | 119/271 [39:09<49:58, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  44%|████▍     | 120/271 [39:29<49:37, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  45%|████▍     | 121/271 [39:48<49:17, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  45%|████▌     | 122/271 [40:08<48:57, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  45%|████▌     | 123/271 [40:28<48:38, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  46%|████▌     | 124/271 [40:48<48:17, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  46%|████▌     | 125/271 [41:07<47:59, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  46%|████▋     | 126/271 [41:27<47:39, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  47%|████▋     | 127/271 [41:47<47:20, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  47%|████▋     | 128/271 [42:06<47:00, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  48%|████▊     | 129/271 [42:26<46:40, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  48%|████▊     | 130/271 [42:46<46:21, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  48%|████▊     | 131/271 [43:06<46:01, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  49%|████▊     | 132/271 [43:25<45:42, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  49%|████▉     | 133/271 [43:45<45:21, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  49%|████▉     | 134/271 [44:05<45:01, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  50%|████▉     | 135/271 [44:24<44:41, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  50%|█████     | 136/271 [44:44<44:22, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  51%|█████     | 137/271 [45:04<44:01, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  51%|█████     | 138/271 [45:24<43:43, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  51%|█████▏    | 139/271 [45:43<43:22, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  52%|█████▏    | 140/271 [46:03<43:02, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  52%|█████▏    | 141/271 [46:23<42:44, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  52%|█████▏    | 142/271 [46:43<42:24, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  53%|█████▎    | 143/271 [47:02<42:04, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  53%|█████▎    | 144/271 [47:22<41:46, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  54%|█████▎    | 145/271 [47:42<41:27, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  54%|█████▍    | 146/271 [48:01<41:07, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  54%|█████▍    | 147/271 [48:21<40:46, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  55%|█████▍    | 148/271 [48:41<40:26, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  55%|█████▍    | 149/271 [49:01<40:07, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  55%|█████▌    | 150/271 [49:20<39:48, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  56%|█████▌    | 151/271 [49:40<39:27, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  56%|█████▌    | 152/271 [50:00<39:07, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  56%|█████▋    | 153/271 [50:20<38:46, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  57%|█████▋    | 154/271 [50:39<38:27, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  57%|█████▋    | 155/271 [50:59<38:06, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  58%|█████▊    | 156/271 [51:19<37:46, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  58%|█████▊    | 157/271 [51:38<37:26, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  58%|█████▊    | 158/271 [51:58<37:07, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  59%|█████▊    | 159/271 [52:18<36:48, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  59%|█████▉    | 160/271 [52:38<36:29, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  59%|█████▉    | 161/271 [52:57<36:10, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  60%|█████▉    | 162/271 [53:17<35:47, 19.70s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  60%|██████    | 163/271 [53:37<35:28, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  61%|██████    | 164/271 [53:56<35:09, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  61%|██████    | 165/271 [54:16<34:49, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  61%|██████▏   | 166/271 [54:36<34:30, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  62%|██████▏   | 167/271 [54:56<34:10, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  62%|██████▏   | 168/271 [55:15<33:50, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  62%|██████▏   | 169/271 [55:35<33:30, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  63%|██████▎   | 170/271 [55:55<33:11, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  63%|██████▎   | 171/271 [56:14<32:51, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  63%|██████▎   | 172/271 [56:34<32:31, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  64%|██████▍   | 173/271 [56:54<32:12, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  64%|██████▍   | 174/271 [57:14<31:52, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  65%|██████▍   | 175/271 [57:33<31:32, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  65%|██████▍   | 176/271 [57:53<31:13, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  65%|██████▌   | 177/271 [58:13<30:53, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  66%|██████▌   | 178/271 [58:32<30:33, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  66%|██████▌   | 179/271 [58:52<30:13, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  66%|██████▋   | 180/271 [59:12<30:04, 19.83s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  67%|██████▋   | 181/271 [59:32<29:41, 19.80s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  67%|██████▋   | 182/271 [59:52<29:20, 19.78s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  68%|██████▊   | 183/271 [1:00:11<28:59, 19.77s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  68%|██████▊   | 184/271 [1:00:31<28:38, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  68%|██████▊   | 185/271 [1:00:51<28:17, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  69%|██████▊   | 186/271 [1:01:11<27:57, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  69%|██████▉   | 187/271 [1:01:30<27:36, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  69%|██████▉   | 188/271 [1:01:50<27:16, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  70%|██████▉   | 189/271 [1:02:10<26:57, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  70%|███████   | 190/271 [1:02:29<26:38, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  70%|███████   | 191/271 [1:02:49<26:18, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  71%|███████   | 192/271 [1:03:09<25:58, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  71%|███████   | 193/271 [1:03:29<25:38, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  72%|███████▏  | 194/271 [1:03:48<25:18, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  72%|███████▏  | 195/271 [1:04:08<24:58, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  72%|███████▏  | 196/271 [1:04:28<24:38, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  73%|███████▎  | 197/271 [1:04:48<24:19, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  73%|███████▎  | 198/271 [1:05:07<23:59, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  73%|███████▎  | 199/271 [1:05:27<23:39, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  74%|███████▍  | 200/271 [1:05:47<23:20, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  74%|███████▍  | 201/271 [1:06:06<23:00, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  75%|███████▍  | 202/271 [1:06:26<22:40, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  75%|███████▍  | 203/271 [1:06:46<22:21, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  75%|███████▌  | 204/271 [1:07:06<22:01, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  76%|███████▌  | 205/271 [1:07:25<21:41, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  76%|███████▌  | 206/271 [1:07:45<21:22, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  76%|███████▋  | 207/271 [1:08:05<21:02, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  77%|███████▋  | 208/271 [1:08:24<20:42, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  77%|███████▋  | 209/271 [1:08:44<20:22, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  77%|███████▋  | 210/271 [1:09:04<20:03, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  78%|███████▊  | 211/271 [1:09:24<19:43, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  78%|███████▊  | 212/271 [1:09:43<19:23, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  79%|███████▊  | 213/271 [1:10:03<19:03, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  79%|███████▉  | 214/271 [1:10:23<18:43, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  79%|███████▉  | 215/271 [1:10:42<18:24, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  80%|███████▉  | 216/271 [1:11:02<18:04, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  80%|████████  | 217/271 [1:11:22<17:45, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  80%|████████  | 218/271 [1:11:42<17:25, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  81%|████████  | 219/271 [1:12:01<17:05, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  81%|████████  | 220/271 [1:12:21<16:45, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  82%|████████▏ | 221/271 [1:12:41<16:26, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  82%|████████▏ | 222/271 [1:13:01<16:06, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  82%|████████▏ | 223/271 [1:13:20<15:46, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  83%|████████▎ | 224/271 [1:13:40<15:26, 19.71s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  83%|████████▎ | 225/271 [1:14:00<15:06, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  83%|████████▎ | 226/271 [1:14:19<14:47, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  84%|████████▍ | 227/271 [1:14:39<14:27, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  84%|████████▍ | 228/271 [1:14:59<14:08, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  85%|████████▍ | 229/271 [1:15:19<13:48, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  85%|████████▍ | 230/271 [1:15:38<13:28, 19.72s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  85%|████████▌ | 231/271 [1:15:58<13:09, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  86%|████████▌ | 232/271 [1:16:18<12:49, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  86%|████████▌ | 233/271 [1:16:38<12:29, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  86%|████████▋ | 234/271 [1:16:57<12:10, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  87%|████████▋ | 235/271 [1:17:17<11:50, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  87%|████████▋ | 236/271 [1:17:37<11:30, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  87%|████████▋ | 237/271 [1:17:56<11:11, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  88%|████████▊ | 238/271 [1:18:16<10:51, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  88%|████████▊ | 239/271 [1:18:36<10:31, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  89%|████████▊ | 240/271 [1:18:56<10:11, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  89%|████████▉ | 241/271 [1:19:15<09:52, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  89%|████████▉ | 242/271 [1:19:35<09:32, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  90%|████████▉ | 243/271 [1:19:55<09:12, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  90%|█████████ | 244/271 [1:20:15<08:53, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  90%|█████████ | 245/271 [1:20:34<08:33, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  91%|█████████ | 246/271 [1:20:54<08:13, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  91%|█████████ | 247/271 [1:21:14<07:53, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  92%|█████████▏| 248/271 [1:21:34<07:33, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  92%|█████████▏| 249/271 [1:21:53<07:14, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  92%|█████████▏| 250/271 [1:22:13<06:54, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  93%|█████████▎| 251/271 [1:22:33<06:34, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  93%|█████████▎| 252/271 [1:22:53<06:15, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  93%|█████████▎| 253/271 [1:23:12<05:55, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  94%|█████████▎| 254/271 [1:23:32<05:35, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  94%|█████████▍| 255/271 [1:23:52<05:16, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  94%|█████████▍| 256/271 [1:24:12<04:56, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  95%|█████████▍| 257/271 [1:24:31<04:36, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  95%|█████████▌| 258/271 [1:24:51<04:16, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  96%|█████████▌| 259/271 [1:25:11<03:56, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  96%|█████████▌| 260/271 [1:25:30<03:37, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  96%|█████████▋| 261/271 [1:25:50<03:17, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  97%|█████████▋| 262/271 [1:26:10<02:57, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  97%|█████████▋| 263/271 [1:26:30<02:37, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  97%|█████████▋| 264/271 [1:26:49<02:18, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  98%|█████████▊| 265/271 [1:27:09<01:58, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  98%|█████████▊| 266/271 [1:27:29<01:38, 19.75s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  99%|█████████▊| 267/271 [1:27:49<01:18, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  99%|█████████▉| 268/271 [1:28:08<00:59, 19.74s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:  99%|█████████▉| 269/271 [1:28:28<00:39, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches: 100%|█████████▉| 270/271 [1:28:48<00:19, 19.73s/batch]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches: 100%|██████████| 271/271 [1:28:57<00:00, 19.70s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses saved to data/input_response_data.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"google/IFEval\")\n",
    "\n",
    "# Model name\n",
    "#model_name = \"Qwen/Qwen2.5-7B\"\n",
    "model_name = \"../models/meta-llama/Llama-3.1-8B_lora_FINAL/checkpoint-14000\"\n",
    "\n",
    "# Quantization configuration using bitsandbytes library\n",
    "compute_dtype = getattr(torch, \"bfloat16\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load the pre-trained model with the specified quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load the tokenizer for Mistral\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    add_eos_token=True,\n",
    "    use_fast=True,\n",
    "    padding_side='left'\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token to EOS token\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id  # Set the model's padding token ID\n",
    "\n",
    "# Disable gradients to save memory and computation\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)  # Disable gradient computation globally\n",
    "\n",
    "# Prepare the output file\n",
    "output_dir = \"data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"input_response_data.jsonl\")\n",
    "\n",
    "# Batch processing\n",
    "batch_size = 2  # Adjust based on your GPU memory capacity\n",
    "max_length = 128  # Limit output length to avoid excessive memory usage\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, len(dataset['train']), batch_size), desc=\"Processing Batches\", unit=\"batch\"):\n",
    "        try:\n",
    "            if (i + batch_size) > len(dataset['train']):\n",
    "                batch_prompts = dataset['train']['prompt'][i:len(dataset['train'])]\n",
    "            else:\n",
    "                batch_prompts = dataset['train']['prompt'][i:i + batch_size]\n",
    "            # Tokenize inputs\n",
    "            inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            \n",
    "            # Generate responses\n",
    "            with torch.no_grad():  # Ensure gradients are disabled during generation\n",
    "                if max_length:\n",
    "                    outputs = model.generate(**inputs, max_new_tokens=max_length)\n",
    "                else:\n",
    "                    outputs = model.generate(**inputs)\n",
    "            # Decode responses\n",
    "            responses = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "\n",
    "            # Write each response directly to the file\n",
    "            for prompt, response in zip(batch_prompts, responses):\n",
    "                f.write(json.dumps({\"prompt\": prompt, \"response\": response}) + '\\n')\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {i}: {e}\")\n",
    "\n",
    "print(f\"Responses saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
